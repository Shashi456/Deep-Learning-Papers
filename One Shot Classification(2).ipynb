{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13600\n",
      "13800\n",
      "14000\n",
      "14200\n",
      "14400\n",
      "14600\n",
      "14800\n",
      "15000\n",
      "15200\n",
      "15400\n",
      "15600\n",
      "15800\n",
      "16000\n",
      "16200\n",
      "16400\n",
      "16600\n",
      "16800\n",
      "17000\n",
      "17200\n",
      "17400\n",
      "17600\n",
      "17800\n",
      "18000\n",
      "18200\n",
      "18400\n",
      "18600\n",
      "18800\n",
      "19000\n",
      "19200\n",
      "19400\n",
      "19600\n",
      "19800\n",
      "20000\n",
      "20200\n",
      "20400\n",
      "20600\n",
      "20800\n",
      "21000\n",
      "21200\n",
      "21400\n",
      "21600\n",
      "21800\n",
      "22000\n",
      "22200\n",
      "22400\n",
      "22600\n",
      "22800\n",
      "23000\n",
      "23200\n",
      "23400\n",
      "23600\n",
      "23800\n",
      "24000\n",
      "24200\n",
      "24400\n",
      "24600\n",
      "24800\n",
      "25000\n",
      "25200\n",
      "25400\n",
      "25600\n",
      "25800\n",
      "26000\n",
      "26200\n",
      "26400\n",
      "26600\n",
      "26800\n",
      "27000\n",
      "27200\n",
      "27400\n",
      "27600\n",
      "27800\n",
      "28000\n",
      "28200\n",
      "28400\n",
      "28600\n",
      "28800\n",
      "29000\n",
      "29200\n",
      "29400\n",
      "29600\n",
      "29800\n",
      "30000\n",
      "30200\n",
      "30400\n",
      "30600\n",
      "30800\n",
      "31000\n",
      "31200\n",
      "31400\n",
      "31600\n",
      "31800\n",
      "32000\n",
      "32200\n",
      "32400\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "image_path = 'omniglot_resized/*/*/'\n",
    "\n",
    "all_images = glob.glob(image_path + '*')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for image_file in all_images:\n",
    "    im = Image.open(image_file)\n",
    "    im = im.resize((28,28), resample=Image.LANCZOS)\n",
    "    im.save(image_file)\n",
    "    i += 1\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.datasets as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import math\n",
    "import argparse\n",
    "import random\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "#import task_generator as tg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2fde482be0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "sample_img = \"omniglot_resized/Sanskrit/character02/0852_01.png\"\n",
    "plt.imshow(Image.open(sample_img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f304014dac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Rotate(object):\n",
    "    def __init__(self, angle):\n",
    "        self.angle = angle\n",
    "    def __call__(self, x, mode=\"reflect\"):\n",
    "        x = x.rotate(self.angle)\n",
    "        return x\n",
    "    \n",
    "r = Rotate(90)\n",
    "plt.imshow(r(Image.open(sample_img)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623\n"
     ]
    }
   ],
   "source": [
    "#there are 1623 characters in total, so we use 1200 characters to train the network while the rest are used for testing\n",
    "def omniglot_character_folders():\n",
    "    data_folder = 'omniglot_resized/'\n",
    "\n",
    "    character_folders = [os.path.join(data_folder, family, character) \\\n",
    "                for family in os.listdir(data_folder) \\\n",
    "                if os.path.isdir(os.path.join(data_folder, family)) \\\n",
    "                for character in os.listdir(os.path.join(data_folder, family))]\n",
    "    random.seed(1)\n",
    "    random.shuffle(character_folders)\n",
    "\n",
    "    print(len(character_folders))\n",
    "    num_train = 1200\n",
    "    metatrain_character_folders = character_folders[:num_train]\n",
    "    metaval_character_folders = character_folders[num_train:]\n",
    "\n",
    "    return metatrain_character_folders,metaval_character_folders\n",
    "\n",
    "train, val = omniglot_character_folders()\n",
    "\n",
    "#print(train)\n",
    "\n",
    "#print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotTask(object):\n",
    "    # This function is basically for data generation, its used for training and testing purposes\n",
    "    # This class is for task generation for both meta training and meta testing.\n",
    "    def __init__(self, character_folders, num_classes, train_num,test_num):\n",
    "\n",
    "        self.character_folders = character_folders\n",
    "        self.num_classes = num_classes\n",
    "        self.train_num = train_num\n",
    "        self.test_num = test_num\n",
    "\n",
    "        class_folders = random.sample(self.character_folders,self.num_classes)\n",
    "        labels = np.array(range(len(class_folders)))\n",
    "        labels = dict(zip(class_folders, labels))\n",
    "        samples = dict()\n",
    "\n",
    "        self.train_roots = []\n",
    "        self.test_roots = []\n",
    "        for c in class_folders:\n",
    "\n",
    "            temp = [os.path.join(c, x) for x in os.listdir(c)]\n",
    "            samples[c] = random.sample(temp, len(temp))\n",
    "\n",
    "            self.train_roots += samples[c][:train_num]\n",
    "            self.test_roots += samples[c][train_num:train_num+test_num]\n",
    "\n",
    "        self.train_labels = [labels[self.get_class(x)] for x in self.train_roots]\n",
    "        self.test_labels = [labels[self.get_class(x)] for x in self.test_roots]\n",
    "\n",
    "    def get_class(self, sample):\n",
    "        return os.path.join(*sample.split('/')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotDataset(Dataset):\n",
    "    # For the dataset loader\n",
    "\n",
    "    def __init__(self, task, split='train', transform=None, target_transform=None):\n",
    "        self.transform = transform # Torch operations on the input image\n",
    "        self.target_transform = target_transform\n",
    "        self.task = task\n",
    "        self.split = split\n",
    "        self.image_roots = self.task.train_roots if self.split == 'train' else self.task.test_roots\n",
    "        self.labels = self.task.train_labels if self.split == 'train' else self.task.test_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_roots)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raise NotImplementedError(\"This is an abstract class. Subclass this class for your particular dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Omniglot(FewShotDataset):\n",
    "    # For loading the dataset\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Omniglot, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_root = self.image_roots[idx]\n",
    "        image = Image.open(image_root)\n",
    "        image = image.convert('L')\n",
    "        image = image.resize((28,28), resample=Image.LANCZOS)\n",
    "        # the above written lanczos is just a way of filtering the image, other possible methods could be bilinear etc\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "#Balancing code borrowed  \n",
    "class ClassBalancedSampler(Sampler):\n",
    "    # TO sample the same number of examples from the c1 classes we want to classify our image into \n",
    "\n",
    "    def __init__(self, num_per_class, num_cl, num_inst,shuffle=True):\n",
    "        self.num_per_class = num_per_class\n",
    "        self.num_cl = num_cl\n",
    "        self.num_inst = num_inst\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            batch = [[i+j*self.num_inst for i in torch.randperm(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n",
    "        else:\n",
    "            batch = [[i+j*self.num_inst for i in range(self.num_inst)[:self.num_per_class]] for j in range(self.num_cl)]\n",
    "        batch = [item for sublist in batch for item in sublist]\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(batch)\n",
    "        return iter(batch)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_data_loader(task, num_per_class=1, split='train',shuffle=True,rotation=0):\n",
    "    # NOTE: batch size here is # instances PER CLASS\n",
    "    # Data loader is a crucial part of all networks, it is the way you feed data into the network.\n",
    "    # It is absolutely mandatory for the network. \n",
    "    normalize = transforms.Normalize(mean=[0.92206, 0.92206, 0.92206], std=[0.08426, 0.08426, 0.08426])\n",
    "\n",
    "    dataset = Omniglot(task,split=split,transform=transforms.Compose([Rotate(rotation),transforms.ToTensor(),normalize]))\n",
    "\n",
    "    if split == 'train':\n",
    "        sampler = ClassBalancedSampler(num_per_class, task.num_classes, task.train_num,shuffle=shuffle)\n",
    "    else:\n",
    "        sampler = ClassBalancedSampler(num_per_class, task.num_classes, task.test_num,shuffle=shuffle)\n",
    "    loader = DataLoader(dataset, batch_size=num_per_class*task.num_classes, sampler=sampler)\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Network \n",
    "The paper mentions a model in which both the images are first put through convolution block and then the features are concatenated to act as an input to the relation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper Details\n",
    "# the following configurations have been suggested in the paper \n",
    "FEATURE_DIM = 64\n",
    "RELATION_DIM = 8\n",
    "CLASS_NUM = 20\n",
    "SAMPLE_NUM_PER_CLASS = 1\n",
    "BATCH_NUM_PER_CLASS = 10 #as per paper\n",
    "EPISODE = 1000000 # It was found that the network actually converged in 30000 iterations, these many iterations might \n",
    "#needed for 5shot classification\n",
    "TEST_EPISODE = 1000 # as per paper\n",
    "LEARNING_RATE = 10e-3 #as per paper\n",
    "HIDDEN_UNIT = 8 # as per paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623\n",
      "episode: 100 loss 0.047234851866960526\n",
      "episode: 200 loss 0.030134856700897217\n",
      "episode: 300 loss 0.028716329485177994\n",
      "episode: 400 loss 0.025335080921649933\n",
      "episode: 500 loss 0.021182678639888763\n",
      "episode: 600 loss 0.013566968031227589\n",
      "episode: 700 loss 0.01777578517794609\n",
      "episode: 800 loss 0.021663079038262367\n",
      "episode: 900 loss 0.014451860450208187\n",
      "episode: 1000 loss 0.01456803735345602\n",
      "episode: 1100 loss 0.014613676816225052\n",
      "episode: 1200 loss 0.012531456537544727\n",
      "episode: 1300 loss 0.012393396347761154\n",
      "episode: 1400 loss 0.012708797119557858\n",
      "episode: 1500 loss 0.01445039827376604\n",
      "episode: 1600 loss 0.009744142182171345\n",
      "episode: 1700 loss 0.015053289011120796\n",
      "episode: 1800 loss 0.009002644568681717\n",
      "episode: 1900 loss 0.014661770313978195\n",
      "episode: 2000 loss 0.0062833684496581554\n",
      "episode: 2100 loss 0.010207521729171276\n",
      "episode: 2200 loss 0.008253704756498337\n",
      "episode: 2300 loss 0.012623954564332962\n",
      "episode: 2400 loss 0.007745732553303242\n",
      "episode: 2500 loss 0.012527993880212307\n",
      "episode: 2600 loss 0.007910195738077164\n",
      "episode: 2700 loss 0.010839126072824001\n",
      "episode: 2800 loss 0.017649799585342407\n",
      "episode: 2900 loss 0.007663676515221596\n",
      "episode: 3000 loss 0.010000905953347683\n",
      "episode: 3100 loss 0.012410247698426247\n",
      "episode: 3200 loss 0.007062332704663277\n",
      "episode: 3300 loss 0.0076247029937803745\n",
      "episode: 3400 loss 0.00433550588786602\n",
      "episode: 3500 loss 0.009469094686210155\n",
      "episode: 3600 loss 0.01002452988177538\n",
      "episode: 3700 loss 0.009604024700820446\n",
      "episode: 3800 loss 0.006905261427164078\n",
      "episode: 3900 loss 0.0070176576264202595\n",
      "episode: 4000 loss 0.009239867329597473\n",
      "episode: 4100 loss 0.008849320001900196\n",
      "episode: 4200 loss 0.007475519552826881\n",
      "episode: 4300 loss 0.008650295436382294\n",
      "episode: 4400 loss 0.00609581358730793\n",
      "episode: 4500 loss 0.008557927794754505\n",
      "episode: 4600 loss 0.00682067358866334\n",
      "episode: 4700 loss 0.010800089687108994\n",
      "episode: 4800 loss 0.009949330240488052\n",
      "episode: 4900 loss 0.013122253119945526\n",
      "episode: 5000 loss 0.007351211737841368\n",
      "Testing...\n",
      "test accuracy: 0.95175\n",
      "save networks for episode: 4999\n",
      "episode: 5100 loss 0.008719679899513721\n",
      "episode: 5200 loss 0.00991152971982956\n",
      "episode: 5300 loss 0.007364945951849222\n",
      "episode: 5400 loss 0.008024412207305431\n",
      "episode: 5500 loss 0.009709428064525127\n",
      "episode: 5600 loss 0.008951366879045963\n",
      "episode: 5700 loss 0.006784327793866396\n",
      "episode: 5800 loss 0.008478909730911255\n",
      "episode: 5900 loss 0.006402444094419479\n",
      "episode: 6000 loss 0.014174285344779491\n",
      "episode: 6100 loss 0.01051880232989788\n",
      "episode: 6200 loss 0.004751160740852356\n",
      "episode: 6300 loss 0.004749520216137171\n",
      "episode: 6400 loss 0.008801753632724285\n",
      "episode: 6500 loss 0.010287069715559483\n",
      "episode: 6600 loss 0.004976525437086821\n",
      "episode: 6700 loss 0.009871992282569408\n",
      "episode: 6800 loss 0.0074431863613426685\n",
      "episode: 6900 loss 0.009392018429934978\n",
      "episode: 7000 loss 0.00631657475605607\n",
      "episode: 7100 loss 0.005682504270225763\n",
      "episode: 7200 loss 0.008516239933669567\n",
      "episode: 7300 loss 0.006531190127134323\n",
      "episode: 7400 loss 0.005787068512290716\n",
      "episode: 7500 loss 0.0049176509492099285\n",
      "episode: 7600 loss 0.008589452132582664\n",
      "episode: 7700 loss 0.006442565005272627\n",
      "episode: 7800 loss 0.007594328839331865\n",
      "episode: 7900 loss 0.008277663961052895\n",
      "episode: 8000 loss 0.012554915621876717\n",
      "episode: 8100 loss 0.007748444098979235\n",
      "episode: 8200 loss 0.005777955055236816\n",
      "episode: 8300 loss 0.009997977875173092\n",
      "episode: 8400 loss 0.008964071050286293\n",
      "episode: 8500 loss 0.005336773116141558\n",
      "episode: 8600 loss 0.008890149183571339\n",
      "episode: 8700 loss 0.007537608500570059\n",
      "episode: 8800 loss 0.0093105249106884\n",
      "episode: 8900 loss 0.0026940936222672462\n",
      "episode: 9000 loss 0.006783272605389357\n",
      "episode: 9100 loss 0.0035698956344276667\n",
      "episode: 9200 loss 0.007584191858768463\n",
      "episode: 9300 loss 0.005599207244813442\n",
      "episode: 9400 loss 0.004291695076972246\n",
      "episode: 9500 loss 0.006123014260083437\n",
      "episode: 9600 loss 0.008896604180335999\n",
      "episode: 9700 loss 0.0049240184016525745\n",
      "episode: 9800 loss 0.003983294125646353\n",
      "episode: 9900 loss 0.006053292192518711\n",
      "episode: 10000 loss 0.010979779995977879\n",
      "Testing...\n",
      "test accuracy: 0.9643999999999999\n",
      "save networks for episode: 9999\n",
      "episode: 10100 loss 0.006185918115079403\n",
      "episode: 10200 loss 0.006040581967681646\n",
      "episode: 10300 loss 0.004560884088277817\n",
      "episode: 10400 loss 0.006051487755030394\n",
      "episode: 10500 loss 0.009573855437338352\n",
      "episode: 10600 loss 0.007231324445456266\n",
      "episode: 10700 loss 0.012323901988565922\n",
      "episode: 10800 loss 0.0030652338173240423\n",
      "episode: 10900 loss 0.005986724980175495\n",
      "episode: 11000 loss 0.00794771034270525\n",
      "episode: 11100 loss 0.004508348647505045\n",
      "episode: 11200 loss 0.007947113364934921\n",
      "episode: 11300 loss 0.005753419362008572\n",
      "episode: 11400 loss 0.004311573226004839\n",
      "episode: 11500 loss 0.0072299884632229805\n",
      "episode: 11600 loss 0.009820591658353806\n",
      "episode: 11700 loss 0.007564575877040625\n",
      "episode: 11800 loss 0.011273509822785854\n",
      "episode: 11900 loss 0.003161653643473983\n",
      "episode: 12000 loss 0.005846469663083553\n",
      "episode: 12100 loss 0.004316532053053379\n",
      "episode: 12200 loss 0.0032209171913564205\n",
      "episode: 12300 loss 0.005678726825863123\n",
      "episode: 12400 loss 0.003237502882257104\n",
      "episode: 12500 loss 0.005816650111228228\n",
      "episode: 12600 loss 0.004184175282716751\n",
      "episode: 12700 loss 0.0033760725054889917\n",
      "episode: 12800 loss 0.00233704992569983\n",
      "episode: 12900 loss 0.007915905676782131\n",
      "episode: 13000 loss 0.006173460744321346\n",
      "episode: 13100 loss 0.005484405439347029\n",
      "episode: 13200 loss 0.007024715654551983\n",
      "episode: 13300 loss 0.006344200111925602\n",
      "episode: 13400 loss 0.004704232327640057\n",
      "episode: 13500 loss 0.007158604916185141\n",
      "episode: 13600 loss 0.004341684747487307\n",
      "episode: 13700 loss 0.004223985597491264\n",
      "episode: 13800 loss 0.011549180373549461\n",
      "episode: 13900 loss 0.011820943094789982\n",
      "episode: 14000 loss 0.007519406266510487\n",
      "episode: 14100 loss 0.00764084467664361\n",
      "episode: 14200 loss 0.003933557774871588\n",
      "episode: 14300 loss 0.005063513293862343\n",
      "episode: 14400 loss 0.005670852493494749\n",
      "episode: 14500 loss 0.007406853139400482\n",
      "episode: 14600 loss 0.006926275324076414\n",
      "episode: 14700 loss 0.005399851128458977\n",
      "episode: 14800 loss 0.0030193892307579517\n",
      "episode: 14900 loss 0.0015518765430897474\n",
      "episode: 15000 loss 0.005083042662590742\n",
      "Testing...\n",
      "test accuracy: 0.9705\n",
      "save networks for episode: 14999\n",
      "episode: 15100 loss 0.0035265155602246523\n",
      "episode: 15200 loss 0.0076749734580516815\n",
      "episode: 15300 loss 0.004718367476016283\n",
      "episode: 15400 loss 0.008721502497792244\n",
      "episode: 15500 loss 0.003399200038984418\n",
      "episode: 15600 loss 0.0056356568820774555\n",
      "episode: 15700 loss 0.0071653928607702255\n",
      "episode: 15800 loss 0.0026994708459824324\n",
      "episode: 15900 loss 0.006894039921462536\n",
      "episode: 16000 loss 0.004819740541279316\n",
      "episode: 16100 loss 0.005436355248093605\n",
      "episode: 16200 loss 0.005703008733689785\n",
      "episode: 16300 loss 0.0038741931784898043\n",
      "episode: 16400 loss 0.008803339675068855\n",
      "episode: 16500 loss 0.006730572320520878\n",
      "episode: 16600 loss 0.004075543489307165\n",
      "episode: 16700 loss 0.007126196753233671\n",
      "episode: 16800 loss 0.005335481837391853\n",
      "episode: 16900 loss 0.008063659071922302\n",
      "episode: 17000 loss 0.006776513531804085\n",
      "episode: 17100 loss 0.003935254644602537\n",
      "episode: 17200 loss 0.00608872203156352\n",
      "episode: 17300 loss 0.004366925917565823\n",
      "episode: 17400 loss 0.002940372098237276\n",
      "episode: 17500 loss 0.006041171960532665\n",
      "episode: 17600 loss 0.008810589089989662\n",
      "episode: 17700 loss 0.005577686708420515\n",
      "episode: 17800 loss 0.003843986429274082\n",
      "episode: 17900 loss 0.006689129397273064\n",
      "episode: 18000 loss 0.0039022096898406744\n",
      "episode: 18100 loss 0.002400883473455906\n",
      "episode: 18200 loss 0.006700544152408838\n",
      "episode: 18300 loss 0.0034129598643630743\n",
      "episode: 18400 loss 0.0031884941272437572\n",
      "episode: 18500 loss 0.009678862057626247\n",
      "episode: 18600 loss 0.004693462513387203\n",
      "episode: 18700 loss 0.0064674667082726955\n",
      "episode: 18800 loss 0.0014846816193312407\n",
      "episode: 18900 loss 0.006448662839829922\n",
      "episode: 19000 loss 0.0070571391843259335\n",
      "episode: 19100 loss 0.007687934674322605\n",
      "episode: 19200 loss 0.006474990397691727\n",
      "episode: 19300 loss 0.00647687865421176\n",
      "episode: 19400 loss 0.0103154256939888\n",
      "episode: 19500 loss 0.001652699545957148\n",
      "episode: 19600 loss 0.00534806028008461\n",
      "episode: 19700 loss 0.004676682408899069\n",
      "episode: 19800 loss 0.005035300273448229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 19900 loss 0.0031604350078850985\n",
      "episode: 20000 loss 0.003133546793833375\n",
      "Testing...\n",
      "test accuracy: 0.9712999999999999\n",
      "save networks for episode: 19999\n",
      "episode: 20100 loss 0.00395806971937418\n",
      "episode: 20200 loss 0.003600972704589367\n",
      "episode: 20300 loss 0.009259535931050777\n",
      "episode: 20400 loss 0.0045841229148209095\n",
      "episode: 20500 loss 0.007245531305670738\n",
      "episode: 20600 loss 0.003935899585485458\n",
      "episode: 20700 loss 0.007002098020166159\n",
      "episode: 20800 loss 0.0036954539828002453\n",
      "episode: 20900 loss 0.0035489199217408895\n",
      "episode: 21000 loss 0.005894646979868412\n",
      "episode: 21100 loss 0.00503436429426074\n",
      "episode: 21200 loss 0.007964667864143848\n",
      "episode: 21300 loss 0.008546394295990467\n",
      "episode: 21400 loss 0.002242116490378976\n",
      "episode: 21500 loss 0.006433666683733463\n",
      "episode: 21600 loss 0.00531307328492403\n",
      "episode: 21700 loss 0.003937945701181889\n",
      "episode: 21800 loss 0.0046241492964327335\n",
      "episode: 21900 loss 0.003856981173157692\n",
      "episode: 22000 loss 0.010574566200375557\n",
      "episode: 22100 loss 0.0023646836634725332\n",
      "episode: 22200 loss 0.005778854712843895\n",
      "episode: 22300 loss 0.007556641940027475\n",
      "episode: 22400 loss 0.006401547230780125\n",
      "episode: 22500 loss 0.00254824198782444\n",
      "episode: 22600 loss 0.00710170716047287\n",
      "episode: 22700 loss 0.005247738212347031\n",
      "episode: 22800 loss 0.009043533354997635\n",
      "episode: 22900 loss 0.002781831892207265\n",
      "episode: 23000 loss 0.002946327207610011\n",
      "episode: 23100 loss 0.004093540832400322\n",
      "episode: 23200 loss 0.005104942712932825\n",
      "episode: 23300 loss 0.0045811752788722515\n",
      "episode: 23900 loss 0.00932264979928732\n",
      "episode: 24000 loss 0.002805182710289955\n",
      "episode: 24100 loss 0.010257910937070847\n",
      "episode: 24200 loss 0.004450769629329443\n",
      "episode: 24300 loss 0.00768899405375123\n",
      "episode: 24400 loss 0.004994131159037352\n",
      "episode: 24500 loss 0.002504080766811967\n",
      "episode: 24600 loss 0.0040956647135317326\n",
      "episode: 24700 loss 0.007048001978546381\n",
      "episode: 24800 loss 0.005148536991328001\n",
      "episode: 24900 loss 0.008607789874076843\n",
      "episode: 25000 loss 0.0023146746680140495\n",
      "Testing...\n",
      "test accuracy: 0.975\n",
      "save networks for episode: 24999\n",
      "episode: 25100 loss 0.0067497557029128075\n",
      "episode: 25200 loss 0.006456345785409212\n",
      "episode: 25300 loss 0.0065803672187030315\n",
      "episode: 25400 loss 0.0036717881448566914\n",
      "episode: 25500 loss 0.005660924129188061\n",
      "episode: 25600 loss 0.005237087141722441\n",
      "episode: 25700 loss 0.004079760983586311\n",
      "episode: 25800 loss 0.006161832716315985\n",
      "episode: 25900 loss 0.005036431830376387\n",
      "episode: 26000 loss 0.0029177542310208082\n",
      "episode: 26100 loss 0.0037481545004993677\n",
      "episode: 26200 loss 0.0024802437983453274\n",
      "episode: 26300 loss 0.003943124320358038\n",
      "episode: 26400 loss 0.002652297029271722\n",
      "episode: 26500 loss 0.0060896617360413074\n",
      "episode: 26600 loss 0.0036841484252363443\n",
      "episode: 26700 loss 0.008814625442028046\n",
      "episode: 26800 loss 0.0032514820341020823\n",
      "episode: 26900 loss 0.00383555656298995\n",
      "episode: 27000 loss 0.004426111467182636\n",
      "episode: 27100 loss 0.0031411871314048767\n",
      "episode: 27200 loss 0.008952166885137558\n",
      "episode: 27300 loss 0.0042848591692745686\n",
      "episode: 27400 loss 0.002416532952338457\n",
      "episode: 27500 loss 0.0032443413510918617\n",
      "episode: 27600 loss 0.0034451058600097895\n",
      "episode: 27700 loss 0.0033658226020634174\n",
      "episode: 27800 loss 0.005655499640852213\n",
      "episode: 27900 loss 0.0031085347291082144\n",
      "episode: 28000 loss 0.0037308083847165108\n",
      "episode: 28100 loss 0.007657604292035103\n",
      "episode: 28200 loss 0.0022454133722931147\n",
      "episode: 28300 loss 0.005273499991744757\n",
      "episode: 28400 loss 0.007348517421633005\n",
      "episode: 28500 loss 0.007048183586448431\n",
      "episode: 28600 loss 0.001602012780494988\n",
      "episode: 28700 loss 0.005044985096901655\n",
      "episode: 28800 loss 0.0037151111755520105\n",
      "episode: 28900 loss 0.004080439917743206\n",
      "episode: 29000 loss 0.008924075402319431\n",
      "episode: 29100 loss 0.0031990488059818745\n",
      "episode: 29200 loss 0.0025103839579969645\n",
      "episode: 29300 loss 0.004064090549945831\n",
      "episode: 29400 loss 0.005882859230041504\n",
      "episode: 29500 loss 0.0025699054822325706\n",
      "episode: 29600 loss 0.00633431039750576\n",
      "episode: 29700 loss 0.003331601619720459\n",
      "episode: 29800 loss 0.006108881440013647\n",
      "episode: 29900 loss 0.0011507854796946049\n",
      "episode: 30000 loss 0.004703277722001076\n",
      "Testing...\n",
      "test accuracy: 0.97305\n",
      "episode: 30100 loss 0.004866741131991148\n",
      "episode: 30200 loss 0.001660709036514163\n",
      "episode: 30300 loss 0.004130573943257332\n",
      "episode: 30400 loss 0.002404293976724148\n",
      "episode: 30500 loss 0.0040729655884206295\n",
      "episode: 30600 loss 0.005154873710125685\n",
      "episode: 30700 loss 0.0032079739030450583\n",
      "episode: 30800 loss 0.004975497256964445\n",
      "episode: 30900 loss 0.0035974227357655764\n",
      "episode: 31000 loss 0.0031170863658189774\n",
      "episode: 31100 loss 0.002326608169823885\n",
      "episode: 31200 loss 0.003392667043954134\n",
      "episode: 31300 loss 0.007425257004797459\n",
      "episode: 31400 loss 0.006831597536802292\n",
      "episode: 31500 loss 0.004226748365908861\n",
      "episode: 31600 loss 0.0046373275108635426\n",
      "episode: 31700 loss 0.0015024299500510097\n",
      "episode: 31800 loss 0.009039502590894699\n",
      "episode: 31900 loss 0.003957563079893589\n",
      "episode: 32000 loss 0.0045963553711771965\n",
      "episode: 32100 loss 0.0025276520755141973\n",
      "episode: 32200 loss 0.002076110104098916\n",
      "episode: 32300 loss 0.005021187011152506\n",
      "episode: 32900 loss 0.009494118392467499\n",
      "episode: 33000 loss 0.003328838851302862\n",
      "episode: 33100 loss 0.0022339734714478254\n",
      "episode: 33200 loss 0.0028669291641563177\n",
      "episode: 33300 loss 0.0037032412365078926\n",
      "episode: 33400 loss 0.006491951644420624\n",
      "episode: 33500 loss 0.006118330173194408\n",
      "episode: 33600 loss 0.0027304659597575665\n",
      "episode: 33700 loss 0.006797581445425749\n",
      "episode: 33800 loss 0.0030611813999712467\n",
      "episode: 33900 loss 0.006464989855885506\n",
      "episode: 34000 loss 0.007151997648179531\n",
      "episode: 34100 loss 0.005510085262358189\n",
      "episode: 34200 loss 0.006652512587606907\n",
      "episode: 34300 loss 0.0029616686515510082\n",
      "episode: 34400 loss 0.004047814290970564\n",
      "episode: 34500 loss 0.002826981246471405\n",
      "episode: 34600 loss 0.002021304564550519\n",
      "episode: 34700 loss 0.0015929173678159714\n",
      "episode: 34800 loss 0.0047947559505701065\n",
      "episode: 34900 loss 0.006704962346702814\n",
      "episode: 35000 loss 0.007979710586369038\n",
      "Testing...\n",
      "test accuracy: 0.9739\n",
      "episode: 35100 loss 0.005704060196876526\n",
      "episode: 35200 loss 0.0056330179795622826\n",
      "episode: 35300 loss 0.004124694503843784\n",
      "episode: 35400 loss 0.003168300027027726\n",
      "episode: 35500 loss 0.004518560133874416\n",
      "episode: 35600 loss 0.0041632987558841705\n",
      "episode: 35700 loss 0.0017631816444918513\n",
      "episode: 35800 loss 0.008298749104142189\n",
      "episode: 35900 loss 0.007767417933791876\n",
      "episode: 36000 loss 0.008012082427740097\n",
      "episode: 36100 loss 0.005159074906259775\n",
      "episode: 36200 loss 0.004969203844666481\n",
      "episode: 36300 loss 0.003528666216880083\n",
      "episode: 36400 loss 0.006826029624789953\n",
      "episode: 36500 loss 0.001822603982873261\n",
      "episode: 36600 loss 0.0039056497626006603\n",
      "episode: 37000 loss 0.0037025390192866325\n",
      "episode: 37100 loss 0.0010971195297315717\n",
      "episode: 37200 loss 0.002320351544767618\n",
      "episode: 37300 loss 0.0020784439984709024\n",
      "episode: 37400 loss 0.0013696806272491813\n",
      "episode: 38000 loss 0.003202010178938508\n",
      "episode: 38100 loss 0.005178053397685289\n",
      "episode: 38200 loss 0.00425510061904788\n",
      "episode: 38300 loss 0.0022652996703982353\n",
      "episode: 38400 loss 0.006425799801945686\n",
      "episode: 38500 loss 0.005498144775629044\n",
      "episode: 38600 loss 0.006269337609410286\n",
      "episode: 38700 loss 0.004467008635401726\n",
      "episode: 38800 loss 0.0031464649364352226\n",
      "episode: 38900 loss 0.0017771280836313963\n",
      "episode: 39000 loss 0.005118453409522772\n",
      "episode: 39100 loss 0.0041066431440413\n",
      "episode: 39200 loss 0.006064914632588625\n",
      "episode: 39300 loss 0.005280391313135624\n",
      "episode: 39400 loss 0.006371509749442339\n",
      "episode: 39500 loss 0.004689184948801994\n",
      "episode: 39600 loss 0.004005509428679943\n",
      "episode: 39700 loss 0.00534834573045373\n",
      "episode: 39800 loss 0.0034690499305725098\n",
      "episode: 39900 loss 0.0034789941273629665\n",
      "episode: 40000 loss 0.0050207688473165035\n",
      "Testing...\n",
      "test accuracy: 0.9735\n",
      "episode: 40100 loss 0.0045026736333966255\n",
      "episode: 40200 loss 0.008685428649187088\n",
      "episode: 40300 loss 0.00257420283742249\n",
      "episode: 40400 loss 0.0028734758961945772\n",
      "episode: 40500 loss 0.002298157662153244\n",
      "episode: 40600 loss 0.0035764984786510468\n",
      "episode: 40700 loss 0.004040866158902645\n",
      "episode: 40800 loss 0.01054966077208519\n",
      "episode: 40900 loss 0.0016032406128942966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 41000 loss 0.001265936647541821\n",
      "episode: 41100 loss 0.007452445104718208\n",
      "episode: 41200 loss 0.00459452997893095\n",
      "episode: 41300 loss 0.004217158537358046\n",
      "episode: 41400 loss 0.004831523168832064\n",
      "episode: 41500 loss 0.0012594233267009258\n",
      "episode: 41600 loss 0.0019701330456882715\n",
      "episode: 41700 loss 0.0026809333357959986\n",
      "episode: 41800 loss 0.0033638791646808386\n",
      "episode: 41900 loss 0.0024230137933045626\n",
      "episode: 42000 loss 0.006814518943428993\n",
      "episode: 42100 loss 0.0010654791258275509\n",
      "episode: 42200 loss 0.004809497855603695\n",
      "episode: 42300 loss 0.004863325972110033\n",
      "episode: 42400 loss 0.006882484070956707\n",
      "episode: 42500 loss 0.0036198243033140898\n",
      "episode: 42600 loss 0.002313165692612529\n",
      "episode: 42700 loss 0.0059229726903140545\n",
      "episode: 42800 loss 0.0023776746820658445\n",
      "episode: 42900 loss 0.005758829414844513\n",
      "episode: 43000 loss 0.005096423905342817\n",
      "episode: 43100 loss 0.002691881963983178\n",
      "episode: 43200 loss 0.0024386653676629066\n",
      "episode: 43300 loss 0.005153115373104811\n",
      "episode: 43400 loss 0.00657655019313097\n",
      "episode: 43500 loss 0.0023981635458767414\n",
      "episode: 43600 loss 0.002472087973728776\n",
      "episode: 43700 loss 0.006769412197172642\n",
      "episode: 43800 loss 0.004280528053641319\n",
      "episode: 43900 loss 0.0016615022905170918\n",
      "episode: 44000 loss 0.00221818033605814\n",
      "episode: 44100 loss 0.00868438370525837\n",
      "episode: 44200 loss 0.004404386971145868\n",
      "episode: 44300 loss 0.00236418005079031\n",
      "episode: 44400 loss 0.004942183382809162\n",
      "episode: 44500 loss 0.0027847180608659983\n",
      "episode: 44600 loss 0.004335928708314896\n",
      "episode: 44700 loss 0.004528526216745377\n",
      "episode: 44800 loss 0.004567510448396206\n",
      "episode: 44900 loss 0.0032801905181258917\n",
      "episode: 45000 loss 0.0025372824165970087\n",
      "Testing...\n",
      "test accuracy: 0.9752000000000001\n",
      "save networks for episode: 44999\n",
      "episode: 45100 loss 0.0038097857031971216\n",
      "episode: 45200 loss 0.0017874056939035654\n",
      "episode: 45300 loss 0.002154654124751687\n",
      "episode: 45400 loss 0.005568130407482386\n",
      "episode: 45500 loss 0.007035714108496904\n",
      "episode: 45600 loss 0.005290093366056681\n",
      "episode: 45700 loss 0.0017571235075592995\n",
      "episode: 45800 loss 0.0032428728882223368\n",
      "episode: 45900 loss 0.0029460955411195755\n",
      "episode: 46000 loss 0.007611272856593132\n",
      "episode: 46100 loss 0.005667010322213173\n",
      "episode: 46200 loss 0.0059210690669715405\n",
      "episode: 46300 loss 0.008335153572261333\n",
      "episode: 46400 loss 0.003611365333199501\n",
      "episode: 46500 loss 0.0008270362741313875\n",
      "episode: 46600 loss 0.002209056168794632\n",
      "episode: 46700 loss 0.002143021672964096\n",
      "episode: 46800 loss 0.003646550700068474\n",
      "episode: 46900 loss 0.003273852402344346\n",
      "episode: 47000 loss 0.0030147505458444357\n",
      "episode: 47100 loss 0.004256008192896843\n",
      "episode: 47200 loss 0.004114876966923475\n",
      "episode: 47300 loss 0.004450865555554628\n",
      "episode: 47400 loss 0.004277723375707865\n",
      "episode: 47500 loss 0.0015405867015942931\n",
      "episode: 47600 loss 0.0028331896755844355\n",
      "episode: 47700 loss 0.0028092002030462027\n",
      "episode: 47800 loss 0.002840843517333269\n",
      "episode: 47900 loss 0.004713693168014288\n",
      "episode: 48000 loss 0.001954620936885476\n",
      "episode: 48100 loss 0.0030709828715771437\n",
      "episode: 48200 loss 0.0025489896070212126\n",
      "episode: 48300 loss 0.0023730178363621235\n",
      "episode: 48400 loss 0.004549465142190456\n",
      "episode: 48500 loss 0.008733580820262432\n",
      "episode: 48600 loss 0.0023189231287688017\n",
      "episode: 48700 loss 0.0047904979437589645\n",
      "episode: 48800 loss 0.01660943776369095\n",
      "episode: 48900 loss 0.002490681130439043\n",
      "episode: 49000 loss 0.002900094958022237\n",
      "episode: 49100 loss 0.003112302627414465\n",
      "episode: 49200 loss 0.0019447127124294639\n",
      "episode: 49300 loss 0.004948205314576626\n",
      "episode: 49400 loss 0.004692636430263519\n",
      "episode: 49500 loss 0.001167250331491232\n",
      "episode: 49600 loss 0.003050654660910368\n",
      "episode: 49700 loss 0.004097552504390478\n",
      "episode: 49800 loss 0.004188966937363148\n",
      "episode: 49900 loss 0.005911314859986305\n",
      "episode: 50000 loss 0.004528388846665621\n",
      "Testing...\n",
      "test accuracy: 0.9732999999999999\n",
      "episode: 50100 loss 0.003108559176325798\n",
      "episode: 50200 loss 0.002445064950734377\n",
      "episode: 50300 loss 0.005360671319067478\n",
      "episode: 50400 loss 0.0031591071747243404\n",
      "episode: 50500 loss 0.004383450839668512\n",
      "episode: 50600 loss 0.003653778927400708\n",
      "episode: 50700 loss 0.004020885564386845\n",
      "episode: 50800 loss 0.0027932138182222843\n",
      "episode: 50900 loss 0.0072480058297514915\n",
      "episode: 51000 loss 0.00515366205945611\n",
      "episode: 51100 loss 0.011684637516736984\n",
      "episode: 51200 loss 0.0031189676374197006\n",
      "episode: 51300 loss 0.0030105416662991047\n",
      "episode: 51400 loss 0.0027161482721567154\n",
      "episode: 51500 loss 0.0012451024958863854\n",
      "episode: 51600 loss 0.004026531707495451\n",
      "episode: 51700 loss 0.0014941631816327572\n",
      "episode: 51800 loss 0.003430931130424142\n",
      "episode: 51900 loss 0.0031755189411342144\n",
      "episode: 52000 loss 0.01113533228635788\n",
      "episode: 52100 loss 0.003941407427191734\n",
      "episode: 52200 loss 0.004650119226425886\n",
      "episode: 52300 loss 0.003513775300234556\n",
      "episode: 52400 loss 0.004280545748770237\n",
      "episode: 52500 loss 0.004037547390908003\n",
      "episode: 52600 loss 0.0030325131956487894\n",
      "episode: 52700 loss 0.00472936499863863\n",
      "episode: 52800 loss 0.002736492082476616\n",
      "episode: 52900 loss 0.0014758440665900707\n",
      "episode: 53000 loss 0.0016651389887556434\n",
      "episode: 53100 loss 0.001998019637539983\n",
      "episode: 53200 loss 0.0014975867234170437\n",
      "episode: 53300 loss 0.0016902921488508582\n",
      "episode: 53400 loss 0.0019214753992855549\n",
      "episode: 53500 loss 0.005700530484318733\n",
      "episode: 53600 loss 0.004401371348649263\n",
      "episode: 53700 loss 0.0020401556976139545\n",
      "episode: 53800 loss 0.0037612924352288246\n",
      "episode: 53900 loss 0.0025860783644020557\n",
      "episode: 54000 loss 0.005153475794941187\n",
      "episode: 54100 loss 0.0023165757302194834\n",
      "episode: 54200 loss 0.005797173362225294\n",
      "episode: 54300 loss 0.007110060658305883\n",
      "episode: 54900 loss 0.0031637821812182665\n",
      "episode: 55000 loss 0.0037275764625519514\n",
      "Testing...\n",
      "test accuracy: 0.97505\n",
      "episode: 55100 loss 0.0030037739779800177\n",
      "episode: 55200 loss 0.003969011828303337\n",
      "episode: 55300 loss 0.002921866485849023\n",
      "episode: 55400 loss 0.002168322214856744\n",
      "episode: 55500 loss 0.0032547966111451387\n",
      "episode: 55600 loss 0.00148033257573843\n",
      "episode: 55700 loss 0.0024779278319329023\n",
      "episode: 55800 loss 0.0016314748208969831\n",
      "episode: 55900 loss 0.0037533806171268225\n",
      "episode: 56000 loss 0.0028232871554791927\n",
      "episode: 56100 loss 0.0017557594692334533\n",
      "episode: 56200 loss 0.003469320945441723\n",
      "episode: 56300 loss 0.001993326935917139\n",
      "episode: 56400 loss 0.006519079674035311\n",
      "episode: 56500 loss 0.0038646641187369823\n",
      "episode: 56600 loss 0.004237775690853596\n",
      "episode: 56700 loss 0.0024311747401952744\n",
      "episode: 56800 loss 0.006219263654202223\n",
      "episode: 56900 loss 0.004450432490557432\n",
      "episode: 57000 loss 0.0015812969068065286\n",
      "episode: 57100 loss 0.0017012652242556214\n",
      "episode: 57200 loss 0.002203353913500905\n",
      "episode: 57300 loss 0.004139465745538473\n",
      "episode: 57400 loss 0.002372580347582698\n",
      "episode: 57500 loss 0.0023440541699528694\n",
      "episode: 57600 loss 0.005764735862612724\n",
      "episode: 57700 loss 0.003330130595713854\n",
      "episode: 57800 loss 0.004322631284594536\n",
      "episode: 57900 loss 0.00344152026809752\n",
      "episode: 58000 loss 0.0006515265558846295\n",
      "episode: 58100 loss 0.002946987049654126\n",
      "episode: 58200 loss 0.00542712677270174\n",
      "episode: 58300 loss 0.005020867567509413\n",
      "episode: 58400 loss 0.0037944563664495945\n",
      "episode: 58500 loss 0.002372917253524065\n",
      "episode: 58600 loss 0.0020877637434750795\n",
      "episode: 58700 loss 0.007245925720781088\n",
      "episode: 58800 loss 0.0011863162508234382\n",
      "episode: 58900 loss 0.006001842208206654\n",
      "episode: 59000 loss 0.0014582877047359943\n",
      "episode: 59100 loss 0.0026074089109897614\n",
      "episode: 59200 loss 0.0054005528800189495\n",
      "episode: 59300 loss 0.0028660413809120655\n",
      "episode: 59400 loss 0.0019932056311517954\n",
      "episode: 59500 loss 0.00506194680929184\n",
      "episode: 59600 loss 0.0020437943749129772\n",
      "episode: 59700 loss 0.0016959644854068756\n",
      "episode: 59800 loss 0.0032365736551582813\n",
      "episode: 59900 loss 0.005277058109641075\n",
      "episode: 60000 loss 0.0036727795377373695\n",
      "Testing...\n",
      "test accuracy: 0.9757\n",
      "save networks for episode: 59999\n",
      "episode: 60100 loss 0.002789442427456379\n",
      "episode: 60200 loss 0.004315593745559454\n",
      "episode: 60300 loss 0.0033975779078900814\n",
      "episode: 60400 loss 0.001539464108645916\n",
      "episode: 60500 loss 0.003973715472966433\n",
      "episode: 60600 loss 0.0029388677794486284\n",
      "episode: 60700 loss 0.002284375950694084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 60800 loss 0.004791132174432278\n",
      "episode: 60900 loss 0.0024964509066194296\n",
      "episode: 61000 loss 0.0035645782481878996\n",
      "episode: 61100 loss 0.001809322857297957\n",
      "episode: 61200 loss 0.0056870607659220695\n",
      "episode: 61300 loss 0.004382009152323008\n",
      "episode: 61400 loss 0.0031511380802839994\n",
      "episode: 61500 loss 0.00234976620413363\n",
      "episode: 61600 loss 0.005619928706437349\n",
      "episode: 61700 loss 0.005399757996201515\n",
      "episode: 61800 loss 0.005524763371795416\n",
      "episode: 61900 loss 0.004333087243139744\n",
      "episode: 62000 loss 0.002380536636337638\n",
      "episode: 62100 loss 0.004245559684932232\n",
      "episode: 62200 loss 0.0028577439952641726\n",
      "episode: 62300 loss 0.0014786302344873548\n",
      "episode: 62400 loss 0.001638683839701116\n",
      "episode: 62500 loss 0.0027501224540174007\n",
      "episode: 62600 loss 0.0024066490586847067\n",
      "episode: 62700 loss 0.001766238478012383\n",
      "episode: 62800 loss 0.001175003475509584\n",
      "episode: 62900 loss 0.0016342290909960866\n",
      "episode: 63000 loss 0.004213697277009487\n",
      "episode: 63100 loss 0.00275651877745986\n",
      "episode: 63200 loss 0.0013597417855635285\n",
      "episode: 63300 loss 0.0010025015799328685\n",
      "episode: 63400 loss 0.0034338145051151514\n",
      "episode: 63500 loss 0.007574320770800114\n",
      "episode: 63600 loss 0.0016863832715898752\n",
      "episode: 63700 loss 0.002450865926221013\n",
      "episode: 63800 loss 0.006266302894800901\n",
      "episode: 63900 loss 0.002915051532909274\n",
      "episode: 64000 loss 0.00510454410687089\n",
      "episode: 64100 loss 0.0021988688968122005\n",
      "episode: 64200 loss 0.008576751686632633\n",
      "episode: 64300 loss 0.005642242264002562\n",
      "episode: 64400 loss 0.0013916490133851767\n",
      "episode: 64500 loss 0.002173440996557474\n",
      "episode: 64600 loss 0.002635049633681774\n",
      "episode: 64700 loss 0.006346515379846096\n",
      "episode: 64800 loss 0.001181388390250504\n",
      "episode: 64900 loss 0.0036332830786705017\n",
      "episode: 65000 loss 0.004826897289603949\n",
      "Testing...\n",
      "test accuracy: 0.9718\n",
      "episode: 65100 loss 0.002717491239309311\n",
      "episode: 65200 loss 0.0009755695937201381\n",
      "episode: 65300 loss 0.003403533948585391\n",
      "episode: 65400 loss 0.005203606095165014\n",
      "episode: 65500 loss 0.004266378935426474\n",
      "episode: 65600 loss 0.0040694489143788815\n",
      "episode: 65700 loss 0.009642736054956913\n",
      "episode: 65800 loss 0.0024010157212615013\n",
      "episode: 65900 loss 0.004397907294332981\n",
      "episode: 66000 loss 0.0031861213501542807\n",
      "episode: 66100 loss 0.006096820812672377\n",
      "episode: 66200 loss 0.0016203665873035789\n",
      "episode: 66300 loss 0.0030299739446491003\n",
      "episode: 66400 loss 0.0021783767733722925\n",
      "episode: 66500 loss 0.0014416282065212727\n",
      "episode: 66600 loss 0.002652136143296957\n",
      "episode: 66700 loss 0.002252922859042883\n",
      "episode: 66800 loss 0.004519669339060783\n",
      "episode: 66900 loss 0.005101100075989962\n",
      "episode: 67000 loss 0.0057786209508776665\n",
      "episode: 67100 loss 0.0022273396607488394\n",
      "episode: 67200 loss 0.0048657567240297794\n",
      "episode: 67300 loss 0.003438247600570321\n",
      "episode: 67800 loss 0.0034125589299947023\n",
      "episode: 67900 loss 0.004459258168935776\n",
      "episode: 68000 loss 0.001230322988703847\n",
      "episode: 68100 loss 0.00226242165081203\n",
      "episode: 68200 loss 0.0030253904405981302\n",
      "episode: 68300 loss 0.005508534610271454\n",
      "episode: 68400 loss 0.0027317123021930456\n",
      "episode: 68500 loss 0.00411849282681942\n",
      "episode: 68600 loss 0.002340806880965829\n",
      "episode: 68700 loss 0.0019143143435940146\n",
      "episode: 68800 loss 0.007007237058132887\n",
      "episode: 68900 loss 0.002997415605932474\n",
      "episode: 69000 loss 0.0030269012786448\n",
      "episode: 69100 loss 0.0026416233740746975\n",
      "episode: 69200 loss 0.002097492106258869\n",
      "episode: 69300 loss 0.0005667493678629398\n",
      "episode: 69400 loss 0.002746426733210683\n",
      "episode: 69500 loss 0.003919412847608328\n",
      "episode: 69600 loss 0.002369202906265855\n",
      "episode: 69700 loss 0.007248700596392155\n",
      "episode: 69800 loss 0.0036098146811127663\n",
      "episode: 69900 loss 0.0014455100754275918\n",
      "episode: 70000 loss 0.004819839261472225\n",
      "Testing...\n",
      "test accuracy: 0.9736\n",
      "episode: 70100 loss 0.0034453149419277906\n",
      "episode: 70200 loss 0.0023035453632473946\n",
      "episode: 70300 loss 0.0028239567764103413\n",
      "episode: 70400 loss 0.005982299335300922\n",
      "episode: 70500 loss 0.003565946128219366\n",
      "episode: 70600 loss 0.0019520417554304004\n",
      "episode: 70700 loss 0.0005650175735354424\n",
      "episode: 70800 loss 0.0046682776883244514\n",
      "episode: 70900 loss 0.0009499246370978653\n",
      "episode: 71000 loss 0.002119639655575156\n",
      "episode: 71100 loss 0.0012755487114191055\n",
      "episode: 71200 loss 0.008781125769019127\n",
      "episode: 71300 loss 0.0024479429703205824\n",
      "episode: 71400 loss 0.0029404128435999155\n",
      "episode: 71500 loss 0.0029574816580861807\n",
      "episode: 71600 loss 0.004041935317218304\n",
      "episode: 71700 loss 0.0067215426824986935\n",
      "episode: 71800 loss 0.0027819210663437843\n",
      "episode: 71900 loss 0.00416415324434638\n",
      "episode: 72000 loss 0.0032587777823209763\n",
      "episode: 72100 loss 0.00355543103069067\n",
      "episode: 72200 loss 0.0025809549260884523\n",
      "episode: 72300 loss 0.003813881194218993\n",
      "episode: 72400 loss 0.0018802277045324445\n",
      "episode: 72500 loss 0.004963929299265146\n",
      "episode: 72600 loss 0.0016478695906698704\n",
      "episode: 72700 loss 0.002057363511994481\n",
      "episode: 72800 loss 0.003348914673551917\n",
      "episode: 73300 loss 0.001136976177804172\n",
      "episode: 73400 loss 0.002068428322672844\n",
      "episode: 73500 loss 0.0030231918208301067\n",
      "episode: 73600 loss 0.0027303786482661963\n",
      "episode: 73700 loss 0.0022862569894641638\n",
      "episode: 73800 loss 0.0031406679190695286\n",
      "episode: 73900 loss 0.0029857836198061705\n",
      "episode: 74000 loss 0.0009173831203952432\n",
      "episode: 74100 loss 0.0012504775077104568\n",
      "episode: 74200 loss 0.002306654816493392\n",
      "episode: 74300 loss 0.0036917931865900755\n",
      "episode: 74400 loss 0.004931938368827105\n",
      "episode: 74500 loss 0.0038859881460666656\n",
      "episode: 74600 loss 0.0019854893907904625\n",
      "episode: 74700 loss 0.0017885154811665416\n",
      "episode: 74800 loss 0.003643300384283066\n",
      "episode: 74900 loss 0.0012884433381259441\n",
      "episode: 75000 loss 0.002871372038498521\n",
      "Testing...\n",
      "test accuracy: 0.97345\n",
      "episode: 75100 loss 0.003677736734971404\n",
      "episode: 75200 loss 0.0012649823911488056\n",
      "episode: 75300 loss 0.0035100209061056376\n",
      "episode: 75400 loss 0.004476100672036409\n",
      "episode: 75500 loss 0.001878833631053567\n",
      "episode: 75600 loss 0.0059398505836725235\n",
      "episode: 75700 loss 0.0026081630494445562\n",
      "episode: 75800 loss 0.00445527583360672\n",
      "episode: 75900 loss 0.002304905327036977\n",
      "episode: 76000 loss 0.003476414131000638\n",
      "episode: 76100 loss 0.0044107744470238686\n",
      "episode: 76200 loss 0.0037752212956547737\n",
      "episode: 76300 loss 0.0010469889966771007\n",
      "episode: 76400 loss 0.0045737954787909985\n",
      "episode: 76500 loss 0.0008016294450499117\n",
      "episode: 76600 loss 0.007117529399693012\n",
      "episode: 76700 loss 0.0023829594720155\n",
      "episode: 76800 loss 0.0020860310178250074\n",
      "episode: 76900 loss 0.002753047738224268\n",
      "episode: 77000 loss 0.0030073465313762426\n",
      "episode: 77100 loss 0.003040546551346779\n",
      "episode: 77200 loss 0.00044671661453321576\n",
      "episode: 77300 loss 0.0017748732352629304\n",
      "episode: 77400 loss 0.0014577662805095315\n",
      "episode: 77500 loss 0.0032309480011463165\n",
      "episode: 77600 loss 0.0018548619700595737\n",
      "episode: 77700 loss 0.0010283131850883365\n",
      "episode: 78300 loss 0.0008817456546239555\n",
      "episode: 78400 loss 0.0035164623986929655\n",
      "episode: 78500 loss 0.0072654299437999725\n",
      "episode: 78600 loss 0.003220145357772708\n",
      "episode: 78700 loss 0.0018989662639796734\n",
      "episode: 78800 loss 0.0026351280976086855\n",
      "episode: 78900 loss 0.008013559505343437\n",
      "episode: 79000 loss 0.001986086368560791\n",
      "episode: 79100 loss 0.0054324353113770485\n",
      "episode: 79200 loss 0.003764962311834097\n",
      "episode: 79300 loss 0.001960544614121318\n",
      "episode: 79400 loss 0.00437312014400959\n",
      "episode: 79500 loss 0.0021023894660174847\n",
      "episode: 79600 loss 0.0012382786953821778\n",
      "episode: 79700 loss 0.0006949858507141471\n",
      "episode: 79800 loss 0.004593973979353905\n",
      "episode: 79900 loss 0.007476326078176498\n",
      "episode: 80000 loss 0.002804936608299613\n",
      "Testing...\n",
      "test accuracy: 0.974\n",
      "episode: 80100 loss 0.008042318746447563\n",
      "episode: 80200 loss 0.006706973537802696\n",
      "episode: 80300 loss 0.0020817890763282776\n",
      "episode: 80400 loss 0.004111678805202246\n",
      "episode: 80500 loss 0.003691216465085745\n",
      "episode: 80600 loss 0.001262564561329782\n",
      "episode: 80700 loss 0.0032386635430157185\n",
      "episode: 80800 loss 0.0017573905643075705\n",
      "episode: 80900 loss 0.0012753872433677316\n",
      "episode: 81000 loss 0.005683876108378172\n",
      "episode: 81100 loss 0.003298455383628607\n",
      "episode: 81200 loss 0.0022384864278137684\n",
      "episode: 81300 loss 0.0050408681854605675\n",
      "episode: 81400 loss 0.004694975446909666\n",
      "episode: 81500 loss 0.003282794263213873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 81600 loss 0.0014361522626131773\n",
      "episode: 81700 loss 0.0039770039729774\n",
      "episode: 81800 loss 0.002418926451355219\n",
      "episode: 81900 loss 0.0028946769889444113\n",
      "episode: 82500 loss 0.002801464404910803\n",
      "episode: 82600 loss 0.0013052364811301231\n",
      "episode: 82700 loss 0.005143740680068731\n",
      "episode: 82800 loss 0.002751007443293929\n",
      "episode: 82900 loss 0.0019135529873892665\n",
      "episode: 83000 loss 0.0004656213568523526\n",
      "episode: 83100 loss 0.003803742816671729\n",
      "episode: 83200 loss 0.0006026354967616498\n",
      "episode: 83300 loss 0.0025244574062526226\n",
      "episode: 83400 loss 0.0071932231076061726\n",
      "episode: 83500 loss 0.002729029394686222\n",
      "episode: 83600 loss 0.0033772208262234926\n",
      "episode: 83700 loss 0.002214462962001562\n",
      "episode: 83800 loss 0.0010392317781224847\n",
      "episode: 83900 loss 0.0026416543405503035\n",
      "episode: 84000 loss 0.0009444665047340095\n",
      "episode: 84100 loss 0.0014641335001215339\n",
      "episode: 84200 loss 0.003792133880779147\n",
      "episode: 84300 loss 0.0015422403812408447\n",
      "episode: 84400 loss 0.002560781082138419\n",
      "episode: 84500 loss 0.005420596804469824\n",
      "episode: 84600 loss 0.0015362200792878866\n",
      "episode: 84700 loss 0.001487341127358377\n",
      "episode: 84800 loss 0.003678907873108983\n",
      "episode: 84900 loss 0.004640576429665089\n",
      "episode: 85000 loss 0.001983910333365202\n",
      "Testing...\n",
      "test accuracy: 0.9731000000000001\n",
      "episode: 85100 loss 0.004504296462982893\n",
      "episode: 85200 loss 0.006377751938998699\n",
      "episode: 85300 loss 0.0020753040444105864\n",
      "episode: 85400 loss 0.00616486556828022\n",
      "episode: 85500 loss 0.0028557449113577604\n",
      "episode: 86100 loss 0.0031329914927482605\n",
      "episode: 86200 loss 0.001958118751645088\n",
      "episode: 86300 loss 0.0017805042443796992\n",
      "episode: 86400 loss 0.0031649274751544\n",
      "episode: 86500 loss 0.004678688012063503\n",
      "episode: 86600 loss 0.0015107850776985288\n",
      "episode: 86700 loss 0.0015618838369846344\n",
      "episode: 86800 loss 0.0011948124738410115\n",
      "episode: 86900 loss 0.0019604049157351255\n",
      "episode: 87000 loss 0.006478403694927692\n",
      "episode: 87100 loss 0.004364853259176016\n",
      "episode: 87200 loss 0.0024199143517762423\n",
      "episode: 87300 loss 0.002888184040784836\n",
      "episode: 87400 loss 0.003429579548537731\n",
      "episode: 87500 loss 0.0014179825084283948\n",
      "episode: 87600 loss 0.002845213282853365\n",
      "episode: 87700 loss 0.00206097518093884\n",
      "episode: 87800 loss 0.005531755276024342\n",
      "episode: 87900 loss 0.003386756870895624\n",
      "episode: 88000 loss 0.0032625128515064716\n",
      "episode: 88100 loss 0.0021087941713631153\n",
      "episode: 88200 loss 0.004422807600349188\n",
      "episode: 88300 loss 0.0018546066712588072\n",
      "episode: 88400 loss 0.004108778666704893\n",
      "episode: 88500 loss 0.002535187639296055\n",
      "episode: 88600 loss 0.0030393777415156364\n",
      "episode: 89200 loss 0.0010205705184489489\n",
      "episode: 89300 loss 0.003327392740175128\n",
      "episode: 89400 loss 0.0039221555925905704\n",
      "episode: 89500 loss 0.002044535707682371\n",
      "episode: 89600 loss 0.004843936767429113\n",
      "episode: 89700 loss 0.0020524265710264444\n",
      "episode: 89800 loss 0.0018539339071139693\n",
      "episode: 89900 loss 0.0017463286640122533\n",
      "episode: 90000 loss 0.002373978728428483\n",
      "Testing...\n",
      "test accuracy: 0.97625\n",
      "save networks for episode: 89999\n",
      "episode: 90100 loss 0.0024611959233880043\n",
      "episode: 90200 loss 0.0022294961381703615\n",
      "episode: 90300 loss 0.0013648899039253592\n",
      "episode: 90400 loss 0.0027395854704082012\n",
      "episode: 90500 loss 0.002925489330664277\n",
      "episode: 90600 loss 0.0017787351971492171\n",
      "episode: 90700 loss 0.0021678581833839417\n",
      "episode: 90800 loss 0.00680937385186553\n",
      "episode: 90900 loss 0.001711032702587545\n",
      "episode: 91000 loss 0.002100863493978977\n",
      "episode: 91100 loss 0.0021608425304293633\n",
      "episode: 91200 loss 0.00658009946346283\n",
      "episode: 91300 loss 0.001669125515036285\n",
      "episode: 91400 loss 0.0019472409039735794\n",
      "episode: 91500 loss 0.002354510361328721\n",
      "episode: 91600 loss 0.0012658738996833563\n",
      "episode: 91700 loss 0.0020721021573990583\n",
      "episode: 91800 loss 0.0014984728768467903\n",
      "episode: 91900 loss 0.0023272924590855837\n",
      "episode: 92000 loss 0.00254165381193161\n",
      "episode: 92100 loss 0.0009197588078677654\n",
      "episode: 92200 loss 0.004235278349369764\n",
      "episode: 92300 loss 0.0014948775060474873\n",
      "episode: 92400 loss 0.0016289533814415336\n",
      "episode: 92500 loss 0.0022267920430749655\n",
      "episode: 92600 loss 0.003094262210652232\n",
      "episode: 92700 loss 0.004780821036547422\n",
      "episode: 92800 loss 0.0032119101379066706\n",
      "episode: 92900 loss 0.001854219939559698\n",
      "episode: 93000 loss 0.003671282669529319\n",
      "episode: 93100 loss 0.001693545375019312\n",
      "episode: 93200 loss 0.0009122405317611992\n",
      "episode: 93300 loss 0.0011856125202029943\n",
      "episode: 93400 loss 0.002094138180837035\n",
      "episode: 93500 loss 0.0027259208727627993\n",
      "episode: 93600 loss 0.0049884989857673645\n",
      "episode: 93700 loss 0.001761915977112949\n",
      "episode: 93800 loss 0.002259255386888981\n",
      "episode: 93900 loss 0.004076529759913683\n",
      "episode: 94000 loss 0.0010145819978788495\n",
      "episode: 94100 loss 0.0006294059567153454\n",
      "episode: 94200 loss 0.006791139021515846\n",
      "episode: 94300 loss 0.0012856331886723638\n",
      "episode: 94400 loss 0.001316979993134737\n",
      "episode: 94500 loss 0.001346339238807559\n",
      "episode: 94600 loss 0.0014146737521514297\n",
      "episode: 94700 loss 0.0025863514747470617\n",
      "episode: 94800 loss 0.002904272638261318\n",
      "episode: 94900 loss 0.0026043723337352276\n",
      "episode: 95000 loss 0.001071431557647884\n",
      "Testing...\n",
      "test accuracy: 0.97565\n",
      "episode: 95100 loss 0.005264551844447851\n",
      "episode: 95200 loss 0.004072523210197687\n",
      "episode: 95300 loss 0.0025324637535959482\n",
      "episode: 95400 loss 0.0032118652015924454\n",
      "episode: 95500 loss 0.0026655455585569143\n",
      "episode: 95600 loss 0.0044975620694458485\n",
      "episode: 95700 loss 0.000955053314100951\n",
      "episode: 95800 loss 0.007666939403861761\n",
      "episode: 95900 loss 0.0019806171767413616\n",
      "episode: 96000 loss 0.004009331110864878\n",
      "episode: 96100 loss 0.0018903766758739948\n",
      "episode: 96200 loss 0.0037677783984690905\n",
      "episode: 96300 loss 0.0057489606551826\n",
      "episode: 96400 loss 0.0008712275302968919\n",
      "episode: 96500 loss 0.004611228127032518\n",
      "episode: 96600 loss 0.0011674908455461264\n",
      "episode: 97100 loss 0.0021233647130429745\n",
      "episode: 97200 loss 0.0037674393970519304\n",
      "episode: 97300 loss 0.0010400997707620263\n",
      "episode: 97400 loss 0.005400152876973152\n",
      "episode: 97500 loss 0.004735117312520742\n",
      "episode: 97600 loss 0.003470740746706724\n",
      "episode: 97700 loss 0.004605470225214958\n",
      "episode: 97800 loss 0.003670463338494301\n",
      "episode: 97900 loss 0.0058033461682498455\n",
      "episode: 98000 loss 0.0029480403754860163\n",
      "episode: 98100 loss 0.004456051159650087\n",
      "episode: 98200 loss 0.0031136665493249893\n",
      "episode: 98300 loss 0.005352813750505447\n",
      "episode: 98400 loss 0.002497242297977209\n",
      "episode: 98500 loss 0.0014269613893702626\n",
      "episode: 98600 loss 0.002003082539886236\n",
      "episode: 98700 loss 0.004726418759673834\n",
      "episode: 98800 loss 0.006309431046247482\n",
      "episode: 98900 loss 0.0011372379958629608\n",
      "episode: 99000 loss 0.006419972516596317\n",
      "episode: 99100 loss 0.0009392859064973891\n",
      "episode: 99200 loss 0.0015728161670267582\n",
      "episode: 99300 loss 0.000946100044529885\n",
      "episode: 99400 loss 0.005609503481537104\n",
      "episode: 99500 loss 0.003791519207879901\n",
      "episode: 99600 loss 0.0034576645120978355\n",
      "episode: 99700 loss 0.0015206326497718692\n",
      "episode: 99800 loss 0.003011305583640933\n",
      "episode: 99900 loss 0.0003131779085379094\n",
      "episode: 100000 loss 0.0042845760472118855\n",
      "Testing...\n",
      "test accuracy: 0.97445\n",
      "episode: 100100 loss 0.0044657159596681595\n",
      "episode: 100200 loss 0.0022886137012392282\n",
      "episode: 100300 loss 0.0015476952539756894\n",
      "episode: 100400 loss 0.0006047591450624168\n",
      "episode: 100500 loss 0.004398714285343885\n",
      "episode: 100600 loss 0.0013105456018820405\n",
      "episode: 100700 loss 0.001587378210388124\n",
      "episode: 100800 loss 0.0011639446020126343\n",
      "episode: 100900 loss 0.0006338594248518348\n",
      "episode: 101000 loss 0.0021343687549233437\n",
      "episode: 101100 loss 0.0008073042845353484\n",
      "episode: 101200 loss 0.006035164929926395\n",
      "episode: 101300 loss 0.0015687202103435993\n",
      "episode: 101400 loss 0.0010899245971813798\n",
      "episode: 101500 loss 0.0034157440531998873\n",
      "episode: 101600 loss 0.00606911163777113\n",
      "episode: 101700 loss 0.0015001685824245214\n",
      "episode: 101800 loss 0.004132259637117386\n",
      "episode: 101900 loss 0.0007647676975466311\n",
      "episode: 102000 loss 0.012007747776806355\n",
      "episode: 102500 loss 0.00032072249450720847\n",
      "episode: 102600 loss 0.0013667764142155647\n",
      "episode: 102700 loss 0.0016497340984642506\n",
      "episode: 102800 loss 0.004077430348843336\n",
      "episode: 102900 loss 0.0016255324007943273\n",
      "episode: 103000 loss 0.0027850051410496235\n",
      "episode: 103100 loss 0.0013123912503942847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 103200 loss 0.005703277885913849\n",
      "episode: 103300 loss 0.0033875831868499517\n",
      "episode: 103400 loss 0.001194996410049498\n",
      "episode: 103500 loss 0.006744151469320059\n",
      "episode: 103600 loss 0.007216408848762512\n",
      "episode: 103700 loss 0.0018985128263011575\n",
      "episode: 103800 loss 0.0011968291364610195\n",
      "episode: 103900 loss 0.002436029724776745\n",
      "episode: 104000 loss 0.0022884949576109648\n",
      "episode: 104100 loss 0.004296845756471157\n",
      "episode: 104200 loss 0.0011545394081622362\n",
      "episode: 104300 loss 0.0005619779694825411\n",
      "episode: 104400 loss 0.0031308578327298164\n",
      "episode: 104500 loss 0.001549157197587192\n",
      "episode: 104600 loss 0.001918294234201312\n",
      "episode: 104700 loss 0.0036254122387617826\n",
      "episode: 104800 loss 0.0016760444268584251\n",
      "episode: 104900 loss 0.001190502429381013\n",
      "episode: 105000 loss 0.0009645461686886847\n",
      "Testing...\n",
      "test accuracy: 0.97665\n",
      "save networks for episode: 104999\n",
      "episode: 105100 loss 0.003252337919548154\n",
      "episode: 105200 loss 0.0036457707174122334\n",
      "episode: 105300 loss 0.0030024282168596983\n",
      "episode: 105400 loss 0.0012194359442219138\n",
      "episode: 105500 loss 0.002018955070525408\n",
      "episode: 105600 loss 0.002639158396050334\n",
      "episode: 105700 loss 0.005256996024399996\n",
      "episode: 105800 loss 0.0026130364276468754\n",
      "episode: 105900 loss 0.0014889518497511744\n",
      "episode: 106000 loss 0.0021326751448214054\n",
      "episode: 106100 loss 0.0018765619024634361\n",
      "episode: 106200 loss 0.0027827925514429808\n",
      "episode: 106300 loss 0.002493551466614008\n",
      "episode: 106400 loss 0.003469062503427267\n",
      "episode: 107000 loss 0.0014239181764423847\n",
      "episode: 107100 loss 0.00034003533073700964\n",
      "episode: 107200 loss 0.005004529375582933\n",
      "episode: 107300 loss 0.0023532817140221596\n",
      "episode: 107400 loss 0.001095596351660788\n",
      "episode: 107500 loss 0.0018178669270128012\n",
      "episode: 107600 loss 0.0013507372932508588\n",
      "episode: 107700 loss 0.001064349664375186\n",
      "episode: 107800 loss 0.0010616325307637453\n",
      "episode: 107900 loss 0.0008638867293484509\n",
      "episode: 108000 loss 0.004624879918992519\n",
      "episode: 108100 loss 0.0010646707378327847\n",
      "episode: 108200 loss 0.003459235420450568\n",
      "episode: 108300 loss 0.0012327987933531404\n",
      "episode: 108400 loss 0.0010172887705266476\n",
      "episode: 108500 loss 0.0037227191496640444\n",
      "episode: 108600 loss 0.0026382512878626585\n",
      "episode: 108700 loss 0.005521797109395266\n",
      "episode: 108800 loss 0.0027843040879815817\n",
      "episode: 108900 loss 0.001458583166822791\n",
      "episode: 109000 loss 0.002947947010397911\n",
      "episode: 109100 loss 0.0012047046329826117\n",
      "episode: 109200 loss 0.00521565368399024\n",
      "episode: 109300 loss 0.0054895877838134766\n",
      "episode: 109400 loss 0.002043078187853098\n",
      "episode: 109500 loss 0.002532145706936717\n",
      "episode: 109600 loss 0.0014317040331661701\n",
      "episode: 109700 loss 0.0016430815448984504\n",
      "episode: 109800 loss 0.00204253732226789\n",
      "episode: 109900 loss 0.0033934006933122873\n",
      "episode: 110000 loss 0.0024970611557364464\n",
      "Testing...\n",
      "test accuracy: 0.975\n",
      "episode: 110100 loss 0.003539556870236993\n",
      "episode: 110200 loss 0.0006474921829067171\n",
      "episode: 110300 loss 0.0016965012764558196\n",
      "episode: 110400 loss 0.0023723579943180084\n",
      "episode: 110500 loss 0.00026871723821386695\n",
      "episode: 110600 loss 0.006881894078105688\n",
      "episode: 110700 loss 0.0011260663159191608\n",
      "episode: 110800 loss 0.002284092828631401\n",
      "episode: 110900 loss 0.005653440486639738\n",
      "episode: 111000 loss 0.004370486829429865\n",
      "episode: 111100 loss 0.00039564791950397193\n",
      "episode: 111200 loss 0.0021480533760041\n",
      "episode: 111300 loss 0.0007423735805787146\n",
      "episode: 111400 loss 0.0031788325868546963\n",
      "episode: 111500 loss 0.002788315759971738\n",
      "episode: 111600 loss 0.001840017270296812\n",
      "episode: 111700 loss 0.004560417030006647\n",
      "episode: 111800 loss 0.0016457894816994667\n",
      "episode: 111900 loss 0.002582354238256812\n",
      "episode: 112000 loss 0.0011997821275144815\n",
      "episode: 112100 loss 0.0024690607096999884\n",
      "episode: 112200 loss 0.0028071869164705276\n",
      "episode: 112300 loss 0.001981558511033654\n",
      "episode: 112400 loss 0.002408834407106042\n",
      "episode: 112500 loss 0.0007915114983916283\n",
      "episode: 112600 loss 0.005805963650345802\n",
      "episode: 112700 loss 0.0013912273570895195\n",
      "episode: 112800 loss 0.0038233809173107147\n",
      "episode: 112900 loss 0.0017576721729710698\n",
      "episode: 113000 loss 0.001125345821492374\n",
      "episode: 113100 loss 0.0036008816678076982\n",
      "episode: 113200 loss 0.0027179259341210127\n",
      "episode: 113300 loss 0.0009425497846677899\n",
      "episode: 113400 loss 0.0021801029797643423\n",
      "episode: 113500 loss 0.002266217488795519\n",
      "episode: 113600 loss 0.0011996481334790587\n",
      "episode: 113700 loss 0.0034731063060462475\n",
      "episode: 114400 loss 0.0020919640082865953\n",
      "episode: 114500 loss 0.0022352205123752356\n",
      "episode: 114600 loss 0.0010261606657877564\n",
      "episode: 114700 loss 0.0037627886049449444\n",
      "episode: 114800 loss 0.0007842194754630327\n",
      "episode: 114900 loss 0.0036658619064837694\n",
      "episode: 115000 loss 0.006035827100276947\n",
      "Testing...\n",
      "test accuracy: 0.9765\n",
      "episode: 115100 loss 0.0023597273975610733\n",
      "episode: 115200 loss 0.0011368327541276813\n",
      "episode: 115300 loss 0.005347283557057381\n",
      "episode: 115400 loss 0.0013940202770754695\n",
      "episode: 115500 loss 0.004335996229201555\n",
      "episode: 115600 loss 0.0016209435416385531\n",
      "episode: 115700 loss 0.006613597739487886\n",
      "episode: 115800 loss 0.0003229817084502429\n",
      "episode: 115900 loss 0.003449529642239213\n",
      "episode: 116000 loss 0.0018732267199084163\n",
      "episode: 116100 loss 0.000675499439239502\n",
      "episode: 116200 loss 0.005918263457715511\n",
      "episode: 116300 loss 0.00248252646997571\n",
      "episode: 116400 loss 0.0015869135968387127\n",
      "episode: 116500 loss 0.001960687804967165\n",
      "episode: 116600 loss 0.0016719393897801638\n",
      "episode: 116700 loss 0.0022781246807426214\n",
      "episode: 116800 loss 0.0038176928646862507\n",
      "episode: 116900 loss 0.006071626674383879\n",
      "episode: 117000 loss 0.001751721603795886\n",
      "episode: 117100 loss 0.0015626171370968223\n",
      "episode: 117200 loss 0.0019451214466243982\n",
      "episode: 117300 loss 0.00153003865852952\n",
      "episode: 117400 loss 0.001116601750254631\n",
      "episode: 117500 loss 0.0034629711881279945\n",
      "episode: 117600 loss 0.0016102672088891268\n",
      "episode: 117700 loss 0.0015617641620337963\n",
      "episode: 117800 loss 0.004108026623725891\n",
      "episode: 117900 loss 0.0012188489781692624\n",
      "episode: 118000 loss 0.003477552207186818\n",
      "episode: 118100 loss 0.003712026635184884\n",
      "episode: 118200 loss 0.002291264943778515\n",
      "episode: 118300 loss 0.0030374585185199976\n",
      "episode: 118400 loss 0.0016966304974630475\n",
      "episode: 118500 loss 0.002300550928339362\n",
      "episode: 118600 loss 0.0005478638340719044\n",
      "episode: 118700 loss 0.0010659650433808565\n",
      "episode: 118800 loss 0.0008434347109869123\n",
      "episode: 118900 loss 0.0017651122761890292\n",
      "episode: 119000 loss 0.0006359738763421774\n",
      "episode: 119100 loss 0.0024159245658665895\n",
      "episode: 119200 loss 0.0037991339340806007\n",
      "episode: 119300 loss 0.003599821822717786\n",
      "episode: 119400 loss 0.0027618305757641792\n",
      "episode: 119500 loss 0.00024896510876715183\n",
      "episode: 119600 loss 0.0027984173502773046\n",
      "episode: 119700 loss 0.004446062725037336\n",
      "episode: 119800 loss 0.002150918822735548\n",
      "episode: 119900 loss 0.00208137440495193\n",
      "episode: 120000 loss 0.006755792070180178\n",
      "Testing...\n",
      "test accuracy: 0.9759500000000001\n",
      "episode: 120100 loss 0.0038961509708315134\n",
      "episode: 120200 loss 0.0013252176577225327\n",
      "episode: 120300 loss 0.0012402374995872378\n",
      "episode: 120400 loss 0.003393034217879176\n",
      "episode: 120500 loss 0.0050382353365421295\n",
      "episode: 120600 loss 0.006656460464000702\n",
      "episode: 120700 loss 0.004079851787537336\n",
      "episode: 120800 loss 0.002826560754328966\n",
      "episode: 120900 loss 0.0004784820193890482\n",
      "episode: 121000 loss 0.0013497405452653766\n",
      "episode: 121100 loss 0.000748999766074121\n",
      "episode: 121200 loss 0.001208354253321886\n",
      "episode: 121300 loss 0.0014507381711155176\n",
      "episode: 121400 loss 0.002398878335952759\n",
      "episode: 121500 loss 0.004487697966396809\n",
      "episode: 121600 loss 0.002588537521660328\n",
      "episode: 121700 loss 0.0007356498972512782\n",
      "episode: 121800 loss 0.004079920705407858\n",
      "episode: 121900 loss 0.0036512683145701885\n",
      "episode: 122000 loss 0.002413640497252345\n",
      "episode: 122100 loss 0.001726606860756874\n",
      "episode: 122200 loss 0.000389996130252257\n",
      "episode: 122300 loss 0.002741646720096469\n",
      "episode: 122400 loss 0.0018248313572257757\n",
      "episode: 122500 loss 0.004107820801436901\n",
      "episode: 122600 loss 0.003605735255405307\n",
      "episode: 122700 loss 0.0024748975411057472\n",
      "episode: 122800 loss 0.005821334198117256\n",
      "episode: 122900 loss 0.00013855929137207568\n",
      "episode: 123000 loss 0.0023917043581604958\n",
      "episode: 123100 loss 0.0006804157746955752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 123200 loss 0.0017005640547722578\n",
      "episode: 123300 loss 0.0016097989864647388\n",
      "episode: 123400 loss 0.0021449585910886526\n",
      "episode: 123500 loss 0.0032073736656457186\n",
      "episode: 123600 loss 0.001743695349432528\n",
      "episode: 123700 loss 0.0014129497576504946\n",
      "episode: 123800 loss 0.0014133434742689133\n",
      "episode: 123900 loss 0.003091234713792801\n",
      "episode: 124000 loss 0.004821952898055315\n",
      "episode: 124100 loss 0.0017952495254576206\n",
      "episode: 124200 loss 0.0024402132257819176\n",
      "episode: 124300 loss 0.003136557526886463\n",
      "episode: 124400 loss 0.0026673278771340847\n",
      "episode: 124500 loss 0.0011147217592224479\n",
      "episode: 124600 loss 0.003745941910892725\n",
      "episode: 124700 loss 0.0012038099812343717\n",
      "episode: 124800 loss 0.0014182967133820057\n",
      "episode: 124900 loss 0.0009939788142219186\n",
      "episode: 125000 loss 0.0031475042924284935\n",
      "Testing...\n",
      "test accuracy: 0.97485\n",
      "episode: 125100 loss 0.0008845809497870505\n",
      "episode: 125200 loss 0.005083675961941481\n",
      "episode: 125300 loss 0.0008472389308735728\n",
      "episode: 125400 loss 0.001889299019239843\n",
      "episode: 125500 loss 0.0042961654253304005\n",
      "episode: 125600 loss 0.0006919446168467402\n",
      "episode: 125700 loss 0.0018524768529459834\n",
      "episode: 125800 loss 0.0024308334104716778\n",
      "episode: 125900 loss 0.006939963903278112\n",
      "episode: 126000 loss 0.0033458974212408066\n",
      "episode: 126100 loss 0.004716833122074604\n",
      "episode: 126200 loss 0.0005705600487999618\n",
      "episode: 126300 loss 0.002264570677652955\n",
      "episode: 126400 loss 0.004937606863677502\n",
      "episode: 126500 loss 0.0017938825767487288\n",
      "episode: 126600 loss 0.001857092254795134\n",
      "episode: 126700 loss 0.0017379039200022817\n",
      "episode: 126800 loss 0.0004160762473475188\n",
      "episode: 126900 loss 0.002447447506710887\n",
      "episode: 127000 loss 0.0013409547973424196\n",
      "episode: 127100 loss 0.0011901127872988582\n",
      "episode: 127200 loss 0.0030669900588691235\n",
      "episode: 127300 loss 0.004389001522213221\n",
      "episode: 127400 loss 0.0016460843617096543\n",
      "episode: 127500 loss 0.0010927853872999549\n",
      "episode: 127600 loss 0.0031047717202454805\n",
      "episode: 127700 loss 0.0012367672752588987\n",
      "episode: 127800 loss 0.0009482365567237139\n",
      "episode: 127900 loss 0.002678800607100129\n",
      "episode: 128000 loss 0.0019977805204689503\n",
      "episode: 128100 loss 0.0009816158562898636\n",
      "episode: 128200 loss 0.002090295311063528\n",
      "episode: 128300 loss 0.0004946581902913749\n",
      "episode: 128400 loss 0.00345116900280118\n",
      "episode: 128500 loss 0.005179066676646471\n",
      "episode: 128600 loss 0.005462972912937403\n",
      "episode: 128700 loss 0.0023231215309351683\n",
      "episode: 128800 loss 0.0024621898774057627\n",
      "episode: 128900 loss 0.004786777775734663\n",
      "episode: 129000 loss 0.0015803532442077994\n",
      "episode: 129100 loss 0.0029756720177829266\n",
      "episode: 129200 loss 0.00018891136278398335\n",
      "episode: 129300 loss 0.0009078794391825795\n",
      "episode: 129400 loss 0.005674419458955526\n",
      "episode: 129500 loss 0.0010728542692959309\n",
      "episode: 129600 loss 0.0018881837604567409\n",
      "episode: 129700 loss 0.003091416321694851\n",
      "episode: 129800 loss 0.0038780784234404564\n",
      "episode: 129900 loss 0.0009144626674242318\n",
      "episode: 130000 loss 0.002096880692988634\n",
      "Testing...\n",
      "test accuracy: 0.9753999999999999\n",
      "episode: 130100 loss 0.003369350451976061\n",
      "episode: 130200 loss 0.0016686824383214116\n",
      "episode: 130300 loss 0.006168274208903313\n",
      "episode: 130400 loss 0.00044518179493024945\n",
      "episode: 130500 loss 0.004517889115959406\n",
      "episode: 130600 loss 0.0012424198212102056\n",
      "episode: 130700 loss 0.0011744974181056023\n",
      "episode: 130800 loss 0.0004731357330456376\n",
      "episode: 130900 loss 0.005685361102223396\n",
      "episode: 131000 loss 0.001959781860932708\n",
      "episode: 131100 loss 0.0031915465369820595\n",
      "episode: 131200 loss 0.0010650879703462124\n",
      "episode: 131300 loss 0.0039373040199279785\n",
      "episode: 131400 loss 0.0016790659865364432\n",
      "episode: 131500 loss 0.003893569577485323\n",
      "episode: 131600 loss 0.002076540607959032\n",
      "episode: 131700 loss 0.0023327693343162537\n",
      "episode: 131800 loss 0.002959295641630888\n",
      "episode: 131900 loss 0.0016228328458964825\n",
      "episode: 132000 loss 0.00186357949860394\n",
      "episode: 132100 loss 0.0013052149442955852\n",
      "episode: 132200 loss 0.001202177256345749\n",
      "episode: 132300 loss 0.004018447361886501\n",
      "episode: 132400 loss 0.0033091744408011436\n",
      "episode: 132500 loss 0.0011211882811039686\n",
      "episode: 132600 loss 0.0013440167531371117\n",
      "episode: 132700 loss 0.0023617036640644073\n",
      "episode: 132800 loss 0.0022492664866149426\n",
      "episode: 132900 loss 0.00369342602789402\n",
      "episode: 133000 loss 0.0021625400986522436\n",
      "episode: 133100 loss 0.0006915189442224801\n",
      "episode: 133200 loss 0.004208642523735762\n",
      "episode: 133300 loss 0.0020391782745718956\n",
      "episode: 133400 loss 0.004681174177676439\n",
      "episode: 133500 loss 0.0011345554376021028\n",
      "episode: 133600 loss 0.0014170113718137145\n",
      "episode: 133700 loss 0.0039870766922831535\n",
      "episode: 133800 loss 0.0012886237818747759\n",
      "episode: 133900 loss 0.0015871261712163687\n",
      "episode: 134000 loss 0.0016592898173257709\n",
      "episode: 134100 loss 0.005367060657590628\n",
      "episode: 134200 loss 0.001722060376778245\n",
      "episode: 134300 loss 0.007037345785647631\n",
      "episode: 134400 loss 0.001571544911712408\n",
      "episode: 134500 loss 0.004603829234838486\n",
      "episode: 134600 loss 0.004236665088683367\n",
      "episode: 134700 loss 0.0026720643509179354\n",
      "episode: 134800 loss 0.0019265450537204742\n",
      "episode: 134900 loss 0.0028163266833871603\n",
      "episode: 135000 loss 0.0021146144717931747\n",
      "Testing...\n",
      "test accuracy: 0.97585\n",
      "episode: 135100 loss 0.0027323805261403322\n",
      "episode: 135200 loss 0.003167225979268551\n",
      "episode: 135300 loss 0.0004457487375475466\n",
      "episode: 135400 loss 0.0022701979614794254\n",
      "episode: 135500 loss 0.001940048416145146\n",
      "episode: 135600 loss 0.001363891176879406\n",
      "episode: 135700 loss 0.0009223549859598279\n",
      "episode: 135800 loss 0.00037766070454381406\n",
      "episode: 135900 loss 0.0017865803092718124\n",
      "episode: 136000 loss 0.001522320439107716\n",
      "episode: 136100 loss 0.0012656638864427805\n",
      "episode: 136200 loss 0.0017025453271344304\n",
      "episode: 136300 loss 0.0018477668054401875\n",
      "episode: 136400 loss 0.003219477366656065\n",
      "episode: 136500 loss 0.00160352629609406\n",
      "episode: 136600 loss 0.003068228019401431\n",
      "episode: 136700 loss 0.001753200776875019\n",
      "episode: 136800 loss 0.0010807957733049989\n",
      "episode: 136900 loss 0.000958491291385144\n",
      "episode: 137000 loss 0.004125609528273344\n",
      "episode: 137100 loss 0.0019140086369588971\n",
      "episode: 137200 loss 0.0010417047888040543\n",
      "episode: 137300 loss 0.002689958084374666\n",
      "episode: 137400 loss 0.0019066112581640482\n",
      "episode: 137500 loss 0.002334213349968195\n",
      "episode: 137600 loss 0.00269063632003963\n",
      "episode: 137700 loss 0.0010409352835267782\n",
      "episode: 137800 loss 0.005542886909097433\n",
      "episode: 137900 loss 0.0022139307111501694\n",
      "episode: 138000 loss 0.001816630712710321\n",
      "episode: 138100 loss 0.003394810715690255\n",
      "episode: 138200 loss 0.0069119855761528015\n",
      "episode: 138300 loss 0.0007692916551604867\n",
      "episode: 138400 loss 0.0022301494609564543\n",
      "episode: 138500 loss 0.0033982458990067244\n",
      "episode: 138600 loss 0.003620068309828639\n",
      "episode: 138700 loss 0.0019311356591060758\n",
      "episode: 138800 loss 0.0020855232141911983\n",
      "episode: 138900 loss 0.002087915549054742\n",
      "episode: 139000 loss 0.004165062215179205\n",
      "episode: 139100 loss 0.0019581164233386517\n",
      "episode: 139200 loss 0.0072880401276052\n",
      "episode: 139300 loss 0.003311455948278308\n",
      "episode: 139400 loss 0.004361329134553671\n",
      "episode: 139500 loss 0.0009026850457303226\n",
      "episode: 139600 loss 0.000377210060833022\n",
      "episode: 139700 loss 0.004450647160410881\n",
      "episode: 139800 loss 0.0010222058044746518\n",
      "episode: 139900 loss 0.0005802708910778165\n",
      "episode: 140000 loss 0.0030744033865630627\n",
      "Testing...\n",
      "test accuracy: 0.97635\n",
      "episode: 140100 loss 0.0015686138067394495\n",
      "episode: 140200 loss 0.005008942447602749\n",
      "episode: 140300 loss 0.002776956418529153\n",
      "episode: 140400 loss 0.003449193900451064\n",
      "episode: 140500 loss 0.0016833929112181067\n",
      "episode: 140600 loss 0.0008240957977250218\n",
      "episode: 140700 loss 0.0004397820739541203\n",
      "episode: 140800 loss 0.0011667184298858047\n",
      "episode: 140900 loss 0.0013774114195257425\n",
      "episode: 141000 loss 0.0013021253980696201\n",
      "episode: 141100 loss 0.0058647519908845425\n",
      "episode: 141200 loss 0.001938503934070468\n",
      "episode: 141300 loss 0.0013259745901450515\n",
      "episode: 141400 loss 0.0022367904894053936\n",
      "episode: 141500 loss 0.0022940326016396284\n",
      "episode: 141600 loss 0.0005296055460348725\n",
      "episode: 141700 loss 0.004687350708991289\n",
      "episode: 141800 loss 0.003494576085358858\n",
      "episode: 141900 loss 0.0008326323004439473\n",
      "episode: 142000 loss 0.0014912413898855448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 142100 loss 0.002586107701063156\n",
      "episode: 142200 loss 0.0019384078914299607\n",
      "episode: 142300 loss 0.0017204718897119164\n",
      "episode: 142400 loss 0.003759362269192934\n",
      "episode: 142500 loss 0.005493117496371269\n",
      "episode: 142600 loss 0.0017122389981523156\n",
      "episode: 142700 loss 0.004199619870632887\n",
      "episode: 142800 loss 0.0024060350842773914\n",
      "episode: 142900 loss 0.00839728768914938\n",
      "episode: 143000 loss 0.001638691290281713\n",
      "episode: 143100 loss 0.0018368426244705915\n",
      "episode: 143200 loss 0.007329759653657675\n",
      "episode: 143300 loss 0.0004225803422741592\n",
      "episode: 143400 loss 0.007474385667592287\n",
      "episode: 143500 loss 0.0027813741471618414\n",
      "episode: 143600 loss 0.004363414365798235\n",
      "episode: 143700 loss 0.0014045890420675278\n",
      "episode: 143800 loss 0.0013234734069555998\n",
      "episode: 143900 loss 0.008170398883521557\n",
      "episode: 144000 loss 0.0015117865987122059\n",
      "episode: 144100 loss 0.0006318872910924256\n",
      "episode: 144200 loss 0.001698851934634149\n",
      "episode: 144300 loss 0.004957057069987059\n",
      "episode: 144400 loss 0.001104410970583558\n",
      "episode: 144500 loss 0.0005813142633996904\n",
      "episode: 144600 loss 0.005027150269597769\n",
      "episode: 144700 loss 0.0032854306045919657\n",
      "episode: 144800 loss 0.0018359206151217222\n",
      "episode: 144900 loss 0.0006681982195004821\n",
      "episode: 145000 loss 0.0011222431203350425\n",
      "Testing...\n",
      "test accuracy: 0.9755\n",
      "episode: 145100 loss 0.0009262918028980494\n",
      "episode: 145200 loss 0.002230336656793952\n",
      "episode: 145300 loss 0.0019473339198157191\n",
      "episode: 145400 loss 0.001373214996419847\n",
      "episode: 145500 loss 0.000643150182440877\n",
      "episode: 145600 loss 0.0008568062330596149\n",
      "episode: 145700 loss 0.007850848138332367\n",
      "episode: 145800 loss 0.0026641127187758684\n",
      "episode: 145900 loss 0.005486033391207457\n",
      "episode: 146000 loss 0.0034007590729743242\n",
      "episode: 146100 loss 0.0023302664048969746\n",
      "episode: 146200 loss 0.000760349037591368\n",
      "episode: 146300 loss 0.003515599761158228\n",
      "episode: 146400 loss 0.002565165050327778\n",
      "episode: 146500 loss 0.0020444211550056934\n",
      "episode: 146600 loss 0.004140836652368307\n",
      "episode: 146700 loss 0.0024473308585584164\n",
      "episode: 146800 loss 0.0031921190675348043\n",
      "episode: 146900 loss 0.00183676287997514\n",
      "episode: 147000 loss 0.0007972920429892838\n",
      "episode: 147100 loss 0.00042440270772203803\n",
      "episode: 147200 loss 0.0012354718055576086\n",
      "episode: 147300 loss 0.0006442791200242937\n",
      "episode: 147400 loss 0.0010514373425394297\n",
      "episode: 147500 loss 0.004604687914252281\n",
      "episode: 147600 loss 0.0008189366781152785\n",
      "episode: 147700 loss 0.0029672477394342422\n",
      "episode: 147800 loss 0.0027360913809388876\n",
      "episode: 147900 loss 0.0019082926446571946\n",
      "episode: 148000 loss 0.006768133491277695\n",
      "episode: 148100 loss 0.002970397239550948\n",
      "episode: 148200 loss 0.0012134943390265107\n",
      "episode: 148300 loss 0.002105727093294263\n",
      "episode: 148400 loss 0.0021202547941356897\n",
      "episode: 148500 loss 0.0036508257035166025\n",
      "episode: 148600 loss 0.0027707479894161224\n",
      "episode: 148700 loss 0.0012639096239581704\n",
      "episode: 148800 loss 0.0013941809302195907\n",
      "episode: 148900 loss 0.0011739758774638176\n",
      "episode: 149000 loss 0.002068915870040655\n",
      "episode: 149100 loss 0.004344353452324867\n",
      "episode: 149200 loss 0.0007069544517435133\n",
      "episode: 149300 loss 0.005953837186098099\n",
      "episode: 149400 loss 0.0017644704785197973\n",
      "episode: 149500 loss 0.002142953220754862\n",
      "episode: 149600 loss 0.0029639163985848427\n",
      "episode: 149700 loss 0.0031921148765832186\n",
      "episode: 149800 loss 0.007523033302277327\n",
      "episode: 149900 loss 0.0018680505454540253\n",
      "episode: 150000 loss 0.0030473177321255207\n",
      "Testing...\n",
      "test accuracy: 0.97445\n",
      "episode: 150100 loss 0.0014153036754578352\n",
      "episode: 150200 loss 0.0024531069211661816\n",
      "episode: 150300 loss 0.0038715230766683817\n",
      "episode: 150400 loss 0.005430061835795641\n",
      "episode: 150500 loss 0.0008006709977053106\n",
      "episode: 150600 loss 0.0018174552824348211\n",
      "episode: 150700 loss 0.008171005174517632\n",
      "episode: 150800 loss 0.002915194258093834\n",
      "episode: 150900 loss 0.0011214622063562274\n",
      "episode: 151000 loss 0.0016047708922997117\n",
      "episode: 151100 loss 0.0011784516973420978\n",
      "episode: 151200 loss 0.001696215127594769\n",
      "episode: 151300 loss 0.006936223246157169\n",
      "episode: 151400 loss 0.0007019785116426647\n",
      "episode: 151500 loss 0.002528903540223837\n",
      "episode: 151600 loss 0.0049994932487607\n",
      "episode: 151700 loss 0.0017086449079215527\n",
      "episode: 151800 loss 0.0026400897186249495\n",
      "episode: 151900 loss 0.005818205885589123\n",
      "episode: 152000 loss 0.001405975199304521\n",
      "episode: 152100 loss 0.0009685870609246194\n",
      "episode: 152200 loss 0.0036347273271530867\n",
      "episode: 152300 loss 0.002673923736438155\n",
      "episode: 152400 loss 0.003905888646841049\n",
      "episode: 152500 loss 0.000962373218499124\n",
      "episode: 152600 loss 0.0006825784221291542\n",
      "episode: 152700 loss 0.0017177201807498932\n",
      "episode: 152800 loss 0.0025225100107491016\n",
      "episode: 152900 loss 0.0015412564389407635\n",
      "episode: 153000 loss 0.0015474747633561492\n",
      "episode: 153100 loss 0.0009758739033713937\n",
      "episode: 153200 loss 0.0030636449810117483\n",
      "episode: 153300 loss 0.002147808438166976\n",
      "episode: 153400 loss 0.0012736222706735134\n",
      "episode: 153500 loss 0.0012843305012211204\n",
      "episode: 153600 loss 0.001592843676917255\n",
      "episode: 153700 loss 0.0006886656046845019\n",
      "episode: 153800 loss 0.0008417489007115364\n",
      "episode: 153900 loss 0.0011980080744251609\n",
      "episode: 154000 loss 0.0015148791717365384\n",
      "episode: 154100 loss 0.002819675486534834\n",
      "episode: 154200 loss 0.0005116774118505418\n",
      "episode: 154300 loss 0.005518015474081039\n",
      "episode: 154400 loss 0.0018871601205319166\n",
      "episode: 154500 loss 0.0008894027560018003\n",
      "episode: 154600 loss 0.0013755657710134983\n",
      "episode: 154700 loss 0.000499318353831768\n",
      "episode: 154800 loss 0.007204767316579819\n",
      "episode: 154900 loss 0.0064778258092701435\n",
      "episode: 155000 loss 0.0023965893778949976\n",
      "Testing...\n",
      "test accuracy: 0.9742000000000001\n",
      "episode: 155100 loss 0.003404930466786027\n",
      "episode: 155200 loss 0.001484495121985674\n",
      "episode: 155300 loss 0.0009306418942287564\n",
      "episode: 155400 loss 0.0007774317637085915\n",
      "episode: 155500 loss 0.0015064387116581202\n",
      "episode: 155600 loss 0.006021815352141857\n",
      "episode: 155700 loss 0.003966375254094601\n",
      "episode: 155800 loss 0.000987966894172132\n",
      "episode: 155900 loss 0.0015755241038277745\n",
      "episode: 156000 loss 0.00281096831895411\n",
      "episode: 156100 loss 0.0015301266685128212\n",
      "episode: 156200 loss 0.0004579090455081314\n",
      "episode: 156300 loss 0.003372838022187352\n",
      "episode: 156400 loss 0.0012721082894131541\n",
      "episode: 156500 loss 0.0015820746775716543\n",
      "episode: 156600 loss 0.0006918067811056972\n",
      "episode: 156700 loss 0.003700880566611886\n",
      "episode: 156800 loss 0.002446242840960622\n",
      "episode: 156900 loss 0.00334843248128891\n",
      "episode: 157000 loss 0.0008795008761808276\n",
      "episode: 157100 loss 0.0007521762745454907\n",
      "episode: 157200 loss 0.00094739900669083\n",
      "episode: 157300 loss 0.0015974652487784624\n",
      "episode: 157400 loss 0.0014286005171015859\n",
      "episode: 157500 loss 0.0023297262378036976\n",
      "episode: 157600 loss 0.003918958827853203\n",
      "episode: 157700 loss 0.006309868767857552\n",
      "episode: 157800 loss 0.001400101464241743\n",
      "episode: 157900 loss 0.0022748580668121576\n",
      "episode: 158000 loss 0.0010838689049705863\n",
      "episode: 158100 loss 0.0011493630008772016\n",
      "episode: 158200 loss 0.0008659881423227489\n",
      "episode: 158300 loss 0.0006511678802780807\n",
      "episode: 158400 loss 0.0005008535226806998\n",
      "episode: 158500 loss 0.0011002676328644156\n",
      "episode: 158600 loss 0.0020424637477844954\n",
      "episode: 158700 loss 0.0009190300479531288\n",
      "episode: 158800 loss 0.010013479739427567\n",
      "episode: 158900 loss 0.0032609582412987947\n",
      "episode: 159000 loss 0.0013739709975197911\n",
      "episode: 159100 loss 0.0018858880503103137\n",
      "episode: 159200 loss 0.001430062111467123\n",
      "episode: 159300 loss 0.0018042149022221565\n",
      "episode: 159400 loss 0.0007570974412374198\n",
      "episode: 159500 loss 0.00034586628316901624\n",
      "episode: 159600 loss 0.0035726784262806177\n",
      "episode: 159700 loss 0.0009175485465675592\n",
      "episode: 159800 loss 0.0037543110083788633\n",
      "episode: 159900 loss 0.0020016527269035578\n",
      "episode: 160000 loss 0.004158006981015205\n",
      "Testing...\n",
      "test accuracy: 0.97665\n",
      "episode: 160100 loss 0.00355984247289598\n",
      "episode: 160200 loss 0.0010260100243613124\n",
      "episode: 160300 loss 0.0014386571710929275\n",
      "episode: 160400 loss 0.0019999248906970024\n",
      "episode: 160500 loss 0.0038424592930823565\n",
      "episode: 160600 loss 0.0021118393633514643\n",
      "episode: 160700 loss 0.0010353355901315808\n",
      "episode: 160800 loss 0.007278640754520893\n",
      "episode: 160900 loss 0.003075120970606804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 161000 loss 0.002396402880549431\n",
      "episode: 161100 loss 0.0005468508461490273\n",
      "episode: 161200 loss 8.312408317578956e-05\n",
      "episode: 161300 loss 0.0034045488573610783\n",
      "episode: 161400 loss 0.0006925187190063298\n",
      "episode: 161500 loss 0.002968934364616871\n",
      "episode: 161600 loss 0.0031813455279916525\n",
      "episode: 161700 loss 0.0016221338883042336\n",
      "episode: 161800 loss 0.0029584330040961504\n",
      "episode: 161900 loss 0.0006204807432368398\n",
      "episode: 162000 loss 0.003595079993829131\n",
      "episode: 162100 loss 0.001850450411438942\n",
      "episode: 162200 loss 0.0009646399412304163\n",
      "episode: 162300 loss 0.0005431697936728597\n",
      "episode: 162400 loss 0.0006269187433645129\n",
      "episode: 162500 loss 0.001706856768578291\n",
      "episode: 162600 loss 0.004599534906446934\n",
      "episode: 162700 loss 0.003903190139681101\n",
      "episode: 162800 loss 0.0013861972838640213\n",
      "episode: 162900 loss 0.0006147852400317788\n",
      "episode: 163000 loss 0.0012598932953551412\n",
      "episode: 163100 loss 0.0005196424899622798\n",
      "episode: 163200 loss 0.0011801327345892787\n",
      "episode: 163300 loss 0.0007088470738381147\n",
      "episode: 163400 loss 0.0012975640129297972\n",
      "episode: 163500 loss 0.0009700033697299659\n",
      "episode: 163600 loss 0.0011199767468497157\n",
      "episode: 163700 loss 0.00744818989187479\n",
      "episode: 163800 loss 0.0007239743717946112\n",
      "episode: 163900 loss 0.00044611221528612077\n",
      "episode: 164000 loss 0.001823421218432486\n",
      "episode: 164100 loss 0.0012716068886220455\n",
      "episode: 164200 loss 0.002093997085466981\n",
      "episode: 164300 loss 0.001843833364546299\n",
      "episode: 164400 loss 0.0006717705400660634\n",
      "episode: 164500 loss 0.0010343771427869797\n",
      "episode: 164600 loss 0.0022356424015015364\n",
      "episode: 164700 loss 0.0008757913019508123\n",
      "episode: 164800 loss 0.0049280147068202496\n",
      "episode: 164900 loss 0.0031613516621291637\n",
      "episode: 165000 loss 0.003497317200526595\n",
      "Testing...\n",
      "test accuracy: 0.97745\n",
      "save networks for episode: 164999\n",
      "episode: 165100 loss 0.0035273353569209576\n",
      "episode: 165200 loss 0.0025276110973209143\n",
      "episode: 165300 loss 0.0038922177627682686\n",
      "episode: 165400 loss 0.001616690307855606\n",
      "episode: 165500 loss 0.004034322686493397\n",
      "episode: 165600 loss 0.0008486058795824647\n",
      "episode: 165700 loss 0.002068465808406472\n",
      "episode: 165800 loss 0.0015272662276402116\n",
      "episode: 165900 loss 0.0010486440733075142\n",
      "episode: 166000 loss 0.005235911346971989\n",
      "episode: 166100 loss 0.0011163019808009267\n",
      "episode: 166200 loss 0.002595508936792612\n",
      "episode: 166300 loss 0.001340879243798554\n",
      "episode: 166400 loss 0.0021869817283004522\n",
      "episode: 166500 loss 0.0014421895612031221\n",
      "episode: 166600 loss 0.0026524169370532036\n",
      "episode: 166700 loss 0.0025720205157995224\n",
      "episode: 166800 loss 0.0010121881496161222\n",
      "episode: 166900 loss 0.0018189441179856658\n",
      "episode: 167000 loss 0.003948202356696129\n",
      "episode: 167100 loss 0.0021409885957837105\n",
      "episode: 167200 loss 0.0053388820961117744\n",
      "episode: 167300 loss 0.001171151758171618\n",
      "episode: 167400 loss 0.0033826399594545364\n",
      "episode: 167500 loss 0.00482287397608161\n",
      "episode: 167600 loss 0.0015886651817709208\n",
      "episode: 167700 loss 0.002322426764294505\n",
      "episode: 167800 loss 0.00028723012655973434\n",
      "episode: 167900 loss 0.002769996877759695\n",
      "episode: 168000 loss 0.003342262003570795\n",
      "episode: 168100 loss 0.0004090885631740093\n",
      "episode: 168200 loss 0.0028152770828455687\n",
      "episode: 168300 loss 0.0014510169858112931\n",
      "episode: 168400 loss 0.0008777538314461708\n",
      "episode: 168500 loss 0.0030235943850129843\n",
      "episode: 168600 loss 0.0008822560193948448\n",
      "episode: 168700 loss 0.001651039463467896\n",
      "episode: 168800 loss 0.0020125065930187702\n",
      "episode: 168900 loss 0.003489377675577998\n",
      "episode: 169000 loss 0.002112142276018858\n",
      "episode: 169100 loss 0.0008346123504452407\n",
      "episode: 169200 loss 0.004430110566318035\n",
      "episode: 169300 loss 0.0006670485017821193\n",
      "episode: 169400 loss 0.0009435295360162854\n",
      "episode: 169500 loss 0.0006954852724447846\n",
      "episode: 169600 loss 0.007400339003652334\n",
      "episode: 169700 loss 0.0007839453173801303\n",
      "episode: 169800 loss 0.004457429982721806\n",
      "episode: 169900 loss 0.0011729156831279397\n",
      "episode: 170000 loss 0.0037870376836508512\n",
      "Testing...\n",
      "test accuracy: 0.97735\n",
      "episode: 170100 loss 0.0020606056787073612\n",
      "episode: 170200 loss 0.0038662590086460114\n",
      "episode: 170300 loss 0.005118859466165304\n",
      "episode: 170400 loss 0.004961840808391571\n",
      "episode: 170500 loss 0.002711556851863861\n",
      "episode: 170600 loss 0.0015711234882473946\n",
      "episode: 170700 loss 0.0011353313457220793\n",
      "episode: 170800 loss 0.0016295253299176693\n",
      "episode: 170900 loss 0.0014640978770330548\n",
      "episode: 171000 loss 0.0029343212954699993\n",
      "episode: 171100 loss 0.015129940584301949\n",
      "episode: 171200 loss 0.0016314417589455843\n",
      "episode: 171300 loss 0.0010727312183007598\n",
      "episode: 171400 loss 0.0039095208048820496\n",
      "episode: 171500 loss 0.0025187134742736816\n",
      "episode: 171600 loss 0.002346659079194069\n",
      "episode: 171700 loss 0.0017594480887055397\n",
      "episode: 171800 loss 0.0033084724564105272\n",
      "episode: 171900 loss 0.002819919027388096\n",
      "episode: 172000 loss 0.0013371712993830442\n",
      "episode: 172100 loss 0.0009193160221911967\n",
      "episode: 172200 loss 0.000978783704340458\n",
      "episode: 172300 loss 0.0018072794191539288\n",
      "episode: 172400 loss 0.0027991177048534155\n",
      "episode: 172500 loss 0.0014242150355130434\n",
      "episode: 172600 loss 0.001819991390220821\n",
      "episode: 172700 loss 0.0021717145573347807\n",
      "episode: 172800 loss 0.004411633592098951\n",
      "episode: 172900 loss 0.0018994028214365244\n",
      "episode: 173000 loss 0.0018882325384765863\n",
      "episode: 173100 loss 0.002382763661444187\n",
      "episode: 173200 loss 0.0074722436256706715\n",
      "episode: 173300 loss 0.0017931907204911113\n",
      "episode: 173400 loss 0.004161084536463022\n",
      "episode: 173500 loss 0.0023804870434105396\n",
      "episode: 173600 loss 0.015670295804739\n",
      "episode: 173700 loss 0.004641037434339523\n",
      "episode: 173800 loss 0.0006481484160758555\n",
      "episode: 173900 loss 0.006073674652725458\n",
      "episode: 174000 loss 0.0008522295393049717\n",
      "episode: 174100 loss 0.000823385373223573\n",
      "episode: 174200 loss 0.0017143208533525467\n",
      "episode: 174300 loss 0.0017974578076973557\n",
      "episode: 174400 loss 0.002454308792948723\n",
      "episode: 174500 loss 0.0012232763692736626\n",
      "episode: 174600 loss 0.0006592627614736557\n",
      "episode: 174700 loss 0.0025207367725670338\n",
      "episode: 174800 loss 0.002639160957187414\n",
      "episode: 174900 loss 0.0011704646749421954\n",
      "episode: 175000 loss 0.0018640104681253433\n",
      "Testing...\n",
      "test accuracy: 0.9741000000000001\n",
      "episode: 175100 loss 0.0014626051997765899\n",
      "episode: 175200 loss 0.0010712252696976066\n",
      "episode: 175300 loss 0.0010043586371466517\n",
      "episode: 175400 loss 0.0007123532705008984\n",
      "episode: 175500 loss 0.0031410870142281055\n",
      "episode: 175600 loss 0.0010369973024353385\n",
      "episode: 175700 loss 0.006407563108950853\n",
      "episode: 175800 loss 0.0022605815902352333\n",
      "episode: 175900 loss 0.004604279063642025\n",
      "episode: 176000 loss 0.0022221726831048727\n",
      "episode: 176100 loss 0.0010636728256940842\n",
      "episode: 176200 loss 0.0005982255679555237\n",
      "episode: 176300 loss 0.0007823348278179765\n",
      "episode: 176400 loss 0.0014442341635003686\n",
      "episode: 176500 loss 0.0005417834036052227\n",
      "episode: 176600 loss 0.0010620630346238613\n",
      "episode: 176700 loss 0.0009601030615158379\n",
      "episode: 176800 loss 0.0021894609089940786\n",
      "episode: 176900 loss 0.0019565923139452934\n",
      "episode: 177000 loss 0.0030045141465961933\n",
      "episode: 177100 loss 0.0033055839594453573\n",
      "episode: 177200 loss 0.0012683807872235775\n",
      "episode: 177300 loss 0.0014614263782277703\n",
      "episode: 177400 loss 0.0025720868725329638\n",
      "episode: 177500 loss 0.00027240923373028636\n",
      "episode: 177600 loss 0.002499004127457738\n",
      "episode: 177700 loss 0.00026933502522297204\n",
      "episode: 177800 loss 0.00305554480291903\n",
      "episode: 177900 loss 0.001422372180968523\n",
      "episode: 178000 loss 0.005225077271461487\n",
      "episode: 178100 loss 0.0025090044364333153\n",
      "episode: 178200 loss 0.002585780806839466\n",
      "episode: 178300 loss 0.001079853973351419\n",
      "episode: 178400 loss 0.003041507676243782\n",
      "episode: 178500 loss 0.001059745904058218\n",
      "episode: 178600 loss 0.0028008706867694855\n",
      "episode: 178700 loss 0.001488967682234943\n",
      "episode: 178800 loss 0.0004651048802770674\n",
      "episode: 178900 loss 0.001093412283807993\n",
      "episode: 179000 loss 0.0011289624962955713\n",
      "episode: 179100 loss 0.0013968072598800063\n",
      "episode: 179200 loss 0.003047599457204342\n",
      "episode: 179300 loss 0.0018383414717391133\n",
      "episode: 179400 loss 0.0025289736222475767\n",
      "episode: 179500 loss 0.0011281045153737068\n",
      "episode: 179600 loss 0.0018127181101590395\n",
      "episode: 179700 loss 0.0010691217612475157\n",
      "episode: 179800 loss 0.002041418571025133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 179900 loss 0.002623035339638591\n",
      "episode: 180000 loss 0.002521525602787733\n",
      "Testing...\n",
      "test accuracy: 0.97765\n",
      "save networks for episode: 179999\n",
      "episode: 180100 loss 0.0004214684886392206\n",
      "episode: 180200 loss 0.001724366215057671\n",
      "episode: 180300 loss 0.0019271713681519032\n",
      "episode: 180400 loss 0.002355111762881279\n",
      "episode: 180500 loss 0.001673226710408926\n",
      "episode: 180600 loss 0.0006056947750039399\n",
      "episode: 180700 loss 0.0032405017409473658\n",
      "episode: 180800 loss 0.0016091050347313285\n",
      "episode: 180900 loss 0.0006583508220501244\n",
      "episode: 181000 loss 0.0014028511941432953\n",
      "episode: 181100 loss 0.0028104055672883987\n",
      "episode: 181200 loss 0.003142253728583455\n",
      "episode: 181300 loss 0.001034010318107903\n",
      "episode: 181400 loss 0.0074292514473199844\n",
      "episode: 181500 loss 0.0010719895362854004\n",
      "episode: 181600 loss 0.001885092817246914\n",
      "episode: 181700 loss 0.0013103971723467112\n",
      "episode: 181800 loss 0.0015421095304191113\n",
      "episode: 181900 loss 0.0016297606052830815\n",
      "episode: 182000 loss 0.00476043252274394\n",
      "episode: 182100 loss 0.004517676308751106\n",
      "episode: 182200 loss 0.0005989502533338964\n",
      "episode: 182300 loss 0.0006036903942003846\n",
      "episode: 182400 loss 0.0023501201067119837\n",
      "episode: 182500 loss 0.0013680019183084369\n",
      "episode: 182600 loss 0.0035104493144899607\n",
      "episode: 182700 loss 0.0010654008947312832\n",
      "episode: 182800 loss 0.0014904630370438099\n",
      "episode: 182900 loss 0.0016936425818130374\n",
      "episode: 183000 loss 0.0012468092609196901\n",
      "episode: 183100 loss 0.0012826444581151009\n",
      "episode: 183200 loss 0.0024044588208198547\n",
      "episode: 183300 loss 0.009016233496367931\n",
      "episode: 183400 loss 0.001098362379707396\n",
      "episode: 183500 loss 0.004777637310326099\n",
      "episode: 183600 loss 0.005848696921020746\n",
      "episode: 183700 loss 0.0014821043005213141\n",
      "episode: 183800 loss 0.0021936907432973385\n",
      "episode: 183900 loss 0.0010779144940897822\n",
      "episode: 184000 loss 0.0024170747492462397\n",
      "episode: 184100 loss 0.003662677248939872\n",
      "episode: 184200 loss 0.0023098797537386417\n",
      "episode: 184300 loss 0.0019961176440119743\n",
      "episode: 184400 loss 0.0016614291816949844\n",
      "episode: 184500 loss 0.0014950993936508894\n",
      "episode: 184600 loss 0.0005215407581999898\n",
      "episode: 184700 loss 0.00441736588254571\n",
      "episode: 184800 loss 0.00042076068348251283\n",
      "episode: 184900 loss 0.0013279109261929989\n",
      "episode: 185000 loss 0.0008360167266801\n",
      "Testing...\n",
      "test accuracy: 0.9739500000000001\n",
      "episode: 185100 loss 0.0017665892373770475\n",
      "episode: 185200 loss 0.0033584083430469036\n",
      "episode: 185300 loss 0.0008676844881847501\n",
      "episode: 185400 loss 0.004071839619427919\n",
      "episode: 185500 loss 0.0014627020573243499\n",
      "episode: 185600 loss 0.007456743158400059\n",
      "episode: 185700 loss 0.0017882793908938766\n",
      "episode: 185800 loss 0.005993695463985205\n",
      "episode: 185900 loss 0.0013097969349473715\n",
      "episode: 186000 loss 0.0025650085881352425\n",
      "episode: 186100 loss 0.0046548498794436455\n",
      "episode: 186200 loss 0.0009005974279716611\n",
      "episode: 186300 loss 0.00144044472835958\n",
      "episode: 186400 loss 0.0014457806246355176\n",
      "episode: 186500 loss 0.004084104206413031\n",
      "episode: 186600 loss 0.0006141092162579298\n",
      "episode: 186700 loss 0.004464384634047747\n",
      "episode: 186800 loss 0.0009825077140703797\n",
      "episode: 186900 loss 0.0011959311086684465\n",
      "episode: 187000 loss 0.004236749839037657\n",
      "episode: 187100 loss 0.005983763374388218\n",
      "episode: 187200 loss 0.0006428674678318202\n",
      "episode: 187300 loss 0.0009555271826684475\n",
      "episode: 187400 loss 0.00364686013199389\n",
      "episode: 187500 loss 0.0014413746539503336\n",
      "episode: 187600 loss 0.001204185769893229\n",
      "episode: 187700 loss 0.0023846940603107214\n",
      "episode: 187800 loss 0.002008599229156971\n",
      "episode: 187900 loss 0.0009752190089784563\n",
      "episode: 188000 loss 0.005579857621341944\n",
      "episode: 188100 loss 0.001170554431155324\n",
      "episode: 188200 loss 0.002155573572963476\n",
      "episode: 188300 loss 0.0038023157976567745\n",
      "episode: 188400 loss 0.002025832189247012\n",
      "episode: 188500 loss 0.001747861155308783\n",
      "episode: 188600 loss 0.001132387900725007\n",
      "episode: 188700 loss 0.0014678199077025056\n",
      "episode: 188800 loss 0.004093192517757416\n",
      "episode: 188900 loss 0.0005251498077996075\n",
      "episode: 189000 loss 0.0004813498817384243\n",
      "episode: 189100 loss 0.0009892313973978162\n",
      "episode: 189200 loss 0.002584304427728057\n",
      "episode: 189300 loss 0.002869896125048399\n",
      "episode: 189400 loss 0.001158021972514689\n",
      "episode: 189500 loss 0.0009310541790910065\n",
      "episode: 189600 loss 0.007022609934210777\n",
      "episode: 189700 loss 0.0018145497888326645\n",
      "episode: 189800 loss 0.0016925494419410825\n",
      "episode: 189900 loss 0.0013449982507154346\n",
      "episode: 190000 loss 0.001139513566158712\n",
      "Testing...\n",
      "test accuracy: 0.97575\n",
      "episode: 190100 loss 0.00030623574275523424\n",
      "episode: 190200 loss 0.0012053140671923757\n",
      "episode: 190300 loss 0.00019863170746248215\n",
      "episode: 190400 loss 0.0009368028840981424\n",
      "episode: 190500 loss 0.004107694607228041\n",
      "episode: 190600 loss 0.0010781955206766725\n",
      "episode: 190700 loss 0.0010654593352228403\n",
      "episode: 190800 loss 0.0024850694462656975\n",
      "episode: 190900 loss 0.0039879390969872475\n",
      "episode: 191000 loss 0.00039565449696965516\n",
      "episode: 191100 loss 0.0002982893493026495\n",
      "episode: 191200 loss 0.001169973285868764\n",
      "episode: 191300 loss 0.0014215960400179029\n",
      "episode: 191400 loss 0.004725953564047813\n",
      "episode: 191500 loss 0.00181140739005059\n",
      "episode: 191600 loss 0.0019741817377507687\n",
      "episode: 191700 loss 0.0039464919827878475\n",
      "episode: 191800 loss 0.0024707657285034657\n",
      "episode: 191900 loss 0.0024468612391501665\n",
      "episode: 192000 loss 0.0017037574434652925\n",
      "episode: 192100 loss 0.004961708560585976\n",
      "episode: 192200 loss 0.0002450902829878032\n",
      "episode: 192300 loss 0.0046869744546711445\n",
      "episode: 192400 loss 0.0015743422554805875\n",
      "episode: 192500 loss 0.0009621921344660223\n",
      "episode: 192600 loss 0.005687285680323839\n",
      "episode: 192700 loss 0.0009814542718231678\n",
      "episode: 192800 loss 0.0017791257705539465\n",
      "episode: 192900 loss 0.001069002551957965\n",
      "episode: 193000 loss 0.000995761714875698\n",
      "episode: 193100 loss 0.0031417326536029577\n",
      "episode: 193200 loss 0.0030254991725087166\n",
      "episode: 193300 loss 0.00036268221447244287\n",
      "episode: 193400 loss 0.0019735104870051146\n",
      "episode: 193500 loss 0.0022534753661602736\n",
      "episode: 193600 loss 0.0011579880956560373\n",
      "episode: 193700 loss 0.006234213709831238\n",
      "episode: 193800 loss 0.0058955783024430275\n",
      "episode: 193900 loss 0.0003002430603373796\n",
      "episode: 194000 loss 0.002804327057674527\n",
      "episode: 194100 loss 0.001510044327005744\n",
      "episode: 194200 loss 0.00033565942430868745\n",
      "episode: 194300 loss 0.0036974637769162655\n",
      "episode: 194400 loss 0.0017096804222092032\n",
      "episode: 194500 loss 0.0012152846902608871\n",
      "episode: 194600 loss 0.002373205032199621\n",
      "episode: 194700 loss 0.0006258147768676281\n",
      "episode: 194800 loss 0.0014031154569238424\n",
      "episode: 194900 loss 0.00733907800167799\n",
      "episode: 195000 loss 0.0013886087108403444\n",
      "Testing...\n",
      "test accuracy: 0.9742999999999999\n",
      "episode: 195100 loss 0.0015020710416138172\n",
      "episode: 195200 loss 0.0017732096603140235\n",
      "episode: 195300 loss 0.0016803359612822533\n",
      "episode: 195400 loss 0.0014113581273704767\n",
      "episode: 195500 loss 0.0027880186680704355\n",
      "episode: 195600 loss 0.0006871421937830746\n",
      "episode: 195700 loss 0.004646010231226683\n",
      "episode: 195800 loss 0.002633575815707445\n",
      "episode: 195900 loss 0.0004088088753633201\n",
      "episode: 196000 loss 0.0005700113251805305\n",
      "episode: 196100 loss 0.0006589475669898093\n",
      "episode: 196200 loss 0.0010603341506794095\n",
      "episode: 196300 loss 0.0005301280179992318\n",
      "episode: 196400 loss 0.0010240497067570686\n",
      "episode: 196500 loss 0.0011114025255665183\n",
      "episode: 196600 loss 0.0038122208788990974\n",
      "episode: 196700 loss 0.002821606118232012\n",
      "episode: 196800 loss 0.005159624852240086\n",
      "episode: 196900 loss 0.0030380378011614084\n",
      "episode: 197000 loss 0.0006069544469937682\n",
      "episode: 197100 loss 0.0012788702733814716\n",
      "episode: 197200 loss 0.0044761281460523605\n",
      "episode: 197300 loss 0.0022225556895136833\n",
      "episode: 197400 loss 0.0026137533131986856\n",
      "episode: 197500 loss 0.0008721052436158061\n",
      "episode: 197600 loss 0.0016146181151270866\n",
      "episode: 197700 loss 0.0005283464561216533\n",
      "episode: 197800 loss 0.0005522436113096774\n",
      "episode: 197900 loss 0.003518508980050683\n",
      "episode: 198000 loss 0.0026377050671726465\n",
      "episode: 198100 loss 0.0021046523470431566\n",
      "episode: 198200 loss 0.008833074010908604\n",
      "episode: 198300 loss 0.0030260018538683653\n",
      "episode: 198400 loss 0.0014132399810478091\n",
      "episode: 198500 loss 0.0005705214571207762\n",
      "episode: 198600 loss 0.0020152658689767122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 198700 loss 0.0017915357602760196\n",
      "episode: 198800 loss 0.0028289484325796366\n",
      "episode: 198900 loss 0.0021278602071106434\n",
      "episode: 199000 loss 0.0017096094088628888\n",
      "episode: 199100 loss 0.005701120477169752\n",
      "episode: 199200 loss 0.001019527087919414\n",
      "episode: 199300 loss 0.0041501689702272415\n",
      "episode: 199400 loss 0.0072153061628341675\n",
      "episode: 199500 loss 0.004387089516967535\n",
      "episode: 199600 loss 0.0012936305720359087\n",
      "episode: 199700 loss 0.0010462466161698103\n",
      "episode: 199800 loss 0.002278674393892288\n",
      "episode: 199900 loss 0.0003534160496201366\n",
      "episode: 200000 loss 0.0012611363781616092\n",
      "Testing...\n",
      "test accuracy: 0.9751000000000001\n",
      "episode: 200100 loss 0.0018807188607752323\n",
      "episode: 200200 loss 0.003198671853169799\n",
      "episode: 200300 loss 0.0024924566969275475\n",
      "episode: 200400 loss 0.0033463481813669205\n",
      "episode: 200500 loss 0.0003950243699364364\n",
      "episode: 200600 loss 0.0004782359173987061\n",
      "episode: 200700 loss 0.0036391715984791517\n",
      "episode: 200800 loss 0.0004679980338551104\n",
      "episode: 200900 loss 0.0010988418944180012\n",
      "episode: 201000 loss 0.0018804023275151849\n",
      "episode: 201100 loss 0.0028218901716172695\n",
      "episode: 201200 loss 0.008746804669499397\n",
      "episode: 201300 loss 0.0009979462483897805\n",
      "episode: 201400 loss 0.0005535571835935116\n",
      "episode: 201500 loss 0.0011375949252396822\n",
      "episode: 201600 loss 0.00517806364223361\n",
      "episode: 201700 loss 0.00020462308020796627\n",
      "episode: 201800 loss 0.0013173815095797181\n",
      "episode: 201900 loss 0.0006170438718982041\n",
      "episode: 202000 loss 0.000941200356464833\n",
      "episode: 202100 loss 0.003754587611183524\n",
      "episode: 202200 loss 0.002726765116676688\n",
      "episode: 202300 loss 0.0004090977308806032\n",
      "episode: 202400 loss 0.0012264156248420477\n",
      "episode: 202500 loss 0.0011997130932286382\n",
      "episode: 202600 loss 0.006227798294275999\n",
      "episode: 202700 loss 0.008256987668573856\n",
      "episode: 202800 loss 0.0015582521446049213\n",
      "episode: 202900 loss 0.0006132773123681545\n",
      "episode: 203000 loss 0.0015859401319175959\n",
      "episode: 203100 loss 0.0009723749244585633\n",
      "episode: 203200 loss 0.0006906546768732369\n",
      "episode: 203300 loss 0.002229033038020134\n",
      "episode: 203400 loss 0.004552534781396389\n",
      "episode: 203500 loss 0.0042941817082464695\n",
      "episode: 203600 loss 0.004668167792260647\n",
      "episode: 203700 loss 0.0010611708275973797\n",
      "episode: 203800 loss 0.0008472908521071076\n",
      "episode: 203900 loss 0.0010651566553860903\n",
      "episode: 204000 loss 0.001212447532452643\n",
      "episode: 204100 loss 0.004221688024699688\n",
      "episode: 204200 loss 0.0012086930219084024\n",
      "episode: 204300 loss 0.0021101199090480804\n",
      "episode: 204400 loss 0.0013766044285148382\n",
      "episode: 204500 loss 0.00112545071169734\n",
      "episode: 204600 loss 0.0035141429398208857\n",
      "episode: 204700 loss 0.0008542299037799239\n",
      "episode: 204800 loss 0.006127911154180765\n",
      "episode: 204900 loss 0.004056285601109266\n",
      "episode: 205000 loss 0.0024422749411314726\n",
      "Testing...\n",
      "test accuracy: 0.9746\n",
      "episode: 205100 loss 0.001563742058351636\n",
      "episode: 205200 loss 0.0028649065643548965\n",
      "episode: 205300 loss 0.003748977091163397\n",
      "episode: 205400 loss 0.0006654859171248972\n",
      "episode: 205500 loss 0.0006321242544800043\n",
      "episode: 205600 loss 0.0016075235325843096\n",
      "episode: 205700 loss 0.0009099215385504067\n",
      "episode: 205800 loss 0.00041042178054340184\n",
      "episode: 205900 loss 0.0021767872385680676\n",
      "episode: 206000 loss 0.0013700851704925299\n",
      "episode: 206100 loss 0.0013525214744731784\n",
      "episode: 206200 loss 0.0009081381722353399\n",
      "episode: 206300 loss 0.0006095506832934916\n",
      "episode: 206400 loss 0.0005434051272459328\n",
      "episode: 206500 loss 0.0026220425497740507\n",
      "episode: 206600 loss 0.0017109165200963616\n",
      "episode: 206700 loss 0.0023799347691237926\n",
      "episode: 206800 loss 0.0009387433528900146\n",
      "episode: 206900 loss 0.0005737687461078167\n",
      "episode: 207000 loss 0.0014145480236038566\n",
      "episode: 207100 loss 0.0024404057767242193\n",
      "episode: 207200 loss 0.0005441367393359542\n",
      "episode: 207300 loss 0.0009318924858234823\n",
      "episode: 207400 loss 0.0022817887365818024\n",
      "episode: 207500 loss 0.0008329608826898038\n",
      "episode: 207600 loss 0.0010717228287830949\n",
      "episode: 207700 loss 0.0027233653236180544\n",
      "episode: 207800 loss 0.0022027618251740932\n",
      "episode: 207900 loss 0.001999190542846918\n",
      "episode: 208000 loss 0.00018570305837783962\n",
      "episode: 208100 loss 0.0013963417150080204\n",
      "episode: 208200 loss 0.00038234179373830557\n",
      "episode: 208300 loss 0.00015076890122145414\n",
      "episode: 208400 loss 0.00539074931293726\n",
      "episode: 208500 loss 0.005522481165826321\n",
      "episode: 208600 loss 0.0008405079715885222\n",
      "episode: 208700 loss 0.0019148023566231132\n",
      "episode: 208800 loss 0.0013172468170523643\n",
      "episode: 208900 loss 0.0001948811550391838\n",
      "episode: 209000 loss 0.0015163935022428632\n",
      "episode: 209100 loss 0.0011618036078289151\n",
      "episode: 209200 loss 0.0017993629444390535\n",
      "episode: 209300 loss 0.00518467603251338\n",
      "episode: 209400 loss 0.0005858599906787276\n",
      "episode: 209500 loss 0.0007365178316831589\n",
      "episode: 209600 loss 0.0024489874485880136\n",
      "episode: 209700 loss 0.0014612363884225488\n",
      "episode: 209800 loss 0.0024789886083453894\n",
      "episode: 209900 loss 0.0016713578952476382\n",
      "episode: 210000 loss 0.003880477277562022\n",
      "Testing...\n",
      "test accuracy: 0.9749500000000001\n",
      "episode: 210100 loss 0.001856558839790523\n",
      "episode: 210200 loss 0.0039186300709843636\n",
      "episode: 210300 loss 0.0005246819346211851\n",
      "episode: 210400 loss 0.00040929598617367446\n",
      "episode: 210500 loss 0.000886680674739182\n",
      "episode: 210600 loss 0.000921013648621738\n",
      "episode: 210700 loss 0.0016614093910902739\n",
      "episode: 210800 loss 0.0009495954145677388\n",
      "episode: 210900 loss 0.0010660109110176563\n",
      "episode: 211000 loss 0.0007443801150657237\n",
      "episode: 211100 loss 0.0014365841634571552\n",
      "episode: 211200 loss 0.0007687890902161598\n",
      "episode: 211300 loss 0.005748837720602751\n",
      "episode: 211400 loss 0.0003567255917005241\n",
      "episode: 211500 loss 0.0017849509604275227\n",
      "episode: 211600 loss 0.0007924120291136205\n",
      "episode: 211700 loss 0.010185200721025467\n",
      "episode: 211800 loss 0.006942092906683683\n",
      "episode: 211900 loss 0.0018920968286693096\n",
      "episode: 212000 loss 0.001129668322391808\n",
      "episode: 212100 loss 0.0034385421313345432\n",
      "episode: 212200 loss 0.0025110202841460705\n",
      "episode: 212300 loss 0.001609103288501501\n",
      "episode: 212400 loss 0.0030559138394892216\n",
      "episode: 212500 loss 0.0009799761464819312\n",
      "episode: 212600 loss 0.0010348325595259666\n",
      "episode: 212700 loss 0.0037880882155150175\n",
      "episode: 212800 loss 0.00067103625042364\n",
      "episode: 212900 loss 0.0014222384197637439\n",
      "episode: 213000 loss 0.0020699172746390104\n",
      "episode: 213100 loss 0.0006293616606853902\n",
      "episode: 213200 loss 0.0016808666987344623\n",
      "episode: 213300 loss 0.0013528444105759263\n",
      "episode: 213400 loss 0.001056611305102706\n",
      "episode: 213500 loss 0.0029433502350002527\n",
      "episode: 213600 loss 0.0034633458126336336\n",
      "episode: 213700 loss 0.0018327992875128984\n",
      "episode: 213800 loss 0.000601038511376828\n",
      "episode: 213900 loss 0.0016662591369822621\n",
      "episode: 214000 loss 0.001166433678008616\n",
      "episode: 214100 loss 0.00016628322191536427\n",
      "episode: 214200 loss 0.0017751088598743081\n",
      "episode: 214300 loss 0.002336629666388035\n",
      "episode: 214400 loss 0.0016319092828780413\n",
      "episode: 214500 loss 0.0009244959801435471\n",
      "episode: 214600 loss 0.0008922888664528728\n",
      "episode: 214700 loss 3.406274481676519e-05\n",
      "episode: 214800 loss 0.0035331416875123978\n",
      "episode: 214900 loss 0.001161419553682208\n",
      "episode: 215000 loss 0.0011035299394279718\n",
      "Testing...\n",
      "test accuracy: 0.9759500000000001\n",
      "episode: 215100 loss 0.0009348830208182335\n",
      "episode: 215200 loss 0.0006079210434108973\n",
      "episode: 215300 loss 0.0022821396123617887\n",
      "episode: 215400 loss 0.001328230369836092\n",
      "episode: 215500 loss 0.004457430448383093\n",
      "episode: 215600 loss 0.0034491941332817078\n",
      "episode: 215700 loss 0.0013672671047970653\n",
      "episode: 215800 loss 0.0013136592460796237\n",
      "episode: 215900 loss 0.0013391582760959864\n",
      "episode: 216000 loss 0.0015447764890268445\n",
      "episode: 216100 loss 0.0008388702990487218\n",
      "episode: 216200 loss 0.003417265834286809\n",
      "episode: 216300 loss 0.0017338180914521217\n",
      "episode: 216400 loss 0.0014775528106838465\n",
      "episode: 216500 loss 0.0021853456273674965\n",
      "episode: 216600 loss 0.0011723884381353855\n",
      "episode: 216700 loss 0.003025852609425783\n",
      "episode: 216800 loss 0.001203103456646204\n",
      "episode: 216900 loss 0.001266475417651236\n",
      "episode: 217000 loss 0.002275166567414999\n",
      "episode: 217100 loss 0.0005308731342665851\n",
      "episode: 217200 loss 0.0024377694353461266\n",
      "episode: 217300 loss 0.0009732771432027221\n",
      "episode: 217400 loss 0.000717348768375814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 217500 loss 0.0018517456483095884\n",
      "episode: 217600 loss 0.0008744759252294898\n",
      "episode: 217700 loss 0.0028365724720060825\n",
      "episode: 217800 loss 0.002182930940762162\n",
      "episode: 217900 loss 0.0010385253699496388\n",
      "episode: 218000 loss 0.0008123042644001544\n",
      "episode: 218100 loss 0.004565272480249405\n",
      "episode: 218200 loss 0.001224196283146739\n",
      "episode: 218300 loss 0.0006110927788540721\n",
      "episode: 218400 loss 0.0005480487016029656\n",
      "episode: 218500 loss 0.0012648745905607939\n",
      "episode: 218600 loss 0.0002584063622634858\n",
      "episode: 218700 loss 0.0005475522484630346\n",
      "episode: 218800 loss 0.000404549267841503\n",
      "episode: 218900 loss 0.0019900044426321983\n",
      "episode: 219000 loss 0.00025349168572574854\n",
      "episode: 219100 loss 0.0006219457718543708\n",
      "episode: 219200 loss 0.0006581099005416036\n",
      "episode: 219300 loss 0.005131188780069351\n",
      "episode: 219400 loss 0.0016359462169930339\n",
      "episode: 219500 loss 0.0024913055822253227\n",
      "episode: 219600 loss 0.0026766026858240366\n",
      "episode: 219700 loss 8.776049071457237e-05\n",
      "episode: 219800 loss 0.0010321373119950294\n",
      "episode: 219900 loss 0.002431710483506322\n",
      "episode: 220000 loss 0.0007462342618964612\n",
      "Testing...\n",
      "test accuracy: 0.9738\n",
      "episode: 220100 loss 0.0008734359871596098\n",
      "episode: 220200 loss 0.002846199320629239\n",
      "episode: 220300 loss 0.0004497962072491646\n",
      "episode: 220400 loss 0.0019390116212889552\n",
      "episode: 220500 loss 0.0007017884636297822\n",
      "episode: 220600 loss 0.006262416020035744\n",
      "episode: 220700 loss 0.002676809672266245\n",
      "episode: 220800 loss 0.0011716457083821297\n",
      "episode: 220900 loss 0.0035175271332263947\n",
      "episode: 221000 loss 0.0012969126692041755\n",
      "episode: 221100 loss 0.0012885774485766888\n",
      "episode: 221200 loss 0.0025989445857703686\n",
      "episode: 221300 loss 0.003679194487631321\n",
      "episode: 221400 loss 0.001347326091490686\n",
      "episode: 221500 loss 0.0005738547770306468\n",
      "episode: 221600 loss 0.001260042772628367\n",
      "episode: 221700 loss 0.0035528254229575396\n",
      "episode: 221800 loss 0.0023600347340106964\n",
      "episode: 221900 loss 0.0016035137232393026\n",
      "episode: 222000 loss 0.0020411917939782143\n",
      "episode: 222100 loss 0.0009707474964670837\n",
      "episode: 222200 loss 0.0014970371266826987\n",
      "episode: 222300 loss 0.004103120882064104\n",
      "episode: 222400 loss 0.0019326225155964494\n",
      "episode: 222500 loss 0.0008169876527972519\n",
      "episode: 222600 loss 0.0012212380534037948\n",
      "episode: 222700 loss 0.0015236620092764497\n",
      "episode: 222800 loss 0.0014420088846236467\n",
      "episode: 222900 loss 0.0011819980572909117\n",
      "episode: 223000 loss 0.0028605328407138586\n",
      "episode: 223100 loss 0.0012217472540214658\n",
      "episode: 223200 loss 0.00011519442341523245\n",
      "episode: 223300 loss 0.0015376157825812697\n",
      "episode: 223400 loss 0.0012530467938631773\n",
      "episode: 223500 loss 0.004536750726401806\n",
      "episode: 223600 loss 0.003436210099607706\n",
      "episode: 223700 loss 0.002905546221882105\n",
      "episode: 223800 loss 0.0007320729782804847\n",
      "episode: 223900 loss 0.0028998898342251778\n",
      "episode: 224000 loss 0.005998251959681511\n",
      "episode: 224100 loss 0.003232561983168125\n",
      "episode: 224200 loss 0.0007501754444092512\n",
      "episode: 224300 loss 0.002214220818132162\n",
      "episode: 224400 loss 0.0035469080321490765\n",
      "episode: 224500 loss 0.00282478891313076\n",
      "episode: 224600 loss 0.0018172956770285964\n",
      "episode: 224700 loss 0.0006430296343751252\n",
      "episode: 224800 loss 0.0007201139815151691\n",
      "episode: 224900 loss 0.00047704108874313533\n",
      "episode: 225000 loss 0.0006733991322107613\n",
      "Testing...\n",
      "test accuracy: 0.9759500000000001\n",
      "episode: 225100 loss 0.002815737621858716\n",
      "episode: 225200 loss 0.0014117935206741095\n",
      "episode: 225300 loss 0.0021115760318934917\n",
      "episode: 225400 loss 0.0019030793337151408\n",
      "episode: 225500 loss 0.0027835234068334103\n",
      "episode: 225600 loss 0.0009167359094135463\n",
      "episode: 225700 loss 0.0008423604303970933\n",
      "episode: 225800 loss 0.003002657787874341\n",
      "episode: 225900 loss 0.0014162067091092467\n",
      "episode: 226000 loss 0.0009467282216064632\n",
      "episode: 226100 loss 0.0054158479906618595\n",
      "episode: 226200 loss 0.0008501880220137537\n",
      "episode: 226300 loss 0.0017930518370121717\n",
      "episode: 226400 loss 0.0006833130610175431\n",
      "episode: 226500 loss 0.000937981007155031\n",
      "episode: 226600 loss 0.0005803366657346487\n",
      "episode: 226700 loss 0.0014937949599698186\n",
      "episode: 226800 loss 0.0011634681141003966\n",
      "episode: 226900 loss 0.0020741389598697424\n",
      "episode: 227000 loss 0.001880437834188342\n",
      "episode: 227100 loss 0.00219778623431921\n",
      "episode: 227200 loss 0.004939098376780748\n",
      "episode: 227300 loss 0.0009242247324436903\n",
      "episode: 227400 loss 0.0028393655084073544\n",
      "episode: 227500 loss 0.007282020058482885\n",
      "episode: 227600 loss 0.0010225591249763966\n",
      "episode: 227700 loss 0.0006788386963307858\n",
      "episode: 227800 loss 0.0019391498062759638\n",
      "episode: 227900 loss 0.0035064183175563812\n",
      "episode: 228000 loss 0.0016509628621861339\n",
      "episode: 228100 loss 0.00044551651808433235\n",
      "episode: 228200 loss 0.0011767232790589333\n",
      "episode: 228300 loss 0.001166042173281312\n",
      "episode: 228400 loss 0.0011221964377909899\n",
      "episode: 228500 loss 0.0018460610881447792\n",
      "episode: 228600 loss 0.0022731057833880186\n",
      "episode: 228700 loss 0.0018015325767919421\n",
      "episode: 228800 loss 0.0007035768940113485\n",
      "episode: 228900 loss 0.0019174297340214252\n",
      "episode: 229000 loss 0.0007591580506414175\n",
      "episode: 229100 loss 0.000797037675511092\n",
      "episode: 229200 loss 0.0007556550553999841\n",
      "episode: 229300 loss 0.005034109111875296\n",
      "episode: 229400 loss 0.009825442917644978\n",
      "episode: 229500 loss 0.0011944517027586699\n",
      "episode: 229600 loss 0.0025579293724149466\n",
      "episode: 229700 loss 0.0006895792903378606\n",
      "episode: 229800 loss 0.0007758006104268134\n",
      "episode: 229900 loss 0.0009942689212039113\n",
      "episode: 230000 loss 0.0005467272712849081\n",
      "Testing...\n",
      "test accuracy: 0.97415\n",
      "episode: 230100 loss 0.006175695452839136\n",
      "episode: 230200 loss 0.003970780875533819\n",
      "episode: 230300 loss 0.000909616646822542\n",
      "episode: 230400 loss 0.0016818789299577475\n",
      "episode: 230500 loss 0.002729039639234543\n",
      "episode: 230600 loss 0.003075571730732918\n",
      "episode: 230700 loss 0.0005956906243227422\n",
      "episode: 230800 loss 0.0034988143015652895\n",
      "episode: 230900 loss 0.0006363782449625432\n",
      "episode: 231000 loss 0.001067194389179349\n",
      "episode: 231100 loss 7.46577134123072e-05\n",
      "episode: 231200 loss 0.001723671332001686\n",
      "episode: 231300 loss 0.004484069533646107\n",
      "episode: 231400 loss 0.00045010351459495723\n",
      "episode: 231500 loss 0.00043141114292666316\n",
      "episode: 231600 loss 0.002087476896122098\n",
      "episode: 231700 loss 0.002980454359203577\n",
      "episode: 231800 loss 0.0006102468469180167\n",
      "episode: 231900 loss 0.0026645564939826727\n",
      "episode: 232000 loss 0.002882340457290411\n",
      "episode: 232100 loss 0.000919877493288368\n",
      "episode: 232200 loss 0.0003371178172528744\n",
      "episode: 232300 loss 0.0013741370057687163\n",
      "episode: 232400 loss 0.0030647534877061844\n",
      "episode: 232500 loss 0.003125190967693925\n",
      "episode: 232600 loss 0.0014518211828544736\n",
      "episode: 232700 loss 0.0028295288793742657\n",
      "episode: 232800 loss 0.0008957833051681519\n",
      "episode: 232900 loss 0.0008065025322139263\n",
      "episode: 233000 loss 0.004205150064080954\n",
      "episode: 233100 loss 0.0019438366871327162\n",
      "episode: 233200 loss 0.000851706659886986\n",
      "episode: 233300 loss 0.007164669223129749\n",
      "episode: 233400 loss 0.0005371274892240763\n",
      "episode: 233500 loss 0.000781322130933404\n",
      "episode: 233600 loss 0.000816129264421761\n",
      "episode: 233700 loss 0.003921917174011469\n",
      "episode: 233800 loss 0.0011547051835805178\n",
      "episode: 233900 loss 0.0007734098471701145\n",
      "episode: 234000 loss 0.0006633594166487455\n",
      "episode: 234100 loss 0.0031730036716908216\n",
      "episode: 234200 loss 0.0010802664328366518\n",
      "episode: 234300 loss 0.004429084714502096\n",
      "episode: 234400 loss 0.0017817291663959622\n",
      "episode: 234500 loss 0.0008576932596042752\n",
      "episode: 234600 loss 0.001199269900098443\n",
      "episode: 234700 loss 0.005524692125618458\n",
      "episode: 234800 loss 0.001052600098773837\n",
      "episode: 234900 loss 0.000991414999589324\n",
      "episode: 235000 loss 0.0036449707113206387\n",
      "Testing...\n",
      "test accuracy: 0.9742999999999999\n",
      "episode: 235100 loss 0.004168230574578047\n",
      "episode: 235200 loss 0.001644412288442254\n",
      "episode: 235300 loss 0.002327393041923642\n",
      "episode: 235400 loss 0.0028334700036793947\n",
      "episode: 235500 loss 0.0006455344846472144\n",
      "episode: 235600 loss 0.0003567989042494446\n",
      "episode: 235700 loss 0.003005960723385215\n",
      "episode: 235800 loss 0.0033694955054670572\n",
      "episode: 235900 loss 0.0023995335213840008\n",
      "episode: 236000 loss 0.002154168440029025\n",
      "episode: 236100 loss 0.0017908739391714334\n",
      "episode: 236200 loss 0.0016524478560313582\n",
      "episode: 236300 loss 0.0050734467804431915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 236400 loss 0.001567279570735991\n",
      "episode: 236500 loss 0.000442914548330009\n",
      "episode: 236600 loss 0.0009183146175928414\n",
      "episode: 236700 loss 0.0010776123963296413\n",
      "episode: 236800 loss 0.004895435180515051\n",
      "episode: 236900 loss 7.711066427873448e-05\n",
      "episode: 237000 loss 0.0010944779496639967\n",
      "episode: 237100 loss 0.0006863657617941499\n",
      "episode: 237200 loss 0.0019849759992212057\n",
      "episode: 237300 loss 0.0009298364166170359\n",
      "episode: 237400 loss 0.0052685728296637535\n",
      "episode: 237500 loss 0.007211698219180107\n",
      "episode: 237600 loss 0.001685930066742003\n",
      "episode: 237700 loss 0.0021440458949655294\n",
      "episode: 237800 loss 0.004587043076753616\n",
      "episode: 237900 loss 0.003210752736777067\n",
      "episode: 238000 loss 0.0019583599641919136\n",
      "episode: 238100 loss 0.001773298135958612\n",
      "episode: 238200 loss 0.0010233387583866715\n",
      "episode: 238300 loss 0.002440371783450246\n",
      "episode: 238400 loss 0.003545432584360242\n",
      "episode: 238500 loss 0.006111844442784786\n",
      "episode: 238600 loss 0.0014837051276117563\n",
      "episode: 238700 loss 0.0010179867967963219\n",
      "episode: 238800 loss 0.003990746568888426\n",
      "episode: 238900 loss 0.003778306767344475\n",
      "episode: 239000 loss 0.0004461189964786172\n",
      "episode: 239100 loss 0.0007375086424872279\n",
      "episode: 239200 loss 0.006936082150787115\n",
      "episode: 239300 loss 0.00029208004707470536\n",
      "episode: 239400 loss 0.0016609678277745843\n",
      "episode: 239500 loss 0.0006848419434390962\n",
      "episode: 239600 loss 0.0004447030078154057\n",
      "episode: 239700 loss 0.001141936401836574\n",
      "episode: 239800 loss 0.001141077489592135\n",
      "episode: 239900 loss 0.000654711271636188\n",
      "episode: 240000 loss 0.001597174326889217\n",
      "Testing...\n",
      "test accuracy: 0.9749500000000001\n",
      "episode: 240100 loss 0.003612964879721403\n",
      "episode: 240200 loss 0.002786370227113366\n",
      "episode: 240300 loss 0.0014020786620676517\n",
      "episode: 240400 loss 0.0007883532671257854\n",
      "episode: 240500 loss 0.002807819051668048\n",
      "episode: 240600 loss 0.0008241698378697038\n",
      "episode: 240700 loss 0.0024313742760568857\n",
      "episode: 240800 loss 0.0015600408660247922\n",
      "episode: 240900 loss 0.0022363767493516207\n",
      "episode: 241000 loss 0.0007912077126093209\n",
      "episode: 241100 loss 0.0025789248757064342\n",
      "episode: 241200 loss 0.0003631983418017626\n",
      "episode: 241300 loss 0.001745639368891716\n",
      "episode: 241400 loss 0.005207524169236422\n",
      "episode: 241500 loss 0.0014808683190494776\n",
      "episode: 241600 loss 0.0014281178591772914\n",
      "episode: 241700 loss 0.0004525798431131989\n",
      "episode: 241800 loss 0.0009133951389230788\n",
      "episode: 241900 loss 0.002031712094321847\n",
      "episode: 242000 loss 0.0016768547939136624\n",
      "episode: 242100 loss 0.0035863297525793314\n",
      "episode: 242200 loss 0.003663326147943735\n",
      "episode: 242300 loss 0.001019153743982315\n",
      "episode: 242400 loss 0.004201220814138651\n",
      "episode: 242500 loss 0.0025525635574012995\n",
      "episode: 242600 loss 5.816905468236655e-05\n",
      "episode: 242700 loss 0.0005502781714312732\n",
      "episode: 242800 loss 0.004171783570200205\n",
      "episode: 242900 loss 0.0019208018202334642\n",
      "episode: 243000 loss 0.0007279780111275613\n",
      "episode: 243100 loss 0.000973770278505981\n",
      "episode: 243200 loss 0.000727309612557292\n",
      "episode: 243300 loss 0.0006000293651595712\n",
      "episode: 243400 loss 0.003473275573924184\n",
      "episode: 243500 loss 0.0011041578836739063\n",
      "episode: 243600 loss 0.001258804346434772\n",
      "episode: 243700 loss 0.0005673366831615567\n",
      "episode: 243800 loss 0.0011435196502134204\n",
      "episode: 243900 loss 0.0009809217881411314\n",
      "episode: 244000 loss 0.0017354544252157211\n",
      "episode: 244100 loss 0.0004891639691777527\n",
      "episode: 244200 loss 0.005715463310480118\n",
      "episode: 244300 loss 0.0005627402570098639\n",
      "episode: 244400 loss 0.0035618734546005726\n",
      "episode: 244500 loss 0.0048023397102952\n",
      "episode: 244600 loss 0.007587058003991842\n",
      "episode: 244700 loss 0.001887825201265514\n",
      "episode: 244800 loss 0.005467754788696766\n",
      "episode: 244900 loss 0.0025173015892505646\n",
      "episode: 245000 loss 0.0019464354263618588\n",
      "Testing...\n",
      "test accuracy: 0.9766\n",
      "episode: 245100 loss 0.0018640251364558935\n",
      "episode: 245200 loss 0.0007775191916152835\n",
      "episode: 245300 loss 0.0016303552547469735\n",
      "episode: 245400 loss 0.000633992487564683\n",
      "episode: 245500 loss 0.001119721680879593\n",
      "episode: 245600 loss 0.0025047059170901775\n",
      "episode: 245700 loss 0.0006506571662612259\n",
      "episode: 245800 loss 0.0014322545612230897\n",
      "episode: 245900 loss 0.000926410430110991\n",
      "episode: 246000 loss 0.002413838868960738\n",
      "episode: 246100 loss 0.0007448272663168609\n",
      "episode: 246200 loss 0.0012238805647939444\n",
      "episode: 246300 loss 0.0003347419551573694\n",
      "episode: 246400 loss 0.0018700278596952558\n",
      "episode: 246500 loss 0.002514338120818138\n",
      "episode: 246600 loss 0.0046601141802966595\n",
      "episode: 246700 loss 0.0004345392226241529\n",
      "episode: 246800 loss 0.0006071797688491642\n",
      "episode: 246900 loss 0.0008822962990961969\n",
      "episode: 247000 loss 0.0014779289485886693\n",
      "episode: 247100 loss 0.0011416758643463254\n",
      "episode: 247200 loss 0.0007696996908634901\n",
      "episode: 247300 loss 0.0032033396419137716\n",
      "episode: 247400 loss 0.0021095045376569033\n",
      "episode: 247500 loss 0.0016253604553639889\n",
      "episode: 247600 loss 7.94147199485451e-05\n",
      "episode: 247700 loss 0.0031167641282081604\n",
      "episode: 247800 loss 0.0017615497345104814\n",
      "episode: 247900 loss 0.0009024931932799518\n",
      "episode: 248000 loss 0.002310004783794284\n",
      "episode: 248100 loss 0.001264843507669866\n",
      "episode: 248200 loss 0.0028047747910022736\n",
      "episode: 248300 loss 0.002343729604035616\n",
      "episode: 248400 loss 0.0008026554714888334\n",
      "episode: 248500 loss 0.0019249486504122615\n",
      "episode: 248600 loss 0.004632614552974701\n",
      "episode: 248700 loss 0.003939758986234665\n",
      "episode: 248800 loss 0.0010375352576375008\n",
      "episode: 248900 loss 0.0008606483461335301\n",
      "episode: 249000 loss 0.005980453919619322\n",
      "episode: 249100 loss 0.0008400403312407434\n",
      "episode: 249200 loss 0.0013383392943069339\n",
      "episode: 249300 loss 0.0001143382178270258\n",
      "episode: 249400 loss 0.003363121533766389\n",
      "episode: 249500 loss 0.0009959971066564322\n",
      "episode: 249600 loss 0.0005693818093277514\n",
      "episode: 249700 loss 0.0064890519715845585\n",
      "episode: 249800 loss 0.0030753198079764843\n",
      "episode: 249900 loss 0.0016725425375625491\n",
      "episode: 250000 loss 0.0016525762621313334\n",
      "Testing...\n",
      "test accuracy: 0.9745499999999999\n",
      "episode: 250100 loss 0.0008124653249979019\n",
      "episode: 250200 loss 0.0014217812567949295\n",
      "episode: 250300 loss 0.0038436022587120533\n",
      "episode: 250400 loss 0.001653095125220716\n",
      "episode: 250500 loss 0.0013929515844210982\n",
      "episode: 250600 loss 0.0023002505768090487\n",
      "episode: 250700 loss 0.0010224732104688883\n",
      "episode: 250800 loss 0.0016594401095062494\n",
      "episode: 250900 loss 0.002069142647087574\n",
      "episode: 251000 loss 0.004077478311955929\n",
      "episode: 251100 loss 0.0009899893775582314\n",
      "episode: 251200 loss 0.000546859169844538\n",
      "episode: 251300 loss 0.0011867803987115622\n",
      "episode: 251400 loss 0.0003377236134838313\n",
      "episode: 251500 loss 0.002703336300328374\n",
      "episode: 251600 loss 0.000367548200301826\n",
      "episode: 251700 loss 0.00022667547455057502\n",
      "episode: 251800 loss 0.0007941220537759364\n",
      "episode: 251900 loss 0.0011372780427336693\n",
      "episode: 252000 loss 0.003084106370806694\n",
      "episode: 252100 loss 0.0007350072264671326\n",
      "episode: 252200 loss 0.0006791139021515846\n",
      "episode: 252300 loss 0.0066754454746842384\n",
      "episode: 252400 loss 0.00045546889305114746\n",
      "episode: 252500 loss 0.0008192346431314945\n",
      "episode: 252600 loss 0.004415677860379219\n",
      "episode: 252700 loss 0.0010886904783546925\n",
      "episode: 252800 loss 0.00022239680401980877\n",
      "episode: 252900 loss 0.0014753637369722128\n",
      "episode: 253000 loss 0.0007891214336268604\n",
      "episode: 253100 loss 0.00015621056081727147\n",
      "episode: 253200 loss 0.0005459159729070961\n",
      "episode: 253300 loss 0.000390635832445696\n",
      "episode: 253400 loss 0.003962140530347824\n",
      "episode: 253500 loss 0.009620369412004948\n",
      "episode: 253600 loss 0.00019465449440758675\n",
      "episode: 253700 loss 0.00040619290666654706\n",
      "episode: 253800 loss 0.0011306424858048558\n",
      "episode: 253900 loss 0.0014787055552005768\n",
      "episode: 254000 loss 0.0006144733051769435\n",
      "episode: 254100 loss 0.0021648346446454525\n",
      "episode: 254200 loss 0.0005545630119740963\n",
      "episode: 254300 loss 0.0013478121254593134\n",
      "episode: 254400 loss 0.0008940959814935923\n",
      "episode: 254500 loss 0.000792280538007617\n",
      "episode: 254600 loss 0.001349055441096425\n",
      "episode: 254700 loss 0.001946424599736929\n",
      "episode: 254800 loss 0.0017151477513834834\n",
      "episode: 254900 loss 0.00479655247181654\n",
      "episode: 255000 loss 0.0039429860189557076\n",
      "Testing...\n",
      "test accuracy: 0.9721000000000001\n",
      "episode: 255100 loss 0.0017017120262607932\n",
      "episode: 255200 loss 0.000515875406563282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 255300 loss 0.0011764724040403962\n",
      "episode: 255400 loss 0.0015113366534933448\n",
      "episode: 255500 loss 0.00227325945161283\n",
      "episode: 255600 loss 0.0010332622332498431\n",
      "episode: 255700 loss 0.0019342056475579739\n",
      "episode: 255800 loss 0.001841467572376132\n",
      "episode: 255900 loss 0.005370073951780796\n",
      "episode: 256000 loss 0.0031005998607724905\n",
      "episode: 256100 loss 0.002036098623648286\n",
      "episode: 256200 loss 0.0008074712823145092\n",
      "episode: 256300 loss 0.0008453559130430222\n",
      "episode: 256400 loss 0.0017344048246741295\n",
      "episode: 256500 loss 0.0006982578197494149\n",
      "episode: 256600 loss 0.0005291170091368258\n",
      "episode: 256700 loss 0.007397657260298729\n",
      "episode: 256800 loss 0.0012691427255049348\n",
      "episode: 256900 loss 0.0024177751038223505\n",
      "episode: 257000 loss 0.0055042169988155365\n",
      "episode: 257100 loss 0.0017687760991975665\n",
      "episode: 257200 loss 0.0049724397249519825\n",
      "episode: 257300 loss 0.0026441351510584354\n",
      "episode: 257400 loss 0.0018694371683523059\n",
      "episode: 257500 loss 0.0010062482906505466\n",
      "episode: 257600 loss 0.0008762881625443697\n",
      "episode: 257700 loss 0.007088284473866224\n",
      "episode: 257800 loss 0.00016886457160580903\n",
      "episode: 257900 loss 0.001257777214050293\n",
      "episode: 258000 loss 0.002165172714740038\n",
      "episode: 258100 loss 0.0004522149683907628\n",
      "episode: 258200 loss 0.001220253179781139\n",
      "episode: 258300 loss 0.002099049976095557\n",
      "episode: 258400 loss 0.0027588270604610443\n",
      "episode: 258500 loss 0.0017733366694301367\n",
      "episode: 258600 loss 0.0005661878967657685\n",
      "episode: 258700 loss 0.003512878669425845\n",
      "episode: 258800 loss 0.003255364950746298\n",
      "episode: 258900 loss 0.00029076862847432494\n",
      "episode: 259000 loss 0.002893592929467559\n",
      "episode: 259100 loss 0.003288829466328025\n",
      "episode: 259200 loss 0.0012677437625825405\n",
      "episode: 259300 loss 0.001187289715744555\n",
      "episode: 259400 loss 0.0015778590459376574\n",
      "episode: 259500 loss 0.0016922596842050552\n",
      "episode: 259600 loss 0.005641070660203695\n",
      "episode: 259700 loss 0.0009660851792432368\n",
      "episode: 259800 loss 0.0007366897189058363\n",
      "episode: 259900 loss 0.0037434434052556753\n",
      "episode: 260000 loss 0.0011998872505500913\n",
      "Testing...\n",
      "test accuracy: 0.9745499999999999\n",
      "episode: 260100 loss 0.0007010453846305609\n",
      "episode: 260200 loss 0.0015780060784891248\n",
      "episode: 260300 loss 0.0008552544750273228\n",
      "episode: 260400 loss 0.001127323368564248\n",
      "episode: 260500 loss 0.0001694429956842214\n",
      "episode: 260600 loss 0.0022212585899978876\n",
      "episode: 260700 loss 0.0013091008877381682\n",
      "episode: 260800 loss 0.0002579801366664469\n",
      "episode: 260900 loss 0.0013872337294742465\n",
      "episode: 261000 loss 0.003968806937336922\n",
      "episode: 261100 loss 0.0028075166046619415\n",
      "episode: 261200 loss 0.0016415929421782494\n",
      "episode: 261300 loss 0.0006547423545271158\n",
      "episode: 261400 loss 0.0009503612527623773\n",
      "episode: 261500 loss 0.0022211128380149603\n",
      "episode: 261600 loss 0.004983931314200163\n",
      "episode: 261700 loss 0.0017259619198739529\n",
      "episode: 261800 loss 0.0023021872621029615\n",
      "episode: 261900 loss 0.0005546518950723112\n",
      "episode: 262000 loss 0.0010574915213510394\n",
      "episode: 262100 loss 0.002105468651279807\n",
      "episode: 262200 loss 0.004363050684332848\n",
      "episode: 262300 loss 0.0007419104804284871\n",
      "episode: 262400 loss 0.0008433336624875665\n",
      "episode: 262500 loss 0.002426185179501772\n",
      "episode: 262600 loss 0.0009124900097958744\n",
      "episode: 262700 loss 0.0005339100025594234\n",
      "episode: 262800 loss 0.0003940888855140656\n",
      "episode: 262900 loss 0.0002567600749898702\n",
      "episode: 263000 loss 0.0002778469934128225\n",
      "episode: 263100 loss 0.002180777955800295\n",
      "episode: 263200 loss 0.0004091631271876395\n",
      "episode: 263300 loss 0.004348154179751873\n",
      "episode: 263400 loss 0.0009451504447497427\n",
      "episode: 263500 loss 0.0027644133660942316\n",
      "episode: 263600 loss 0.0009130101534537971\n",
      "episode: 263700 loss 0.00019315096142236143\n",
      "episode: 263800 loss 0.0020402444060891867\n",
      "episode: 263900 loss 0.0008652945980429649\n",
      "episode: 264000 loss 0.003461380023509264\n",
      "episode: 264100 loss 0.0014589147176593542\n",
      "episode: 264200 loss 0.001918399822898209\n",
      "episode: 264300 loss 0.0012606825912371278\n",
      "episode: 264400 loss 0.0003142252971883863\n",
      "episode: 264500 loss 0.004146787337958813\n",
      "episode: 264600 loss 0.0012303104158490896\n",
      "episode: 264700 loss 0.0007704460876993835\n",
      "episode: 264800 loss 0.0012475420953705907\n",
      "episode: 264900 loss 0.00037062523188069463\n",
      "episode: 265000 loss 0.00023699119628872722\n",
      "Testing...\n",
      "test accuracy: 0.97625\n",
      "episode: 265100 loss 0.003162495093420148\n",
      "episode: 265200 loss 0.002125995699316263\n",
      "episode: 265300 loss 0.0010621207766234875\n",
      "episode: 265400 loss 0.0006777814123779535\n",
      "episode: 265500 loss 0.004085507243871689\n",
      "episode: 265600 loss 0.0016732113435864449\n",
      "episode: 265700 loss 0.0006660401122644544\n",
      "episode: 265800 loss 0.00039793585892766714\n",
      "episode: 265900 loss 0.002831815043464303\n",
      "episode: 266000 loss 0.0015333618503063917\n",
      "episode: 266100 loss 0.0017169425264000893\n",
      "episode: 266200 loss 0.0011329326080158353\n",
      "episode: 266300 loss 0.0005928193568252027\n",
      "episode: 266400 loss 0.0006860886933282018\n",
      "episode: 266500 loss 0.00043859094148501754\n",
      "episode: 266600 loss 0.0007033093716017902\n",
      "episode: 266700 loss 0.0036652381531894207\n",
      "episode: 266800 loss 0.0008139812853187323\n",
      "episode: 266900 loss 0.0005958832334727049\n",
      "episode: 267000 loss 0.0012616801541298628\n",
      "episode: 267100 loss 0.002407171530649066\n",
      "episode: 267200 loss 0.0006091728573665023\n",
      "episode: 267300 loss 0.002313094213604927\n",
      "episode: 267400 loss 0.005877393763512373\n",
      "episode: 267500 loss 0.00114337052218616\n",
      "episode: 267600 loss 0.0013155096676200628\n",
      "episode: 267700 loss 0.0014809217536821961\n",
      "episode: 267800 loss 0.0009244676330126822\n",
      "episode: 267900 loss 0.0009983634809032083\n",
      "episode: 268000 loss 0.00010678415856091306\n",
      "episode: 268100 loss 0.0004803159972652793\n",
      "episode: 268200 loss 0.0002161182346753776\n",
      "episode: 268300 loss 0.003636065637692809\n",
      "episode: 268400 loss 0.0019001462496817112\n",
      "episode: 268500 loss 0.00026585819432511926\n",
      "episode: 268600 loss 0.0038121575489640236\n",
      "episode: 268700 loss 0.0011717014713212848\n",
      "episode: 268800 loss 0.00161705759819597\n",
      "episode: 268900 loss 0.00014715251745656133\n",
      "episode: 269000 loss 0.0022880423348397017\n",
      "episode: 269100 loss 0.0010878023458644748\n",
      "episode: 269200 loss 0.0012246210826560855\n",
      "episode: 269300 loss 0.005194670520722866\n",
      "episode: 269400 loss 0.002416124800220132\n",
      "episode: 269500 loss 0.0007185947033576667\n",
      "episode: 269600 loss 0.0005215408164076507\n",
      "episode: 269700 loss 0.00037224101833999157\n",
      "episode: 269800 loss 0.003017274895682931\n",
      "episode: 269900 loss 0.0008571064099669456\n",
      "episode: 270000 loss 0.0037641916424036026\n",
      "Testing...\n",
      "test accuracy: 0.9729\n",
      "episode: 270100 loss 0.0012051453813910484\n",
      "episode: 270200 loss 0.0011493522906675935\n",
      "episode: 270300 loss 0.0014485892606899142\n",
      "episode: 270400 loss 0.00195310078561306\n",
      "episode: 270500 loss 0.001308352337218821\n",
      "episode: 270600 loss 0.0015550291864201427\n",
      "episode: 270700 loss 0.005027120467275381\n",
      "episode: 270800 loss 0.004120992496609688\n",
      "episode: 270900 loss 0.0008747907704673707\n",
      "episode: 271000 loss 0.0015107969520613551\n",
      "episode: 271100 loss 0.0005246028886176646\n",
      "episode: 271200 loss 0.0024493220262229443\n",
      "episode: 271300 loss 0.0035812535788863897\n",
      "episode: 271400 loss 0.0008266469230875373\n",
      "episode: 271500 loss 0.0011649829102680087\n",
      "episode: 271600 loss 0.003827624721452594\n",
      "episode: 271700 loss 0.0007886880775913596\n",
      "episode: 271800 loss 0.0031752176582813263\n",
      "episode: 271900 loss 0.0013201611582189798\n",
      "episode: 272000 loss 0.000448575709015131\n",
      "episode: 272100 loss 0.0011063845595344901\n",
      "episode: 272200 loss 0.0018061965238302946\n",
      "episode: 272300 loss 0.0004257109831087291\n",
      "episode: 272400 loss 0.0027872661594301462\n",
      "episode: 272500 loss 0.001892709988169372\n",
      "episode: 272600 loss 0.0006687358836643398\n",
      "episode: 272700 loss 0.00011374796304153278\n",
      "episode: 272800 loss 0.003000971395522356\n",
      "episode: 272900 loss 0.0014237593859434128\n",
      "episode: 273000 loss 0.007433701306581497\n",
      "episode: 273100 loss 0.0006598023464903235\n",
      "episode: 273200 loss 0.001454034703783691\n",
      "episode: 273300 loss 0.0018182190833613276\n",
      "episode: 273400 loss 0.0057503278367221355\n",
      "episode: 273500 loss 0.002564861671999097\n",
      "episode: 273600 loss 0.0032351785339415073\n",
      "episode: 273700 loss 0.0004889504634775221\n",
      "episode: 273800 loss 0.0015373402275145054\n",
      "episode: 273900 loss 0.002298585372045636\n",
      "episode: 274000 loss 0.0009429379715584219\n",
      "episode: 274100 loss 0.0027252864092588425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 274200 loss 0.0012547418009489775\n",
      "episode: 274300 loss 0.002076364355161786\n",
      "episode: 274400 loss 0.002962894504889846\n",
      "episode: 274500 loss 0.0008321076747961342\n",
      "episode: 274600 loss 0.0014132686192169785\n",
      "episode: 274700 loss 0.004522978328168392\n",
      "episode: 274800 loss 0.0043633379973471165\n",
      "episode: 274900 loss 0.002373587805777788\n",
      "episode: 275000 loss 0.0008865187992341816\n",
      "Testing...\n",
      "test accuracy: 0.97335\n",
      "episode: 275100 loss 0.0018020691350102425\n",
      "episode: 275200 loss 0.000678369658999145\n",
      "episode: 275300 loss 0.0012134065618738532\n",
      "episode: 275400 loss 0.0007699879934079945\n",
      "episode: 275500 loss 0.0069948360323905945\n",
      "episode: 275600 loss 0.0007757736602798104\n",
      "episode: 275700 loss 0.00029511464526876807\n",
      "episode: 275800 loss 0.006005328614264727\n",
      "episode: 275900 loss 0.0022086072713136673\n",
      "episode: 276000 loss 0.0005212252726778388\n",
      "episode: 276100 loss 0.004327872768044472\n",
      "episode: 276200 loss 0.00027582005714066327\n",
      "episode: 276300 loss 0.0042173368856310844\n",
      "episode: 276400 loss 0.0020987680181860924\n",
      "episode: 276500 loss 0.00046590008423663676\n",
      "episode: 276600 loss 0.0007830576505511999\n",
      "episode: 276700 loss 0.0007269619381986558\n",
      "episode: 276800 loss 0.004076756536960602\n",
      "episode: 276900 loss 0.0018841850105673075\n",
      "episode: 277000 loss 0.004239257890731096\n",
      "episode: 277100 loss 0.001324328943155706\n",
      "episode: 277200 loss 0.001102487207390368\n",
      "episode: 277300 loss 0.0002122467994922772\n",
      "episode: 277400 loss 0.006332241930067539\n",
      "episode: 277500 loss 0.005438109859824181\n",
      "episode: 277600 loss 0.003015912603586912\n",
      "episode: 277700 loss 0.0009289918234571815\n",
      "episode: 277800 loss 0.0036253873258829117\n",
      "episode: 277900 loss 0.0010247743921354413\n",
      "episode: 278000 loss 0.0010671410709619522\n",
      "episode: 278100 loss 0.001327673438936472\n",
      "episode: 278200 loss 0.0002015082136495039\n",
      "episode: 278300 loss 0.002095061121508479\n",
      "episode: 278400 loss 0.0007692594081163406\n",
      "episode: 278500 loss 0.0009980816394090652\n",
      "episode: 278600 loss 0.0002962074358947575\n",
      "episode: 278700 loss 0.00355619378387928\n",
      "episode: 278800 loss 0.00275349710136652\n",
      "episode: 278900 loss 0.001372573897242546\n",
      "episode: 279000 loss 0.0006137764430604875\n",
      "episode: 279100 loss 0.001108509604819119\n",
      "episode: 279200 loss 0.0010418043239042163\n",
      "episode: 279300 loss 0.0031032839324325323\n",
      "episode: 279400 loss 0.0026172639336436987\n",
      "episode: 279500 loss 0.001951453392393887\n",
      "episode: 279600 loss 0.0022266388405114412\n",
      "episode: 279700 loss 0.005841786041855812\n",
      "episode: 279800 loss 0.0022771800868213177\n",
      "episode: 279900 loss 0.001274521229788661\n",
      "episode: 280000 loss 0.001957888016477227\n",
      "Testing...\n",
      "test accuracy: 0.9741000000000001\n",
      "episode: 280100 loss 0.001260182587429881\n",
      "episode: 280200 loss 0.003251272952184081\n",
      "episode: 280300 loss 0.0025642276741564274\n",
      "episode: 280400 loss 0.0005629010265693069\n",
      "episode: 280500 loss 0.004476622212678194\n",
      "episode: 280600 loss 0.0019791258964687586\n",
      "episode: 280700 loss 0.0022499796468764544\n",
      "episode: 280800 loss 0.0007531850133091211\n",
      "episode: 280900 loss 0.0022733432706445456\n",
      "episode: 281000 loss 0.002780212089419365\n",
      "episode: 281100 loss 0.004231841769069433\n",
      "episode: 281200 loss 0.0030069644562900066\n",
      "episode: 281300 loss 0.0006323201232589781\n",
      "episode: 281400 loss 0.004411753732711077\n",
      "episode: 281500 loss 0.0051572578959167\n",
      "episode: 281600 loss 0.0007183450507000089\n",
      "episode: 281700 loss 0.0014817138435319066\n",
      "episode: 281800 loss 0.0008449286688119173\n",
      "episode: 281900 loss 0.00039606908103451133\n",
      "episode: 282000 loss 0.0009940500603988767\n",
      "episode: 282100 loss 0.0006251775776036084\n",
      "episode: 282200 loss 0.0010172710753977299\n",
      "episode: 282300 loss 0.0007696999819017947\n",
      "episode: 282400 loss 0.003187220310792327\n",
      "episode: 282500 loss 0.0011532338103279471\n",
      "episode: 282600 loss 0.0008519014227204025\n",
      "episode: 282700 loss 0.0024606857914477587\n",
      "episode: 282800 loss 0.0010803139302879572\n",
      "episode: 282900 loss 0.00044528115540742874\n",
      "episode: 283000 loss 0.0011952028144150972\n",
      "episode: 283100 loss 0.001136219478212297\n",
      "episode: 283200 loss 0.001770369941368699\n",
      "episode: 283300 loss 0.0007685016025789082\n",
      "episode: 283400 loss 0.0018117469735443592\n",
      "episode: 283500 loss 0.0024327475111931562\n",
      "episode: 283600 loss 0.003678529988974333\n",
      "episode: 283700 loss 0.0007376401918008924\n",
      "episode: 283800 loss 0.006611787248402834\n",
      "episode: 283900 loss 0.0006839365232735872\n",
      "episode: 284000 loss 0.0019752238877117634\n",
      "episode: 284100 loss 0.005990966223180294\n",
      "episode: 284200 loss 0.0010900155175477266\n",
      "episode: 284300 loss 0.0007568330620415509\n",
      "episode: 284400 loss 0.003525952808558941\n",
      "episode: 284500 loss 0.0005097427056171\n",
      "episode: 284600 loss 0.007633531466126442\n",
      "episode: 284700 loss 0.007225589826703072\n",
      "episode: 284800 loss 0.0008533655200153589\n",
      "episode: 284900 loss 0.0021126680076122284\n",
      "episode: 285000 loss 0.0011602010345086455\n",
      "Testing...\n",
      "test accuracy: 0.97405\n",
      "episode: 285100 loss 0.0045678699389100075\n",
      "episode: 285200 loss 0.0010862286435440183\n",
      "episode: 285300 loss 0.005582556128501892\n",
      "episode: 285400 loss 0.003672891529276967\n",
      "episode: 285500 loss 0.0010538168717175722\n",
      "episode: 285600 loss 0.0020180793944746256\n",
      "episode: 285700 loss 0.0013689413899555802\n",
      "episode: 285800 loss 0.0024841679260134697\n",
      "episode: 285900 loss 0.001885026111267507\n",
      "episode: 286000 loss 0.0016142504755407572\n",
      "episode: 286100 loss 0.004670869093388319\n",
      "episode: 286200 loss 0.0008809741702862084\n",
      "episode: 286300 loss 0.0012735818745568395\n",
      "episode: 286400 loss 0.0004386335494928062\n",
      "episode: 286500 loss 0.0003740265965461731\n",
      "episode: 286600 loss 0.0008333871955983341\n",
      "episode: 286700 loss 0.0007295587565749884\n",
      "episode: 286800 loss 0.0014377323677763343\n",
      "episode: 286900 loss 0.006688365247100592\n",
      "episode: 287000 loss 0.001130651799030602\n",
      "episode: 287100 loss 0.002804611111059785\n",
      "episode: 287200 loss 0.0001128462899941951\n",
      "episode: 287300 loss 0.0013210296165198088\n",
      "episode: 287400 loss 0.0011216867715120316\n",
      "episode: 287500 loss 0.0008575038518756628\n",
      "episode: 287600 loss 0.0013765331823378801\n",
      "episode: 287700 loss 0.0035855527967214584\n",
      "episode: 287800 loss 0.0021630378905683756\n",
      "episode: 287900 loss 0.000699481985066086\n",
      "episode: 288000 loss 0.003065371885895729\n",
      "episode: 288100 loss 0.003414441831409931\n",
      "episode: 288200 loss 0.0009488054201938212\n",
      "episode: 288300 loss 0.0005585307953879237\n",
      "episode: 288400 loss 0.0026015625335276127\n",
      "episode: 288500 loss 0.0013362078461796045\n",
      "episode: 288600 loss 0.00040405592881143093\n",
      "episode: 288700 loss 0.0004024013178423047\n",
      "episode: 288800 loss 0.0009225251851603389\n",
      "episode: 288900 loss 0.0011619398137554526\n",
      "episode: 289000 loss 0.001264479593373835\n",
      "episode: 289100 loss 0.0005093232030048966\n",
      "episode: 289200 loss 0.0013107393169775605\n",
      "episode: 289300 loss 0.003191278548911214\n",
      "episode: 289400 loss 0.000540729786735028\n",
      "episode: 289500 loss 0.0011229878291487694\n",
      "episode: 289600 loss 0.001573094166815281\n",
      "episode: 289700 loss 0.0016520534409210086\n",
      "episode: 289800 loss 0.0004919127677567303\n",
      "episode: 289900 loss 0.0007940104696899652\n",
      "episode: 290000 loss 0.004405825398862362\n",
      "Testing...\n",
      "test accuracy: 0.97705\n",
      "episode: 290100 loss 0.002558687934651971\n",
      "episode: 290200 loss 0.0010927383555099368\n",
      "episode: 290300 loss 0.004199404735118151\n",
      "episode: 290400 loss 0.0023989251349121332\n",
      "episode: 290500 loss 0.003332955064252019\n",
      "episode: 290600 loss 0.0008576257969252765\n",
      "episode: 290700 loss 0.0028721459675580263\n",
      "episode: 290800 loss 0.002325815847143531\n",
      "episode: 290900 loss 0.0013461532071232796\n",
      "episode: 291000 loss 0.00358135299757123\n",
      "episode: 291100 loss 0.0017077216180041432\n",
      "episode: 291200 loss 0.0037486867513507605\n",
      "episode: 291300 loss 0.0017568820621818304\n",
      "episode: 291400 loss 0.0009931891690939665\n",
      "episode: 291500 loss 0.002830292098224163\n",
      "episode: 291600 loss 0.0029039541259407997\n",
      "episode: 291700 loss 0.0006245846743695438\n",
      "episode: 291800 loss 0.0011127414181828499\n",
      "episode: 291900 loss 0.005549471825361252\n",
      "episode: 292000 loss 0.00019864110799971968\n",
      "episode: 292100 loss 0.0039733536541461945\n",
      "episode: 292200 loss 0.005389868281781673\n",
      "episode: 292300 loss 0.005222237203270197\n",
      "episode: 292400 loss 0.0014651662204414606\n",
      "episode: 292500 loss 0.00336813204921782\n",
      "episode: 292600 loss 0.0006538345478475094\n",
      "episode: 292700 loss 0.0005236492143012583\n",
      "episode: 292800 loss 0.005175418686121702\n",
      "episode: 292900 loss 0.0007897844188846648\n",
      "episode: 293000 loss 0.0019553101155906916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 293100 loss 0.0007082975935190916\n",
      "episode: 293200 loss 0.006732705980539322\n",
      "episode: 293300 loss 0.0020717307925224304\n",
      "episode: 293400 loss 0.0006972856353968382\n",
      "episode: 293500 loss 0.0005798609927296638\n",
      "episode: 293600 loss 0.004050427582114935\n",
      "episode: 293700 loss 0.0058107441291213036\n",
      "episode: 293800 loss 0.0019281132845208049\n",
      "episode: 293900 loss 0.0006938896258361638\n",
      "episode: 294000 loss 0.0016063271323218942\n",
      "episode: 294100 loss 0.0008825035765767097\n",
      "episode: 294200 loss 0.002404933562502265\n",
      "episode: 294300 loss 0.001491581555455923\n",
      "episode: 294400 loss 0.0017753159627318382\n",
      "episode: 294500 loss 0.0016951939323917031\n",
      "episode: 294600 loss 0.001120901433750987\n",
      "episode: 294700 loss 0.00047345992061309516\n",
      "episode: 294800 loss 0.005504949484020472\n",
      "episode: 294900 loss 0.0008279943722300231\n",
      "episode: 295000 loss 0.0015746642602607608\n",
      "Testing...\n",
      "test accuracy: 0.9748\n",
      "episode: 295100 loss 0.000539676402695477\n",
      "episode: 295200 loss 0.0008454846683889627\n",
      "episode: 295300 loss 0.0010004438227042556\n",
      "episode: 295400 loss 0.0028709068428725004\n",
      "episode: 295500 loss 0.0007593766204081476\n",
      "episode: 295600 loss 0.0015897132689133286\n",
      "episode: 295700 loss 0.0008801346411928535\n",
      "episode: 295800 loss 0.0015391161432489753\n",
      "episode: 295900 loss 0.0007080037030391395\n",
      "episode: 296000 loss 0.0008669165545143187\n",
      "episode: 296100 loss 0.00032210967037826777\n",
      "episode: 296200 loss 0.0007038416806608438\n",
      "episode: 296300 loss 0.0054113916121423244\n",
      "episode: 296400 loss 0.0012118179583922029\n",
      "episode: 296500 loss 0.003846647683531046\n",
      "episode: 296600 loss 0.004529016558080912\n",
      "episode: 296700 loss 0.0027249299455434084\n",
      "episode: 296800 loss 0.0011875508353114128\n",
      "episode: 296900 loss 0.0011711115948855877\n",
      "episode: 297000 loss 0.004536785650998354\n",
      "episode: 297100 loss 0.003634992754086852\n",
      "episode: 297200 loss 0.0016669967444613576\n",
      "episode: 297300 loss 0.002226434648036957\n",
      "episode: 297400 loss 0.005451093893498182\n",
      "episode: 297500 loss 0.0018243150552734733\n",
      "episode: 297600 loss 0.00043008357170037925\n",
      "episode: 297700 loss 0.001045385841280222\n",
      "episode: 297800 loss 0.0012601700145751238\n",
      "episode: 297900 loss 0.0024855576921254396\n",
      "episode: 298000 loss 0.0007286021718755364\n",
      "episode: 298100 loss 0.00024659541668370366\n",
      "episode: 298200 loss 0.00409042788669467\n",
      "episode: 298300 loss 0.0005491266492754221\n",
      "episode: 298400 loss 0.0005491134943440557\n",
      "episode: 298500 loss 0.0004157463554292917\n",
      "episode: 298600 loss 0.00020094569481443614\n",
      "episode: 298700 loss 0.0009572512935847044\n",
      "episode: 298800 loss 0.0007946599507704377\n",
      "episode: 298900 loss 0.008991295471787453\n",
      "episode: 299000 loss 0.0006640456849709153\n",
      "episode: 299100 loss 0.0021439208649098873\n",
      "episode: 299200 loss 0.001116825151257217\n",
      "episode: 299300 loss 0.0020906890276819468\n",
      "episode: 299400 loss 0.001023263786919415\n",
      "episode: 299500 loss 0.0008505434379912913\n",
      "episode: 299600 loss 0.0013144166441634297\n",
      "episode: 299700 loss 0.0007536748889833689\n",
      "episode: 299800 loss 0.009617856703698635\n",
      "episode: 299900 loss 0.0001802565238904208\n",
      "episode: 300000 loss 0.0005385145777836442\n",
      "Testing...\n",
      "test accuracy: 0.97375\n",
      "episode: 300100 loss 0.00370641122572124\n",
      "episode: 300200 loss 0.003283279947936535\n",
      "episode: 300300 loss 0.0004527989949565381\n",
      "episode: 300400 loss 0.0019772092346102\n",
      "episode: 300500 loss 0.002167907077819109\n",
      "episode: 300600 loss 0.0013757582055404782\n",
      "episode: 300700 loss 0.00043606088729575276\n",
      "episode: 300800 loss 0.0014965833397582173\n",
      "episode: 300900 loss 0.0003687966673169285\n",
      "episode: 301000 loss 0.001026676851324737\n",
      "episode: 301100 loss 0.0017569615738466382\n",
      "episode: 301200 loss 0.0005389541038312018\n",
      "episode: 301300 loss 0.0023247443605214357\n",
      "episode: 301400 loss 0.0006489190272986889\n",
      "episode: 301500 loss 0.0012649594573304057\n",
      "episode: 301600 loss 0.0003349768230691552\n",
      "episode: 301700 loss 0.005112734157592058\n",
      "episode: 301800 loss 0.000604744185693562\n",
      "episode: 301900 loss 0.005311527289450169\n",
      "episode: 302000 loss 0.0012049215147271752\n",
      "episode: 302100 loss 0.000983346370048821\n",
      "episode: 302200 loss 4.722922676592134e-05\n",
      "episode: 302300 loss 0.0021909100469201803\n",
      "episode: 302400 loss 0.00122257589828223\n",
      "episode: 302500 loss 0.006274938117712736\n",
      "episode: 302600 loss 0.0005258162273094058\n",
      "episode: 302700 loss 0.003872395260259509\n",
      "episode: 302800 loss 0.000881283835042268\n",
      "episode: 302900 loss 0.005056580528616905\n",
      "episode: 303000 loss 0.003013643203303218\n",
      "episode: 303100 loss 0.004325163550674915\n",
      "episode: 303200 loss 0.002094942843541503\n",
      "episode: 303300 loss 0.0009151309495791793\n",
      "episode: 303400 loss 0.00062367512146011\n",
      "episode: 303500 loss 0.0006576681043952703\n",
      "episode: 303600 loss 0.001991309691220522\n",
      "episode: 303700 loss 0.0009864912135526538\n",
      "episode: 303800 loss 0.006023345049470663\n",
      "episode: 303900 loss 0.0009278689394704998\n",
      "episode: 304000 loss 0.0009724786505103111\n",
      "episode: 304100 loss 0.00037922104820609093\n",
      "episode: 304200 loss 0.0009451813530176878\n",
      "episode: 304300 loss 0.0006153552094474435\n",
      "episode: 304400 loss 0.0019517813343554735\n",
      "episode: 304500 loss 0.0007402293267659843\n",
      "episode: 304600 loss 0.000555680482648313\n",
      "episode: 304700 loss 0.002215261571109295\n",
      "episode: 304800 loss 0.005139465909451246\n",
      "episode: 304900 loss 0.0011827617418020964\n",
      "episode: 305000 loss 0.002808190416544676\n",
      "Testing...\n",
      "test accuracy: 0.9751000000000001\n",
      "episode: 305100 loss 0.000588458904530853\n",
      "episode: 305200 loss 0.0005317241884768009\n",
      "episode: 305300 loss 0.0006072971737012267\n",
      "episode: 305400 loss 0.0019463825738057494\n",
      "episode: 305500 loss 0.0007921434589661658\n",
      "episode: 305600 loss 0.0008429213776253164\n",
      "episode: 305700 loss 0.0013492060825228691\n",
      "episode: 305800 loss 0.001872014021500945\n",
      "episode: 305900 loss 0.0012724439147859812\n",
      "episode: 306000 loss 0.0016819071024656296\n",
      "episode: 306100 loss 0.00420434819534421\n",
      "episode: 306200 loss 0.002927981084212661\n",
      "episode: 306300 loss 0.00029061417444609106\n",
      "episode: 306400 loss 0.002187629695981741\n",
      "episode: 306500 loss 0.0006659273058176041\n",
      "episode: 306600 loss 0.0012465366162359715\n",
      "episode: 306700 loss 0.003367685480043292\n",
      "episode: 306800 loss 0.00040889281081035733\n",
      "episode: 306900 loss 0.0010961956577375531\n",
      "episode: 307000 loss 0.0025276278611272573\n",
      "episode: 307100 loss 0.0006007272750139236\n",
      "episode: 307200 loss 0.0006106323562562466\n",
      "episode: 307300 loss 0.0017227880889549851\n",
      "episode: 307400 loss 0.003693200182169676\n",
      "episode: 307500 loss 0.0012887479970231652\n",
      "episode: 307600 loss 0.003055719891563058\n",
      "episode: 307700 loss 0.0010474848095327616\n",
      "episode: 307800 loss 0.0023419049102813005\n",
      "episode: 307900 loss 0.0011695607099682093\n",
      "episode: 308000 loss 0.0007083616801537573\n",
      "episode: 308100 loss 0.00042206086800433695\n",
      "episode: 308200 loss 0.002079665195196867\n",
      "episode: 308300 loss 0.00017835141625255346\n",
      "episode: 308400 loss 0.0013605535496026278\n",
      "episode: 308500 loss 0.001803132239729166\n",
      "episode: 308600 loss 0.0012338347733020782\n",
      "episode: 308700 loss 0.006132903508841991\n",
      "episode: 308800 loss 0.00048025258001871407\n",
      "episode: 308900 loss 0.0057116406969726086\n",
      "episode: 309000 loss 0.0007888554828241467\n",
      "episode: 309100 loss 0.0008705274667590857\n",
      "episode: 309200 loss 0.0007279677665792406\n",
      "episode: 309300 loss 0.00047264283057302237\n",
      "episode: 309400 loss 0.000192138715647161\n",
      "episode: 309500 loss 0.0007232962525449693\n",
      "episode: 309600 loss 0.0008687276858836412\n",
      "episode: 309700 loss 0.0013856104342266917\n",
      "episode: 309800 loss 0.001156508456915617\n",
      "episode: 309900 loss 0.0008805724210105836\n",
      "episode: 310000 loss 0.0010707533219829202\n",
      "Testing...\n",
      "test accuracy: 0.97315\n",
      "episode: 310100 loss 0.0007189299794845283\n",
      "episode: 310200 loss 0.0010237948736175895\n",
      "episode: 310300 loss 0.0015528087969869375\n",
      "episode: 310400 loss 0.002278571482747793\n",
      "episode: 310500 loss 0.0014890172751620412\n",
      "episode: 310600 loss 0.0015290637966245413\n",
      "episode: 310700 loss 0.001324028242379427\n",
      "episode: 310800 loss 0.0009724284755066037\n",
      "episode: 310900 loss 0.002425253624096513\n",
      "episode: 311000 loss 0.005394856445491314\n",
      "episode: 311100 loss 0.0031419931910932064\n",
      "episode: 311200 loss 0.0005466953734867275\n",
      "episode: 311300 loss 0.0009449520148336887\n",
      "episode: 311400 loss 0.00032371413544751704\n",
      "episode: 311500 loss 0.0005811879527755082\n",
      "episode: 311600 loss 0.0014189453795552254\n",
      "episode: 311700 loss 0.0003676274500321597\n",
      "episode: 311800 loss 0.0014139857375994325\n",
      "episode: 311900 loss 0.0030688622500747442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 312000 loss 0.0032273149117827415\n",
      "episode: 312100 loss 0.0007113706087693572\n",
      "episode: 312200 loss 0.0010335457045584917\n",
      "episode: 312300 loss 0.003300800221040845\n",
      "episode: 312400 loss 0.0004554123734124005\n",
      "episode: 312500 loss 0.0003500702150631696\n",
      "episode: 312600 loss 0.0011427635326981544\n",
      "episode: 312700 loss 0.001905030687339604\n",
      "episode: 312800 loss 0.0014625746989622712\n",
      "episode: 312900 loss 0.00026589201297611\n",
      "episode: 313000 loss 0.001239100587554276\n",
      "episode: 313100 loss 0.0013364098267629743\n",
      "episode: 313200 loss 0.006050392985343933\n",
      "episode: 313300 loss 0.0004062372026965022\n",
      "episode: 313400 loss 0.0008621763554401696\n",
      "episode: 313500 loss 0.00458547193557024\n",
      "episode: 313600 loss 0.0006780016701668501\n",
      "episode: 313700 loss 0.00020123629656154662\n",
      "episode: 313800 loss 0.001223309081979096\n",
      "episode: 313900 loss 0.00046477053547278047\n",
      "episode: 314000 loss 0.0011934377253055573\n",
      "episode: 314100 loss 0.0008283986244350672\n",
      "episode: 314200 loss 0.0013150193262845278\n",
      "episode: 314300 loss 0.0021235637832432985\n",
      "episode: 314400 loss 0.00012248422717675567\n",
      "episode: 314500 loss 0.0033978105057030916\n",
      "episode: 314600 loss 0.0008361803484149277\n",
      "episode: 314700 loss 0.006522922310978174\n",
      "episode: 314800 loss 0.002934730378910899\n",
      "episode: 314900 loss 0.002628167625516653\n",
      "episode: 315000 loss 0.0028386402409523726\n",
      "Testing...\n",
      "test accuracy: 0.9749\n",
      "episode: 315100 loss 0.0011524363653734326\n",
      "episode: 315200 loss 0.003522308077663183\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-2ced4c25933b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-2ced4c25933b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelation_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mCNN_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mrn_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The architecture of the network in the paper\n",
    "# First both the sample image and the image from one of the classes is sent into the network \n",
    "# the image features are then concatenated and sent into the relation network\n",
    "# the relation network ultimately learns a deep distance metric \n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "         \n",
    "        self.Block1 = nn.Sequential(\n",
    "                    nn.Conv2d(1,64,3),\n",
    "                    nn.BatchNorm2d(64,momentum=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(2))\n",
    "        self.Block2 = nn.Sequential(\n",
    "                    nn.Conv2d(64,64,3),\n",
    "                    nn.BatchNorm2d(64,momentum=1),\n",
    "                    nn.MaxPool2d(2))\n",
    "        self.Block3 = nn.Sequential(\n",
    "                    nn.Conv2d(64,64,3,padding=1),\n",
    "                    nn.BatchNorm2d(64,momentum=1),\n",
    "                    nn.ReLU(),\n",
    "                    )\n",
    "        self.Block4 = nn.Sequential(\n",
    "                    nn.Conv2d(64,64,3,padding=1),\n",
    "                    nn.BatchNorm2d(64,momentum=1),\n",
    "                    nn.ReLU())\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.Block1(x)\n",
    "        out = self.Block2(out)\n",
    "        out = self.Block3(out)\n",
    "        out = self.Block4(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "class RelationNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RelationNetwork, self).__init__()\n",
    "        self.Block1 = nn.Sequential(\n",
    "                    nn.Conv2d(128,64,3,padding=1),\n",
    "                    nn.BatchNorm2d(64,momentum=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(2))\n",
    "        self.Block2 = nn.Sequential(\n",
    "                    nn.Conv2d(64,64,3,padding=1),\n",
    "                    nn.BatchNorm2d(64,momentum=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fconv1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fconv2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.Block1(x)\n",
    "        out = self.Block2(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = F.relu(self.fconv1(out))\n",
    "        out = torch.sigmoid(self.fconv2(out))\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "def init_weights(m):  #Can Play with Initializations to check \n",
    "    # I have initialized all the blocks with xavier initialization , one form of standard initialization\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(1)\n",
    "        \n",
    "    if type(m) == nn.BatchNorm2d:\n",
    "        m.bias.data.fill_(0.01)\n",
    "        nn.init.constant_(m.weight,1)\n",
    "        \n",
    "        \n",
    "    if type(m) == nn.Conv2d: \n",
    "        m.bias.data.fill_(0.01)\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "       \n",
    "        \n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \n",
    "    train, test = omniglot_character_folders()\n",
    "    #print(\"Char Folders: \", train, val)\n",
    "    \n",
    "    CNN = CNNEncoder()\n",
    "    relation_network = RelationNetwork(FEATURE_DIM, RELATION_DIM)\n",
    "    \n",
    "    CNN.apply(init_weights)\n",
    "    relation_network.apply(init_weights)\n",
    "    \n",
    "    CNN.cuda()\n",
    "    relation_network.cuda()\n",
    "    \n",
    "    CNN_optim = torch.optim.Adam(CNN.parameters(), lr=10e-3)\n",
    "    rn_optim = torch.optim.Adam(relation_network.parameters(), lr = 10e-3)\n",
    "    \n",
    "    # this is to reduce the Learning rate as per mentioned by the paper\n",
    "    # the learning rate scheduler could also be changed to something else and played with\n",
    "    # but in this case the step learning rate was used\n",
    "    CNN_scheduler = StepLR(CNN_optim, step_size=100000, gamma=0.5)#Check gamma value\n",
    "    rn_scheduler = StepLR(rn_optim, step_size=100000, gamma=0.5)\n",
    "    \n",
    "    \n",
    "    last_accuracy = 0.0\n",
    "    \n",
    "    \n",
    "    for episode in range(EPISODE):\n",
    "        \n",
    "        CNN_scheduler.step(episode)\n",
    "        rn_scheduler.step(episode)\n",
    "        \n",
    "        degrees = random.choice([0,90,180,270])\n",
    "        task = OmniglotTask(train, CLASS_NUM, SAMPLE_NUM_PER_CLASS, BATCH_NUM_PER_CLASS)\n",
    "        # the following dataloader are for the training phase \n",
    "        # the sample data loader loads one image per class \n",
    "        # the batch data loader samples 10 images per class \n",
    "        sample_dl = get_data_loader(task, num_per_class=SAMPLE_NUM_PER_CLASS, split=\"train\", shuffle=False, rotation=degrees)\n",
    "        batch_dl = get_data_loader(task, num_per_class=BATCH_NUM_PER_CLASS, split=\"test\", shuffle=True, rotation=degrees)\n",
    "    \n",
    "        samples, sample_labels = sample_dl.__iter__().next()\n",
    "        batches, batch_labels = batch_dl.__iter__().next()\n",
    "        \n",
    "        # \n",
    "        sample_features = CNN(Variable(samples).cuda()) # 20x64*5*5\n",
    "        batch_features = CNN(Variable(batches).cuda()) # 20x64*5*5\n",
    "\n",
    "        # unsqueezing and repeating is just done so as to make it easy to concatenate them into a single vector\n",
    "        sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
    "        batch_features_ext = batch_features.unsqueeze(0).repeat(SAMPLE_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
    "        batch_features_ext = torch.transpose(batch_features_ext,0,1)\n",
    "\n",
    "        # as mentioned earlier the inputs from the CNNs are concatenated and these act as an input to the relation network\n",
    "        relation_pairs = torch.cat((sample_features_ext,batch_features_ext),2).view(-1,FEATURE_DIM*2,5,5)\n",
    "        relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
    "        \n",
    "        \n",
    "        # A mean squared error loss is employed between the labels predicted by the relation network \n",
    "        # and the actual labels\n",
    "        mse = nn.MSELoss().cuda()\n",
    "        one_hot_labels = Variable(torch.zeros(BATCH_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1,1), 1)).cuda()\n",
    "        loss = mse(relations,one_hot_labels)\n",
    "        #print(loss.item())\n",
    "\n",
    "\n",
    "        # training\n",
    "\n",
    "        CNN.zero_grad()\n",
    "        relation_network.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clipping gradients is just done so as to avoid gradient explosion\n",
    "\n",
    "        nn.utils.clip_grad_norm_(CNN.parameters(),0.5)\n",
    "        nn.utils.clip_grad_norm_(relation_network.parameters(),0.5)\n",
    "\n",
    "        CNN_optim.step()\n",
    "        rn_optim.step()\n",
    "\n",
    "        if (episode+1)%100 == 0:\n",
    "                print(\"episode:\",episode+1,\"loss\",loss.item())\n",
    "                \n",
    "                \n",
    "                \n",
    "        if (episode+1)%5000 == 0:\n",
    "\n",
    "            # test\n",
    "            print(\"Testing...\")\n",
    "            total_rewards = 0\n",
    "\n",
    "            for i in range(TEST_EPISODE):\n",
    "                degrees = random.choice([0,90,180,270])\n",
    "                task = OmniglotTask(test,CLASS_NUM,SAMPLE_NUM_PER_CLASS,SAMPLE_NUM_PER_CLASS,)\n",
    "                sample_dataloader = get_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False,rotation=degrees)\n",
    "                test_dataloader = get_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"test\",shuffle=True,rotation=degrees)\n",
    "\n",
    "                sample_images,sample_labels = sample_dataloader.__iter__().next()\n",
    "                test_images,test_labels = test_dataloader.__iter__().next()\n",
    "\n",
    "               \n",
    "                sample_features = CNN(Variable(sample_images).cuda()) \n",
    "                test_features = CNN(Variable(test_images).cuda()) \n",
    "\n",
    "                \n",
    "                sample_features_ext = sample_features.unsqueeze(0).repeat(SAMPLE_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
    "                test_features_ext = test_features.unsqueeze(0).repeat(SAMPLE_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
    "                test_features_ext = torch.transpose(test_features_ext,0,1)\n",
    "\n",
    "                relation_pairs = torch.cat((sample_features_ext,test_features_ext),2).view(-1,FEATURE_DIM*2,5,5)\n",
    "                relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
    "\n",
    "                _,predict_labels = torch.max(relations.data,1)\n",
    "                \n",
    "                test_c = Variable(test_labels).cuda()\n",
    "\n",
    "                rewards = [1 if predict_labels[j]==test_c[j] else 0 for j in range(CLASS_NUM)]\n",
    "\n",
    "                total_rewards += np.sum(rewards)\n",
    "\n",
    "            test_accuracy = total_rewards/1.0/CLASS_NUM/TEST_EPISODE\n",
    "\n",
    "            print(\"test accuracy:\",test_accuracy)\n",
    "\n",
    "            if test_accuracy > last_accuracy:\n",
    "\n",
    "                # save networks\n",
    "                torch.save(CNN.state_dict(),str(\"./models/omniglot_CNN_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
    "                torch.save(relation_network.state_dict(),str(\"./models/omniglot_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
    "\n",
    "                print(\"save networks for episode:\",episode)\n",
    "\n",
    "                last_accuracy = test_accuracy\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The Test Accuracy of the model is : 97.49%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
