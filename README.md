# Papers
These will either be paper implementations or/and reviews of various papers and notes for conference sessions, I will read/watch over time. I currently research on Abstractive Summarization ( A task within NLP).


## Adversarial Examples
- Explaining and Harnessing Adversarial Examples [[Paper](https://arxiv.org/pdf/1412.6572v3.pdf)] [[Review](https://github.com/Shashi456/Papers/blob/master/Review/Explaining%20and%20Harnesssing%20Adversarial%20Examples.md)]
- Intriguing Properties of Neural Networks [[Paper](https://arxiv.org/abs/1312.6199)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Intriguing%20Properties%20of%20Neural%20Networks.md)]
- Practical BlackBox attacks against machine learning [[Paper](https://arxiv.org/abs/1602.02697)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Practical%20Black%20Box%20Attack%20against%20Machine%20Learning.md)]
<?--The Limitations of deep learning in adversarial settings [[Paper](https://arxiv.org/abs/1511.07528)][[Review]()])--?>

## Neural Style
- Neural Algorithm of Artistic Style [[Paper](https://arxiv.org/pdf/1508.06576.pdf)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/A%20Neural%20Algorithm%20of%20Artistic%20Style.md)][[Code](https://github.com/Shashi456/Neural-Style)][[Article](https://towardsdatascience.com/neural-style-transfer-series-part-2-91baad306b24)]

## Image Classification
- Very Deep Convolutional Networks for Large Scale Image Recognition [[Paper](https://arxiv.org/pdf/1409.1556.pdf)][[Review](./Review/VGG.md)]

## One Shot Learning
- Siamese Neural networks for One-Shot Image Recognition [[Paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Siamese%20Neural%20Networks%20for%20One-shot%20Image%20Recogniton.md)]
- Learning to compare: Relation Network for Few shot Learning  [[Paper](http://www.robots.ox.ac.uk/~tvg/publications/2018/0431.pdf)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/LTC%20Relation%20Network%20for%20few%20shot%20learning.md)][[Code](https://github.com/Shashi456/Papers/blob/master/Implementations/Learning%20to%20Compare%20-%20One%20shot%20Leanring/One%20Shot%20Classification(2).ipynb)]


## Natural Language Processing
## Sequence to Sequence Learning

- Sequence to Sequence Learning with Neural Networks. [[Paper](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.md)]


## Attention Based Models
- Neural Machine Translation by jointly learning to align and translate [[Paper](https://arxiv.org/abs/1409.0473)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Neural%20Machine%20Translation%20by%20Jointly%20learning%20to%20align%20and%20translate.md)]


## Text Classification
- Universal Language Model Fine-tuning for Text Classification [[Paper](https://arxiv.org/abs/1801.06146)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Universal%20Language%20Model%20Fine-Tuning%20for%20Text%20Classification.md)]


## Abstractive Summarization
- Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting [[Paper](https://arxiv.org/abs/1805.11080)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Fast%20Abstractive%20Summarization%20with%20Reinforce-Selected%20Sentence%20Rewriting.md)]
- Improving Abstraction in Text Summarization [[Paper](https://arxiv.org/abs/1808.07913)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Improving%20Abstraction%20in%20Text%20Summarization.md)]
- Multi-Reward Reinforced Summarization with Saliency and Entailment [[Paper](https://arxiv.org/abs/1804.06451)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Multi%20Reward%20Reinforced%20Summarization.md)]
- Bottom-Up Abstractive Summarization [[Paper](https://arxiv.org/abs/1808.10792)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/Bottom%20Up%20Abstractive%20Summarization.md)]
- Topic Augmented Generator for Abstractive Summarization [[Paper](https://arxiv.org/abs/1908.07026)][[Review](./Review/TopicAugmentedGenAbsSumm)]
- Earlier Isnâ€™t Always Better: Sub-aspect Analysis on Corpus and System Biases in Summarization [[Paper](https://arxiv.org/abs/1908.11723)][[Review](./Review/SummBiases.md)]
<!-- - Abstractive Text Summarization by Incorporating Reader Comments [[Paper]()][[Review]()]
- Global Encoding For Abstractive Summarization [[Paper]()][[Review]()]
- HIBERT [[Paper]()][[Review]()] -->


### Topic-Based & Query-Based Summarization
- A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization [[Paper](https://arxiv.org/abs/1805.03616)][[Review](./Review/RConvS2Ssummarization.md)]
- Query-Based Abstractive Summarization Using Neural Networks [[Paper](https://arxiv.org/abs/1712.06100)][[Review](./Review/QueryBasedSummNN.md)]
- Transforming Wikipedia into Augmented Data for Query Focused Summarization [[Paper](https://arxiv.org/abs/1911.03324)][[Review](./Review/AugmentWikiforQueryBasedSumm.md)]
- Extreme Summarization with Topic Aware Convolutional Neural Networks [[Paper][v2](https://arxiv.org/abs/1907.08722)[v1](https://arxiv.org/pdf/1808.08745.pdf)][[Review](./Review/XSUM.md)]


## Language Modeling
- CTRL: A Conditional Transformer Language Model for Controllable Generation [[Paper](https://arxiv.org/abs/1909.05858)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/CTRL.md)]


## Training
- Von Mises-Fisher Loss for training Seq2Seq Models with Continous Outputs [[Paper](https://arxiv.org/pdf/1812.04616.pdf)][[Review](https://github.com/Shashi456/Papers/blob/master/Review/VonMisesLoss.md)]

## Question Answering
- Generalizing Question Answering System
with Pre-trained Language Model Fine-tuning [[Paper](https://www.aclweb.org/anthology/D19-5827/)][[Review](./Review/GeneralizingQAXLNET.md)]
- MULTI QA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension [[Paper](https://arxiv.org/abs/1905.13453)][[Review](./Review/MultiQA.md)]
